% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Introduction to Term Structure Models},
  pdfauthor={Jean-Paul Renne and Alain Monfort},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Introduction to Term Structure Models}
\author{Jean-Paul Renne and Alain Monfort}
\date{2024-01-21}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\newcommand{\bv}[1]{\mathbf{#1}}

\hypertarget{intro}{%
\chapter*{Introduction to Term Structure Models}\label{intro}}

Modeling dynamic term structures serves as a practical and indispensable tool in the realm of finance. It enables investors, institutions, and policymakers to make informed decisions, manage risk effectively, and allocate resources wisely. By understanding how interest rates and yields evolve over time, these models offer a clear lens through which to assess market trends and price financial instruments accurately.

This course has been developed by \href{https://sites.google.com/site/jeanpaulrenne/home}{Jean-Paul Renne} and \href{https://faculty.crest.fr/amonfort/}{Alain Monfort}. It is illustrated by R codes using various packages that can be obtained from \href{https://cran.r-project.org}{CRAN}. This \texttt{TSModels} package is available on GitHub. To install it, one need to employ the \texttt{devtools} library:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{) }\CommentTok{\# in case this library has not been loaded yet}
\FunctionTok{library}\NormalTok{(devtools)}
\FunctionTok{install\_github}\NormalTok{(}\StringTok{"jrenne/TSModels"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(AEC)}
\end{Highlighting}
\end{Shaded}

\textbf{Useful (R) links:}

\begin{itemize}
\item
  Download R:

  \begin{itemize}
  \tightlist
  \item
    R software: \url{https://cran.r-project.org} (the basic R software)
  \item
    RStudio: \url{https://www.rstudio.com} (a convenient R editor)
  \end{itemize}
\item
  Tutorials:

  \begin{itemize}
  \tightlist
  \item
    Rstudio: \url{https://dss.princeton.edu/training/RStudio101.pdf} (by Oscar Torres-Reyna)
  \item
    R: \url{https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf} (by Emmanuel Paradis)
  \item
    My own tutorial: \url{https://jrenne.shinyapps.io/Rtuto_publiShiny/}
  \end{itemize}
\end{itemize}

\hypertarget{ChapterAffine}{%
\chapter{Affine processes}\label{ChapterAffine}}

\hypertarget{Information}{%
\section{Information in the Economy: The ``factors''}\label{Information}}

On each date \(t=1,2,\dots,T\), agents receive new information by observing \emph{factors}, also called \emph{states}. We denote the (\(K\)-dimensional) vector of factors by \(w_t\). Vector \(w_t\) is usually random. On date \(t\), vector \(w_t\) is supposed to be perfectly observed by the agents (investors), but can be only partially observed, or unobserved by the econometrician.

Naturally, \(w_t\) can be decomposed into different sub-vectors of different natures. For instance, we can have \(w_t = (y_t', z_t')'\) with
* \(y_t\): observable vector of (geometric) returns,
* \(z_t\): regime, unobserved by the econometrician.

Some of the components of \(w_t\) can be prices. For instance, one component could be a short-term rate, a stock return, or an exchange rate. It can also include macroeconomic variables (inflation, GDP growth), or agent-specific variables.

\hypertarget{Dynamic}{%
\section{Dynamic models and Laplace transform (L.T.)}\label{Dynamic}}

The objective of a dynamic model is to describe the random changes in \(w_t\). The dynamics can be historical or risk-neutral (see Chapter \ref{PandQ}). The dynamics we consider are parametric, in the sense that the conditional distribution \(w_{t+1}|\underline{w_t}\) (with \(\underline{w_t}=\{w_t,w_{t-1},\dots\}\)) depends on a vector of parameters \(\theta\). In practice, it may be the case that \(\theta\) is unknown by the econometrician (see Chapter \ref{Estimation}). The choice (or estimation) of a conditional distribution is equivalent to the choice (or estimation) of a conditional \emph{Laplace transforms}:
\begin{equation}
\varphi(u|\underline{w_t},\theta) =
\mathbb{E}_{\theta}[\exp(u'w_{t+1})|\underline{w_t}], \quad u \in \mathbb{R}^K,\label{eq:LT}
\end{equation}
or a conditional \emph{log Laplace transforms}:
\[
\psi(u|\underline{w_t},\theta) =
\log\{\mathbb{E}_{\theta}[\exp(u'w_{t+1})|\underline{w_t}]\}, \quad u \in
\mathbb{R}^K.
\]

\begin{example}[Conditionally Bernoulli process]
\protect\hypertarget{exm:exBenoulli}{}\label{exm:exBenoulli}If \(w_{t+1}|\underline{w_t} \sim {\mathcal{I}} [p(\underline{w_t},\theta)]\), then:
\[
\varphi(u|w_t)=
\mathbb{E}[\exp(u w_{t+1}) \mid \underline{w_t}] = p_t \exp(u) + 1-p_t
\]
with \(p_t = p(\underline{w_t}, \theta)\).
\end{example}

\begin{example}[Conditionally Binomial process]
\protect\hypertarget{exm:exBenoulli2}{}\label{exm:exBenoulli2}If \(w_{t+1}|\underline{w_t} \in {\mathcal{B}}(n, p_t)\), then:
\[
\varphi(u|w_t)=[p_t   \exp(u) + 1-p_t]^n.
\]
\end{example}

\begin{example}[Conditionally Poisson process]
\protect\hypertarget{exm:exPoisson}{}\label{exm:exPoisson}If \(w_{t+1}|\underline{w_t} \sim {\mathcal{P}}(\lambda_t)\), then:
\begin{eqnarray*}
\varphi(u|w_t) & =&   \sum^\infty_{j=0}  \dfrac{1}{j!}  \exp(-\lambda_t) \lambda^j_t   \exp(uj)  = \exp(-\lambda_t) exp[\lambda_t \exp(u)] \\
& =& \exp\{\lambda_t[\exp(u)-1]\}.
\end{eqnarray*}
\end{example}

\begin{example}[Conditionally normal (or Gaussian) process]
\protect\hypertarget{exm:exGaussian}{}\label{exm:exGaussian}If \(w_{t+1}|\underline{w_t} \sim \mathcal{N}\left(m(\underline{w_t},\theta), \Sigma(\underline{w_t},\theta)\right)\), then:

\[
u'w_{t+1}|\underline{w_t} \sim \mathcal{N}\left(u'm(\underline{w_t},\theta), u'\Sigma(\underline{w_t},\theta)u\right).
\]

\[
\Rightarrow
\left\{
\begin{array}{ccc}
\varphi(u|\underline{w_t},\theta) &=& \exp\left[
\begin{array}{l} u'm(\underline{w_t},\theta)+
\frac{1}{2} u'\Sigma(\underline{w_t},\theta)u\end{array}
\right]\\
\psi(u|\underline{w_t},\theta) &=&
u'm(\underline{w_t},\theta) +  \frac{1}{2}
u'\Sigma(\underline{w_t},\theta)u.
\end{array}
\right.
\]
\end{example}

\hypertarget{AffineLaplace}{%
\section{Laplace Transform and moments/cumulants}\label{AffineLaplace}}

Here are some properties of the Laplace transform (Eq. \eqref{eq:LT}):

\begin{itemize}
\tightlist
\item
  \(\varphi(0|\underline{w_t},\theta) = 1\) and \(\psi(0|\underline{w_t},\theta)=0\).
\item
  It is defined in a convex set \(E\) (containing \(0\)).
\item
  If the interior of \(E\) is non empty, all the (conditional) moments exist.
\end{itemize}

As mentioned above, knowing the (conditional) Laplace transform is equivalent to knowing the (conditional) moments---if they exist. In the scalar case, we have that:

\begin{itemize}
\tightlist
\item
  the moment of order \(n\) closely relates to the \(n^{th}\) derivatives of \(\varphi\):
  \[
  \left[ \begin{array}{l}  \dfrac{\partial^n
  \varphi(u|\underline{w_t},\theta)}{\partial u^n}
  \end{array} \right]_{u=0} = \mathbb{E}_{\theta}[w^n_{t+1}|\underline{w_t}],
  \]
\item
  the cumulant of order \(n\) closely relates to the \(n^{th}\) derivatives of \(\psi\):
  \[
  \left[ \begin{array}{l}  \dfrac{\partial^n
  \psi(u|\underline{w_t},\theta)}{\partial u^n}
  \end{array} \right]_{u=0} = K_n(\underline{w_t},\theta).
  \]
\end{itemize}

In particular, what precedes implies that:
\[
\left\{
\begin{array}{ccc}
K_1(\underline{w_t},\theta) &=& \mathbb{E}_{\theta}[w_{t+1}|\underline{w_t}]\\
K_2(\underline{w_t}, \theta) &=& \mathbb{V}ar_{\theta}[w_{t+1}|\underline{w_t}].
\end{array}
\right.
\]

Accordingly, \(\varphi\) and \(\psi\) are respectively called conditional \textbf{moment} and \textbf{cumulant} generating function.

In the multivariate case, we have:
\begin{eqnarray*}
\left[\begin{array}{l}  \dfrac{\partial \psi}{\partial
u} (u|\underline{w_t},\theta)  \end{array} \right]_{u=0} &=& \mathbb{E}_{\theta}[w_{t+1}|\underline{w_t}] \\
\left[\begin{array}{l}  \dfrac{\partial^2
\psi}{\partial u\partial u'} (u|\underline{w_t},\theta)  \end{array}
\right]_{u=0} &=& \mathbb{V}ar_{\theta}[w_{t+1}|\underline{w_t}].
\end{eqnarray*}

\begin{example}[Conditionally normal (or Gaussian) process]
\protect\hypertarget{exm:exGaussian}{}\label{exm:exGaussian}Consider Example \ref{exm:exGaussian}. Applying the previous formula, we have, in the scalar case:

\begin{itemize}
\tightlist
\item
  \(\psi(u|\underline{w_t},\theta)=u m(\underline{w_t},\theta) + \frac{1}{2}u^2\sigma^2(\underline{w_t},\theta)\).
\item
  \(\left[\begin{array}{l} \dfrac{\partial \psi}{\partial u} (u|\underline{w_t},\theta) \end{array} \right]_{u=0} = m(\underline{w_t},\theta)\).
\item
  \(\left[\begin{array}{l} \dfrac{\partial^2 \psi}{\partial u^2} (u|\underline{w_t},\theta) \end{array} \right]_{u=0} = \sigma^2(\underline{w_t},\theta)\).
\end{itemize}

and, in the multidimensional normal case:

\begin{itemize}
\tightlist
\item
  \(\psi(u|\underline{w_t},\theta)=u' m(\underline{w_t},\theta) + \frac{1}{2}u'\Sigma(\underline{w_t},\theta)u\).
\item
  \(\left[\begin{array}{l} \dfrac{\partial \psi}{\partial u} (u|\underline{w_t},\theta) \end{array} \right]_{u=0} = m(\underline{w_t},\theta)\).
\item
  \(\left[\begin{array}{l} \dfrac{\partial^2 \psi}{\partial u\partial u'} (u|\underline{w_t},\theta) \end{array} \right]_{u=0} = \Sigma(\underline{w_t},\theta)\).
\end{itemize}

In both cases, cumulants of order \(>2\) equal to \(0\).
\end{example}

\hypertarget{additional-properties-of-the-laplace-transform}{%
\section{Additional properties of the Laplace transform}\label{additional-properties-of-the-laplace-transform}}

Here are additional properties of multivariate Laplace transform:

\begin{itemize}
\item
  If \(w_t=(w'_{1t},w'_{2t})'\) \(, u=(u'_1, u'_2)'\):
  \begin{eqnarray*}
  \mathbb{E}_{\theta}[\exp(u'_1 w_{1,t+1}|\underline{w_t})&=&\varphi(u_1,0|\underline{w_t},\theta)] \\
  \mathbb{E}_{\theta}[\exp(u'_2 w
  _{2,t+1}|\underline{w_t})&=&\varphi(0,u_2|\underline{w_t},\theta)].
  \end{eqnarray*}
\item
  If \(w_t=(w'_{1t},w'_{2t})'\), and if \(w_{1t}\) and \(w_{2t}\) are conditionally independent:
  \begin{eqnarray*}
  \varphi(u|\underline{w_t},\theta) &=&
  \varphi(u_1,0|\underline{w_t},\theta)\times\varphi(0,u_2|\underline{w_t},\theta) \\
  \psi(u|\underline{w_t},\theta) &=&
  \psi(u_1,0|\underline{w_t},\theta)+\psi(0,u_2|\underline{w_t},\theta).
  \end{eqnarray*}
\item
  If \(w_{1t}\) and \(w_{2t}\) have the same size and if
  \[
  \varphi(u_1, u_2|\underline{w_t},\theta) = \mathbb{E}_\theta[\exp(u'_1 w_{1, t+1} + u'_2 w_{2,t+1}|\underline{w_t}],
  \]
  then the conditional Laplace transform of \(w_{1, t+1} + w_{2, t+1}\) given
  \(\underline{w_t}\) is \(\varphi(u, u|\underline{w_t},\theta)\).
  In particular, if \(w_{1t}\) and \(w_{2t}\) are conditionally independent and
  have the same size, the conditional Laplace transform and Log-Laplace
  transform of \(w_{1,t+1}+w_{2,t+1}\) are respectively:
  \[
  \varphi(u,0|\underline{w_t},\theta)\times \varphi(0,
  u|\underline{w_t},\theta), \quad \mbox{and}\quad \psi(u,0|\underline{w_t},\theta)+ \psi(0,
  u|\underline{w_t},\theta).
  \]
\end{itemize}

\begin{lemma}[Conditional zero probability for non-negative processes]
\protect\hypertarget{lem:lemMass}{}\label{lem:lemMass}If \(w_t\) is univariate and nonnegative its (conditional)
Laplace transform \(\varphi_t(u) = \mathbb{E}_t[\exp(u w_{t+1})]\) is defined
for \(u \leq 0\) and
\[
\mathbb{P}_t(w_{t+1} = 0) = \lim_{u\rightarrow - \infty} \varphi_t(u).
\]
\end{lemma}

\begin{proof}
We have \(\varphi_t(u) = \mathbb{P}_t(w_{t+1} = 0) + \int_{w_{t+1}> 0} \exp(u w_{t+1}) d\mathbb{P}_t(w_{t+1})\). The Lebesgue theorem ensures that the last integral converges to zero when \(u\) goes to \(-\infty\).
\end{proof}

\begin{lemma}[Conditional zero probability for non-negative multivariate processes]
\protect\hypertarget{lem:lemPetitLemme}{}\label{lem:lemPetitLemme}Assume that:

\begin{itemize}
\tightlist
\item
  \(w_{1,t}\) is valued in \(\mathbb{R}^{d}\) (\(d \geq 1\)),
\item
  \(w_{2,t}\) is valued in \(\mathbb{R}^+ = [0, + \infty )\),
\item
  \(\mathbb{E}_t \left[ \exp \left( u_1 ' w_{1,t+1} + u_2 w_{2,t+1} \right) \right]\) exists for a given \(u_1\) and \(u_2 \leq 0\).
\end{itemize}

Then, we have:
\begin{equation}
\mathbb{E}_t \left[ \exp( u_1 ' w_{1,t+1})  \textbf{1}_{\{w_{2,t+1} = 0 \}} \right] =  \underset{u_2 \rightarrow -\infty}{\lim} \mathbb{E}_t \left[ \exp( u_1 ' w_{1,t+1} + u_2   w_{2,t+1} )  \right].\label{eq:petitlemme}
\end{equation}
\end{lemma}

\begin{proof}
We have that
\begin{eqnarray*}
&&\underset{u_2 \rightarrow -\infty}{\lim} \mathbb{E}_t \left[ \exp( u_1 ' w_{1,t+1} + u_2   w_{2,t+1} )  \right] \\
&=& \mathbb{E}_t \left[ \exp( u_1 ' w_{1,t+1})   \textbf{1}_{\{w_{2,t+1} = 0 \}} \right] +\\
&& \underset{u_2 \rightarrow -\infty}{\lim}   \mathbb{E}_t \left[ \exp( u_1 ' w_{1,t+1} + u_2   w_{2,t+1} )  \textbf{1}_{\{w_{2,t+1} > 0 \}}  \right] ,
\end{eqnarray*}
and since in the second term on the right-hand side \(\exp(u_2 w_{2,t+1}) \textbf{1}_{\{w_{2,t+1} > 0 \}} \rightarrow 0\) when \(u_2 \rightarrow -\infty\), Eq. \eqref{eq:petitlemme} is a consequence of the Lebesgue theorem.
\end{proof}

\hypertarget{AffineCar}{%
\section{Affine (or Car) processes}\label{AffineCar}}

In term structure applications, we will often consider \emph{affine} processes (Definitions \ref{def:Car1} and \ref{def:Carp}). These processes are indeed such that their multi-horizon Laplace transform are simple to compute (Lemma \ref{lem:MHLT} and Proposition \ref{prp:reverseMLT}), which is key to compute bond prices.

\hypertarget{car-processes-of-order-one}{%
\subsection{Car processes of order one}\label{car-processes-of-order-one}}

Here is the definition of a \emph{compound auto-regressive (Car)} process of order one:

\begin{definition}[Affine process of order 1]
\protect\hypertarget{def:Car1}{}\label{def:Car1}A multivariate process \(w_{t+1}\) is Affine of order 1 {[}or \(Car(1)\){]} if
\[
\varphi_t(u)=\mathbb{E}_t[\exp(u'w_{t+1})]=\exp[a(u)'w_t+b(u)]
\]
for some functions \(a(.)\) and \(b(.)\). These functions are univariate if \(w_{t+1}\) (and therefore \(u\)) is scalar.
\end{definition}

Note that \(a(.)\) and \(b(.)\) may be deterministic functions of time (e.g., \citet{Chikhani_Renne_2022}).

A first key example is that of the Gaussian auto-regressive processes:

\begin{example}[Univariate AR(1) Gaussian process]
\protect\hypertarget{exm:GAR1}{}\label{exm:GAR1}If \(w_{t+1}|\underline{w_t} \sim \mathcal{N}(\nu+\rho w_t, \sigma^2)\), then:
\[
\varphi_t(u) = \exp\left(
\begin{array}{l}
u \rho w_t + u \nu + u^2  \frac{\sigma^2}{2}
\end{array}
\right) = \exp[a(u)'w_t+b(u)],
\]
\[
\mbox{with }\left\{
\begin{array}{ccc}
a(u) &=& u \rho\\
b(u) &=& u \nu + u^2  \dfrac{\sigma^2}{2}.
\end{array}
\right.
\]
\end{example}

\begin{example}[Gaussian VAR]
\protect\hypertarget{exm:GVAR1}{}\label{exm:GVAR1}If \(w_{t+1}|\underline{w_t} \sim \mathcal{N}(\mu+\Phi w_t, \Sigma)\), then:
\[
\varphi_t(u) = \exp\left(
\begin{array}{l}
u' (\mu + \Phi  w_t)  +  \frac{1}{2} u' \Sigma u
\end{array}
\right) = \exp[a(u)'w_t+b(u)],
\]
\[
\mbox{with }\left\{
\begin{array}{ccl}
a(u) &=& \Phi'u\\
b(u) &=& u' \mu +  \frac{1}{2} u' \Sigma u = u' \mu + \frac{1}{2}(u \otimes u)' vec(\Sigma).
\end{array}
\right.
\]
\end{example}

\begin{example}[Quadratic Gaussian process]
\protect\hypertarget{exm:QGVAR1}{}\label{exm:QGVAR1}

Consider vector \(w_t = (x'_t,vec(x_t x_t')')'\), where \(x_t\) is a \(n\)-dimensional vector following a Gaussian VAR(1), i.e.
\[
x_{t+1}|\underline{w_t} \sim \mathcal{N}(\mu+\Phi x_t, \Sigma).
\]
Proposition \ref{prp:QGVAR1} shows that if \(u = (v,V)\) where \(v \in \mathbb{R}^n\) and \(V\) a square symmetric matrix of size \(n\), we have:
\begin{eqnarray*}
\varphi_t(u) &=& \mathbb{E}_t\big\{\exp\big[(v',vec(V)')\times w_{t+1}\big]\big\} \\
& =& \exp \left\{a_1(v,V)'x_t +vec(a_2(v,V))' vec(x_t'x_t) + b(v,V) \right\},
\end{eqnarray*}
where:
\begin{eqnarray*}
a_2(u) & = & \Phi'V (I_n - 2\Sigma V)^{-1} \Phi \nonumber \\
a_1(u) & = & \Phi'\left[(I_n-2V\Sigma)^{-1}(v+2V\mu)\right] \nonumber \\
b(u) & = & u'(I_n - 2 \Sigma V)^{-1}\left(\mu + \frac{1}{2} \Sigma v\right) +\\
&& \mu'V(I_n - 2 \Sigma V)^{-1}\mu - \frac{1}{2}\log\big|I_n - 2\Sigma V\big|.\label{eq:laplaceZ}
\end{eqnarray*}

Quadratic processes can be used to construct positive process. Indeed, one can determine linear combinations of the components of \(w_t\) (\(\alpha'w_t\), say) that are such that \(\alpha'w_t \ge 0\). For instance, if \(x_t\) is scalar, \(\alpha'w_t = x_t^2\) if \(\alpha = (0,1)'\). This is illustrated by Figure \ref{fig:simQVAR}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{200}
\NormalTok{phi }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{9}\NormalTok{;sigma }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{x.t }\OtherTok{\textless{}{-}} \DecValTok{0}\NormalTok{; x }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\ControlFlowTok{for}\NormalTok{(t }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T)\{}
\NormalTok{  x.t }\OtherTok{\textless{}{-}}\NormalTok{ phi}\SpecialCharTok{*}\NormalTok{x.t }\SpecialCharTok{+}\NormalTok{ sigma}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{  x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(x,x.t)\}}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{15}\NormalTok{,.}\DecValTok{85}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(x,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}\AttributeTok{main=}\StringTok{"x\_t"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(x}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}\AttributeTok{main=}\StringTok{"x\_t\^{}2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/simQVAR-1} \caption{Simulation of a quadratic processes $x_t$.}\label{fig:simQVAR}
\end{figure}

\end{example}

Another example of nonnegative process is that of the auto-regressive Gamma process \citep{Gourieroux_Jasiak_2006} and its extension \citep{zarg_2017}.

\begin{example}[Autoregressive gamma process, ARG(1)]
\protect\hypertarget{exm:ARG1}{}\label{exm:ARG1}

An ARG process is defined as follows:
\[
\frac{w_{t+1}}{\mu} \sim \gamma(\nu+z_t) \quad \mbox{where} \quad z_t \sim \mathcal{P} \left( \frac{\rho w_t}{\mu} \right),
\]
with \(\nu\), \(\mu\), \(\rho > 0\). (Alternatively \(z_t \sim {\mathcal{P}}(\beta w_t)\), with \(\rho = \beta \mu\).)

Proposition \ref{prp:LTARG} shows that we have \(\varphi_t(u) = \exp[a(u)'w_t+b(u)]\) with
\[
\left\{
\begin{array}{ccc}
a(u) &=&  \dfrac{\rho u}{1-u \mu}\\
b(u) &=& -\nu  
\log(1-u \mu).
\end{array}
\right.
\]

One can simulate ARG processes by using \href{https://jrenne.shinyapps.io/Affine/}{this web-interface} (select the ``ARG'' panel).

It can be shown that:
\[
\left\{
\begin{array}{ccc}
\mathbb{E}(w_{t+1}|\underline{w_t}) &=& \nu \mu + \rho w_t \\
\mathbb{V}ar(w_{t+1}|\underline{w_t}) &=& \nu \mu^2 + 2 \mu \rho w_t.
\end{array}
\right.
\]
and that:
\[
w_{t+1}=\nu\mu+\rho w_t+\varepsilon_{t+1},
\]
where \(\varepsilon_{t+1}\) is a martingale difference \(\Rightarrow\) \(w_{t+1}\) is a weak \(AR(1)\).

\citet{zarg_2017} porpose the extended ARG process and the ARG\(_0\) process. The latter is such that \(\nu = 0\) and \(\beta w_t\) is replaced with \(\alpha + \beta w_t\), i.e.:
\begin{equation}
\frac{w_{t+1}}{\mu} \sim \gamma(z_t),\quad z_t \sim {\mathcal{P}}(\alpha + \beta w_t).\label{eq:ARG0}
\end{equation}
It is easily seen that we then have:
\[
\varphi_t(u) = exp \left[\frac{\beta \mu u}{1-u \mu} w_t + \frac{\alpha \mu u}{1-u \mu}
\right].
\]
The ARG\(_0\) process features a point mass at zero, with conditional probability \(exp(-\alpha - \beta w_t)\). Note that 0 is absorbing if \(\alpha = 0\).

Figure \ref{fig:simARG0} displays the simulated path of an ARG\(_0\) process (since we set \(\nu\) to zero). Note that function \texttt{simul.ARG} is included in the \texttt{TSModels} package.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TSModels)}
\NormalTok{W }\OtherTok{\textless{}{-}} \FunctionTok{simul.ARG}\NormalTok{(}\DecValTok{300}\NormalTok{,}\AttributeTok{mu=}\NormalTok{.}\DecValTok{5}\NormalTok{,}\AttributeTok{nu=}\DecValTok{0}\NormalTok{,}\AttributeTok{rho=}\NormalTok{.}\DecValTok{9}\NormalTok{,}\AttributeTok{alpha=}\NormalTok{.}\DecValTok{1}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(W,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/simARG0-1} \caption{Simulation of an ARG0 processes.}\label{fig:simARG0}
\end{figure}

\end{example}

Certain affine processes are valued in specific sets (e.g., integers). It is the case of compound Poisson proceses:

\begin{example}[Compound Poisson process]
\protect\hypertarget{exm:CompoundPoisson}{}\label{exm:CompoundPoisson}

A compound Poisson process is defined as follows (with \(\gamma > 0\), \(0 < \pi< 1\), and \(\lambda > 0\)):
\[\frac{w_{t+1}}{\gamma} = z_{t+1} + \varepsilon_{t+1},
\]
where \(z_{t+1}\) and \(\varepsilon_{t+1}\) conditionally independent, and where
\(z_{t+1} \sim {\mathcal B} \left(\frac{w_t}{\gamma},\pi\right)\), with \(\varepsilon_{t+1} \sim {\mathcal P}(\lambda)\).

This process is valued in \(\{j \gamma, j \in \mathbb{N}, \gamma \in \mathbb{R}^+\}\) and we have:
\[
\varphi_t(u) = \exp\left\{
\begin{array}{l}
\dfrac{w_t}{\gamma}   \log[\pi
\exp(u\gamma)+1-\pi]-\lambda[1-\exp(u \gamma)]
\end{array}
\right\},
\]
i.e., \(\varphi_t(u) = \exp\left(a(u)w_t+b(u)\right)\) with
\[
\left\{
\begin{array}{ccl}
a(u)&=& \frac{1}{\gamma}   \log[\pi   \exp(u
\gamma)+1-\pi],\\
b(u) &=& -\lambda[1-\exp(u \gamma)].
\end{array}
\right.
\]

We also have: \(w_{t+1} = \pi w_t + \lambda \gamma + \eta_{t+1}\), where \(\eta_{t+1}\) is a
martingale difference.

One can simulate such processes by using \href{https://jrenne.shinyapps.io/Affine/}{this web-interface} (select the ``Compound Poisson'' panel). Figure \ref{fig:simCPoisson} makes use of function \texttt{simul.compound.poisson} (in package \texttt{TSModels}) to simulate a compound Poisson process.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TSModels)}
\NormalTok{W }\OtherTok{\textless{}{-}} \FunctionTok{simul.compound.poisson}\NormalTok{(}\DecValTok{100}\NormalTok{,}\AttributeTok{Gamma=}\NormalTok{.}\DecValTok{5}\NormalTok{,}\AttributeTok{Pi=}\FloatTok{0.5}\NormalTok{,}\AttributeTok{lambda=}\NormalTok{.}\DecValTok{9}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(W,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/simCPoisson-1} \caption{Simulation of a Compound Poisson process.}\label{fig:simCPoisson}
\end{figure}

\end{example}

\hypertarget{SubCarp}{%
\subsection{\texorpdfstring{Car processes of order \(p\)}{Car processes of order p}}\label{SubCarp}}

Let us now define Car processes of order \(p\):

\begin{definition}[Affine process of order p]
\protect\hypertarget{def:Carp}{}\label{def:Carp}A multivariate process \(w_{t+1}\) is affine of order \(p\) {[}or \(Car(p)\){]} if there exist functions \(a_1(.),\dots,a_p(.)\), and \(b(.)\) such that:
\[
\varphi_t(u)=\mathbb{E}_t[\exp(u' w_{t+1})]=\exp[a_1(u)'w_t+\dots+a_p(u)'w_{t+1-p}+b(u)].
\]
\end{definition}

It can be seen that if \(w_t\) is \(Car(p)\), then \(W_t = [w_t', w_{t-1}',\dots,w_{t-p+1}']'\) is \(Car(1)\).\footnote{We have:
  \begin{eqnarray*}
  \mathbb{E}_t[\exp(u'W_{t+1})] &=& \mathbb{E}_t[\exp(u'_1 w_{t+1}+u'_2 w_t+\dots+u'_p w_{t-p+2})] \\
  &=& \exp(u'_2 w_t+\dots+u'_p w_{t-p+2})\mathbb{E}_t[\exp(u'_1 w_{t+1})] \\
  &=& \exp(u'_2 w_t+\dots+u'_p w_{t-p+2}+a'_1(u_1)
  w_t  +\dots+a'_p(u_1)w_{t+1-p}+b(u_1)) \\
  &=& \exp[A(u)'W_t+B(u)],
  \end{eqnarray*}
  with \(A(u)' = [u'_2+a'_1(u_1),\dots,u'_p+a'_{p-1}(u_1), a'_p(u_1)]\) and \(B(u) = b(u_1)\).} Therefore, without loss of generality we can assume \(p = 1\).

The standard Car(\(p\)) processes are auto-regressive processes of order \(p\). These processes satisfy the definition of index affine processes:

\begin{definition}[Univariate index affine process of order p]
Let \(\exp[a(u)w_t+b(u)]\) be the conditional Laplace transform of a univariate affine process of order 1, the process \(w_{t+1}\) is an \emph{index-affine} process of order \(p\) if:
\[
\varphi_t(u)=\mathbb{E}_t[\exp(u w_{t+1})]=\exp[a(u)(\beta_1 w_t+\dots+\beta_p
w_{t+1-p})+b(u)].
\]
\end{definition}

Examples \ref{exm:ARp} and \ref{exm:ARGp} are two examples of index affine processes.

\begin{example}[Gaussian AR(p) process]
\protect\hypertarget{exm:ARp}{}\label{exm:ARp}This example extends Example \ref{exm:GAR1}. Consider a Gaussian AR(p) process \(w_t\); that is:
\[
w_{t+1} = \nu + \varphi_1 w_t +\dots+ \varphi_p w_{t+1-p}+\sigma \varepsilon_{t+1},\quad \varepsilon_{t+1} \sim i.i.d. \mathcal{N}(0,1).
\]
We have:
\[
\varphi_t(u) = \exp \left[ u \rho (\beta_1 w_t+\dots+\beta_p w_{t+1-p})+u\nu + u^2  \frac{\sigma^2}{2}\right]
\]
with \(\varphi_i = \rho \beta_i\).
\end{example}

\begin{example}[ARG(p) process (positive)]
\protect\hypertarget{exm:ARGp}{}\label{exm:ARGp}This example extends Example \ref{exm:ARG1}.
An ARG process of order \(p\) is defined as follows:
\[
\frac{w_{t+1}}{\mu} \sim \gamma(\nu+z_t) \quad \mbox{where} \quad z_t \sim \mathcal{P} \left( \beta_1 w_t+\dots+\beta_p w_{t+1-p} \right),
\]
with \(\nu\), \(\mu\), \(\beta_i > 0\). We have:
\[
\varphi_t(u) = \exp\left[\frac{\rho u}{1-u \mu} (\beta_1 w_t+\dots+\beta_p w_{t+1-p})-\nu  \log(1-u\mu)\right],
\]
Process \(w_t\) admits the following AR(\(p\)) representation:
\[
w_{t+1} = \nu\mu + \varphi_1 w_t +\dots+ \varphi_p w_{t+1-p}+\varepsilon_{t+1},
\]
with \(\varphi_i = \beta_i\mu\) and where \(\varepsilon_{t+1}\) is a martingale difference.
\end{example}

\hypertarget{Markov}{%
\section{Markov chains}\label{Markov}}

In this subsection, we show that the family of affine processes includes (some) regime-switching models. We consider a time-homogeneous Markov chain \(z_t\), valued in the set of columns of \(Id_J\), the identity matrix of dimension \(J \times J\). The transition probabilities are denoted by \(\pi(e_i, e_j)\), with \(\pi(e_i, e_j) = \mathbb{P}(z_{t+1}=e_j | z_t=e_i)\). With these notations:
\[
\mathbb{E}[\exp(v'z_{t+1})|z_t=e_i,\underline{z_{t-1}}] = \sum^J_{j=1} \exp(v'e_j)\pi (e_i, e_j).
\]
Hence, we have:
\[
\varphi_t(v) = \exp[a_z(v)'z_t],
\]
with
\[
a_z(v)= \left[ \begin{array}{c} \log \left(\sum^J_{j=1} \exp(v'e_j)  \pi(e_1,e_j)\right)\\
\vdots\\
\log \left(\sum^J_{j=1} \exp(v'e_j)  \pi(e_J,e_j)\right)
\end{array}\right].
\]
This proves that \(z_t\) is an affine process.

One can simulate a two-regime Markov chain by using \href{https://jrenne.shinyapps.io/Affine/}{this web-interface} (select the ``Markov-Switching'' panel).

\hypertarget{WAR}{%
\section{Wishart autoregressive (WAR) processes}\label{WAR}}

WAR are \emph{matrix processes}, valued in the space of \((L \times L)\) symmetric positive
definite matrices.

\begin{definition}[Wishart autoregressive (WAR) processes]
\protect\hypertarget{def:WAR}{}\label{def:WAR}Let \(W_{t+1}\) be a \(WAR_L(K, M, \Omega)\) process. It is defined by:
\begin{eqnarray}
&&\mathbb{E}[\exp   Tr(\Gamma W_{t+1})|\underline{W_t}] \label{eq:Trace}\\
&=& \exp\left\{Tr[M'\Gamma(Id-2\Omega \Gamma)^{-1}M W_t]  -  \frac{K}{2}   \log [det(Id-2\Omega \Gamma)]\right\}, \nonumber
\end{eqnarray}
where \(\Gamma\) is a symmetric matrix,\footnote{Indeed, \(Tr(\Gamma W_{t+1})\) is equal to:
  \begin{eqnarray*}
  \sum^L_{i=1}(\Gamma W_{t+1})_{ii} = \sum^L_{i=1}  \sum^L_{j=1} \gamma_{ij} W_{t+1,ij} = \sum^L_{i=1} \gamma_{ii} W_{t+1,ii} + \sum^L_{i<j} (\gamma_{ij}+\gamma_{ji}) W_{t+1,ij}.
  \end{eqnarray*}} \(K\) is a positive scalar, \(M\) is a \((L \times L)\) matrix, and \(\Omega\) is a \((L \times L)\) symmetric positive definite matrix.
\end{definition}

If \(K\) is an integer, Proposition \ref{prp:WARAR} (in the appendix) shows that \(W_{t+1}\) can be obtained from:
\begin{eqnarray*}
\left\{
\begin{array}{ccl}
W_{t+1} & =&  \sum^K_{k=1} x_{k,t+1} x'_{k,t+1}\\
&&\\
x_{k,t+1} & =& M x_{k,t} + \varepsilon_{k,t+1},\quad k \in \{1,\dots,K\},
\end{array}
\right.
\end{eqnarray*}
where \(\varepsilon_{k,t+1} \sim i.i.d. \mathcal{N}(0, \Omega)\) (independent across \(k\)'s).
The proposition also shows that we have:
\[
\mathbb{E}(W_{t+1}|\underline{W_t}) = MW_tM'+K \Omega,
\]
i.e.~\(W_t\) follows a matrix weak AR(1) process.

In particular case, where \(L=1\) (univariate case), we have that:
\begin{eqnarray*}
\mathbb{E}[\exp(u W_{t+1})|\underline{W_t}] = \exp\left[
\frac{u m^2}{1-2\omega u}W_t -
\frac{K}{2}   \log(1-2\omega u)\right].
\end{eqnarray*}
Hence, when \(L=1\), the Wishart process boils down to an \(ARG(1)\) process (Example \ref{exm:ARG1}) with \(\rho = m^2\), \(\mu = 2\omega\), \(\nu = \frac{K}{2}\).

\hypertarget{building}{%
\section{Building affine processes}\label{building}}

\hypertarget{stoch}{%
\subsection{Univariate affine processes with stochastic parameters}\label{stoch}}

Some univariate affine processes can be extended if they satisfy certain conditions. Specifically, consider a univariate affine process whose conditional L.T. is of the form:
\begin{equation}
\mathbb{E}_t   \exp(u y_{t+1}) = \exp[a_0(u)y_t+b_0(u)\delta],\label{eq:extaffine}
\end{equation}
where \(\delta = (\delta_1,\dots,\delta_m)' \in \mathcal{D}\). This process can be generalized by making \(\delta\) stochastic (while staying in the affine family). More precisely assume that:
\[
\mathbb{E}[\exp(u y_{t+1})|\underline{y_t}, \underline{z_{t+1}}] = \exp[a_0(u)y_t+b_0(u)'\Lambda z_{t+1}],
\]
where \(\Lambda\) is a \((m\times k)\) matrix, with \(\Lambda z_{t+1} \in \mathcal{D}\). In this case, if:
\[
\mathbb{E}[\exp(v' z_{t+1})|\underline{y_t}, \underline{z_{t}}] = \exp[a_1(v)'z_t+b_1(v)],
\]
then \(w_{t+1} = (y_{t+1}, z'_{t+1})'\) is affine.\footnote{Indeed, we have:
  \begin{eqnarray*}
  &&\mathbb{E}[\exp(u y_{t+1}+v'z_{t+1})|\underline{y_t}, \underline{z_{t}}] \\
  &=& \mathbb{E}\{\exp(v' z_{t+1})\mathbb{E}[\exp(u y_{t+1})|\underline{y_t},
  \underline{z_{t+1}}]|\underline{y_t}, \underline{z_{t}} \} \\
  &=& \mathbb{E}\{\exp[a_0(u) y_{t}+b_0(u)'\Lambda z_{t+1}+v'z_{t+1}]|\underline{y_t},
  \underline{z_{t}} \} \\
  &=& \exp\{ a_0(u) y_{t}+a_1[\Lambda' b_0(u)+v]'z_t+b_1 [\Lambda' b_0(u)+v]\}.
  \end{eqnarray*}}

\begin{example}[Gaussian AR(p)]
\protect\hypertarget{exm:extendedARp}{}\label{exm:extendedARp}

Using the notation of Example \ref{exm:ARp}, it comes that an AR(p) processes satisfies Eq. \eqref{eq:extaffine} with \(b_0(u) = \left(u, \; \frac{u^2}{2}\right)'\) and \(\delta = (\nu,\sigma^2)' \in \mathcal{D}=\mathbb{R} \times \mathbb{R}^+\). In that case, \(\delta\) (the vector of conditional mean and variance) can be replaced by \ldots{}

\begin{itemize}
\tightlist
\item
  \(\left( \begin{array}{l} z_{1,t+1} \\ z_{2,t+1} \end{array} \right)\), where \(z_{1,t+1}\) and \(z_{2,t+1}\) are independent AR(1) (see Example \ref{exm:GAR1}) and ARG(1) (see Example \ref{exm:ARG1}) processes, respectively.
\item
  \(\left( \begin{array}{ll} \lambda'_1 & 0 \\ 0 & \lambda'_2 \end{array} \right)\)\(\left( \begin{array}{l} z_{1,t+1} \\ z_{2,t+1} \end{array} \right)\), where \(z_{1,t+1}\) and \(z_{2,t+1}\) are independent Markov chains.
\item
  \(\left( \begin{array}{l} \lambda'_1 \\ \lambda'_2 \end{array}\right)z_{t+1}\), where \(z_{t+1}\) is a Markov chain.
\end{itemize}

\end{example}

\begin{example}[ARG(p) model]
\protect\hypertarget{exm:ARGp}{}\label{exm:ARGp}\leavevmode

\begin{itemize}
\tightlist
\item
  \(b_0(u)= - \nu \log(1-u\mu)\), \(\delta=\nu\).
\item
  \(\nu\) (\(\ge 0\)) can be specified for instance as a Markov chain or an ARG.
\end{itemize}

\end{example}

\hypertarget{buildingmulti}{%
\subsection{Multivariate affine processes}\label{buildingmulti}}

One can construct multivariate affine processes by employing the so-called recursive approach. Let us illustrate this by considering the bivariate case. (The multivariate generalization is straightforward.) Consider \(w_t = \left(\begin{array}{c} w_{1,t}\\ w_{2,t} \end{array} \right)\),and assume that we have:
\begin{eqnarray*}
&&\mathbb{E}[\exp(u_1 w_{1,t+1}|\underline{w_{1,t}}, \underline{w_{2,t}})]\\
&=& \exp[a_{11}(u_1)w_{1,{\color{red}{t}}}+a_{12}(u_1)w_{2,{\color{red}{t}}}+b_{1}(u_1)],
\end{eqnarray*}
and:
\begin{eqnarray*}
&& \mathbb{E}[\exp(u_2 w_{2,t+1}|\underline{w_{1,t+1}}, \underline{w_{2,t}})]\\
&= & \exp[a_0(u_2)w_{1,{\color{red}{t+1}}}+a_{21}(u_2)w_{1,{\color{red}{t}}}+a_{22}(u_2)w_{2,{\color{red}{t}}}+b_2(u_2)].
\end{eqnarray*}
Then \(w_t\) is an affine process.\footnote{Indeed, we have:
  \begin{eqnarray*}
  && \mathbb{E}[\exp(u_1 w_{1,t+1}+u_2 w_{2,t+1}|\underline{w_{1,t}}, \underline{w_{2,t}})]\\
  &= & \mathbb{E}\{\exp(u_1 w_{1,t+1}) \mathbb{E}[\exp(u_{2}w_{2,t+1})|\underline{w_{1,t+1}}, \underline{w_{2,t}})]|\underline{w_{1,t}}, \underline{w_{2,t}})\} \\
  &= & \mathbb{E}\{\exp[u_1+a_0(u_2)w_{1,t+1}+a_{21}(u_2)w_{1,t} + a_{22}(u_2)w_{2,t}+b_2(u_2)]|\underline{w_{1,t}}, \underline{w_{2,t}})\} \\
  &= & \exp\{a_{11}[u_1+a_0(u_2)]w_{1,t}+a_{12}[u_1+a_0(u_2)]w_{2,t}+b_1[u_1+a_0(u_2)] \\
  &&+  a_{21}(u_2)w_{1,t}+a_{22}(u_2)w_{2,t}+b_2(u_2)\}.
  \end{eqnarray*}}
The dynamics of the two components of \(w_t\) are of the form:
\begin{eqnarray*}
w_{1,t+1} &=& \alpha_1 \hspace{1.55cm} + \alpha_{11}w_{1,t} + \alpha_{12}w_{2,t} + \varepsilon_{1,t+1} \\
w_{2,t+1} &=& \alpha_2 + \alpha_{0}w_{1,t+1} + \alpha_{21}w_{1,t} + \alpha _{22} w_{2,t} + \varepsilon_{2,t+1}
\end{eqnarray*}
Note that \(\varepsilon_{1,t+1}\) and \(\varepsilon_{2,t+1}\) are non-correlated martingale differences. In the general case, they are conditionally heteroskedastic. What precedes is at play in \(VAR\) model; \citet{zarg_2017} employ this approach to build vector auto-regressive gamma (VARG) processes.

\hypertarget{extending-multivariate-stochastic-processes}{%
\subsection{Extending multivariate stochastic processes}\label{extending-multivariate-stochastic-processes}}

Consider the same framework as in Section \ref{stoch} when \(y_t\) is a \(n\)-dimensional vector. That is, replace Eq. \eqref{eq:extaffine} with:
\begin{equation}
\mathbb{E}_t   \exp(u' y_{t+1}) = \exp[a_0(u)'y_t+b_0(u)\delta],\label{eq:Multiextaffine}
\end{equation}
and further assume that \(\delta\) is stochastic and depends on \(z_t\), such that:
\[
\mathbb{E}[\exp(u y_{t+1})|\underline{y_t}, \underline{z_{t+1}}] = \exp[a_0(u)y_t+b_0(u)'\Lambda z_{t+1}],
\]
where \(\Lambda\) is a \((m\times k)\) matrix, with \(\Lambda z_{t+1} \in \mathcal{D}\). In this case, if:
\[
\mathbb{E}[\exp(v' z_{t+1})|\underline{y_t}, \underline{z_{t}}] = \exp[a_1(v)'z_t+b_1(v)],
\]
then \(w_{t+1} = (y_{t+1}, z'_{t+1})'\) is affine.

\begin{example}[Stochastic parameters Gaussian VAR(1)]
\protect\hypertarget{exm:RSVAR}{}\label{exm:RSVAR}

This example extends Example \ref{exm:GVAR1}. Using the same notations as in the latter example \ref{exm:GVAR1}, we have
\[
b_0(u) = \left(u', \frac{1}{2} (u \otimes u)'\right)' \quad \mbox{and} \quad\delta = (\mu', vec(\Sigma)')' \in \mathbb{R}^n \times vec(\mathcal{S}),
\]
where \(\mathcal{S}\) is the set of symmetric positive semi-definite matrices. Vector \(\delta\) can be replaced by:
\[
\left( \begin{array}{l} z_{1,t+1}
\\ z_{2,t+1}
\end{array} \right),
\]
where

\begin{itemize}
\tightlist
\item
  \(z_{1,t+1}\) is, for instance, a Gaussian VAR process.
\item
  \(z_{2,t+1}\) is
\item
  obtained by applying the \(vec\) operator to a Wishart process,
\item
  replaced by \(\Lambda_2 z_{2,t+1}\), where \(\Lambda_2\) is a \((n^2 \times J)\) matrix whose columns are \(vec(\Sigma_j)\), \(j \in \{1,\dots,J\}\), the \(\Sigma_j\) being \((n \times n)\) positive semi-definite,
\item
  a standardized \(J\)-dimensional VARG process (multivariate extension of Example \ref{exm:ARG1}).
\end{itemize}

\end{example}

\begin{example}[Regime-switching VAR(1)]
\protect\hypertarget{exm:RSVAR2}{}\label{exm:RSVAR2}

One can also use this approach to construct (affine) regime-switching VAR processes (which is another extension of Example \ref{exm:GVAR1}. For that, replace \(\delta\) with

\begin{itemize}
\tightlist
\item
  \(\left( \begin{array}{ll} \Lambda_1 & 0 \\ 0 & \Lambda_2 \end{array} \right)\)\(\left( \begin{array}{l} z_{1,t+1} \\ z_{2,t+1} \end{array} \right)\), where \(\Lambda_1\) is a \((n \times J_1)\) matrix and \(z_{1,t+1}\) is a Markov chain valued in the set of selection vectors of size \(J_1\) (see Subsection \ref{Markov}), \(\Lambda_2\) is the same matrix as in Example \ref{exm:RSVAR} and \(z_{2,t+1}\) is a Markov chain valued in the set of selection vectors of size \(J_2\).
\item
  or \(\left( \begin{array}{l} \Lambda_1 \\ \Lambda_2 \end{array}\right)z_{t+1}\), where \(\Lambda_1\) and\(\Lambda_2\) are the same matrices as above with \(J_1=J_2=J\), and \(z_{t+1}\) is a Markov chain valued in the set of selection vectors of size \(J\).
\end{itemize}

\end{example}

\hypertarget{AffineExtended}{%
\subsection{Extended affine processes}\label{AffineExtended}}

Some processes are not affine, but may be sub-components of an affine process. This can be useful to compute their conditional moments and multi-horizon Laplace transform (as one can use the formulas presented above for that, using the enlarged---affine---vector).

Let us formally define an extended affine process:

\begin{definition}[Extended Affine Processes]
\protect\hypertarget{def:ExtAffine}{}\label{def:ExtAffine}A process \(w_{1,t}\) is extended affine if there exists a process \(w_{2,t} = g(\underline{w_{1,t}})\) such that \((w'_{1,t}, w'_{2,t})'\) is affine (of order 1).
\end{definition}

For an extended affine processes, \(\varphi_{1,t}(u) = \mathbb{E}[\exp(u'w_{1,t+1})|\underline{w_{1,t}}]\) can be obtained from:
\begin{eqnarray*}
\varphi_t(u_1, u_2) &=& \mathbb{E}[\exp(u'_1w_{1,t+1}+u'_2 w_{2,t+1)}|\underline{w_{1,t}}, \underline{w_{2,t}}] \\
&=& \exp[a'_1(u_1,u_2)w_{1,t} + a'_2(u_1,u_2)w_{2,t}+b(u_1,u_2)]
\end{eqnarray*}
by:
\[
\varphi_{1,t}(u) = \varphi_t(u, 0) = \exp[a'_1(u,0)w_{1,t}+a'_2(u,0)g(\underline{w_{1,t}}) + b(u, 0)].
\]
In particular \(w_{1,t}\) may be non-Markovian.

Similarly the multi-horizon Laplace transform (see Section \ref{MHLT})
\[
\mathbb{E}[\exp(\gamma'_{1}w_{1,t+1}+\dots+\gamma'_{h}w_{1,t+h})|\underline{w_{1,t}}]
\]
can be obtained from the knowledge of the extended multi-horizon Laplace transform:
\begin{eqnarray*}
&&\mathbb{E}_t[\exp(\{\gamma'_{1,1}w_{1,t+1}+\gamma'_{2,1}w_{2,t+1}\}+\dots+ \{\gamma'_{1,h}w_{1,t+h}+\gamma'_{2,h}w_{2,t+h}\}] \\
&=& \exp[A'_{1,t,h}(\gamma^h_1, \gamma^h_2)w_{1,t}+A'_{2,t,h}(\gamma^h_1, \gamma^h_2)w_{2,t}+B_{t,h}(\gamma^h_1, \gamma^h_2)],
\end{eqnarray*}
(with \(\gamma^h_1 = (\gamma'_{1,1},\dots, \gamma'_{1,h})'\), and \(\gamma^h_2 = (\gamma'_{2,1},\dots, \gamma'_{2,h})'\)). We indeed have:
\begin{eqnarray*}
&& \mathbb{E}[\exp(\gamma'_{1}w_{1,t+1}+\dots+\gamma'_{h}w_{1,t+h})|\underline{w_{1,t}}]\\
&=& \exp[A'_{1,t,h}(\gamma^h,0) w_{1,t} + A'_{2,t,h}(\gamma^h,0)g (\underline{w_{1,t}}) + B_{t,h}(\gamma^h,0)],
\end{eqnarray*}
with \(\gamma^h = (\gamma_1',\dots,\gamma_h')'\).

\begin{example}[Affine process of order p]
\protect\hypertarget{exm:AffProcessOrderp}{}\label{exm:AffProcessOrderp}If \(\{w_{1,t}\}\) is affine or order \(p>1\), then \((w_{1,t},\dots,w_{1,t-p+1})\) is affine of order 1, but \(\{w_{1,t}\}\) is not affine. That is, in that case, \(w_{2,t} = (w'_{1,t-1}, \dots.w'_{1,t-p+1})'\).

This a kind of extreme case since \(w_{2,t}\) belongs to the information at \(t-1\), which implies \(a_2(u_1, u_2) = u_2\).
\end{example}

\begin{example}[Gaussian ARMA process]
\protect\hypertarget{exm:GaussianARMA}{}\label{exm:GaussianARMA}Consider an \(ARMA(1,1)\) process
\[
w_{1,t} - \varphi w_{1,t-1} = \varepsilon_t-\theta \varepsilon_{t-1},
\]
with \(|\varphi | < 1\), \(|\theta| < 1\), and \(\varepsilon_t \sim i.i.d. \mathcal{N}(0, \sigma^2)\).

\(w_{1,t}\) is not Markovian. Now, take \(w_{2,t} = \varepsilon_t = (1-\theta L)^{-1}(1-\varphi L)w_{1,t}\). We have:
\[
\left(
\begin{array}{l}
w_{1,t+1} \\
w_{2,t+1}
\end{array}
\right) =
\left(
\begin{array}{ll}
\varphi & -\theta \\
0 &      0
\end{array}
\right)
\left(
\begin{array}{l}
w_{1,t} \\
w_{2,t}
\end{array}
\right) +
\left(
\begin{array}{l}
1 \\
1
\end{array}
\right) \varepsilon_{t+1}.
\]
Hence \((w_{1,t}, w_{2,t})'\) is Gaussian \(VAR(1)\), and, therefore, it is affine of order 1.

This is easily extended to \(ARMA(p,q)\) and \(VARMA(p,q)\) processes.
\end{example}

\begin{example}[GARCH type process]
\protect\hypertarget{exm:GARCH}{}\label{exm:GARCH}Consider process \(w_{1,t}\), defined by:
\[
w_{1,t+1}  = \mu + \varphi w_{1,t} + \sigma_{t+1} \varepsilon_{t+1},
\]
where \(|\varphi| < 1\) and \(\varepsilon_t \sim i.i.d. \mathcal{N}(0,1)\), and
\[
\sigma^2_{t+1} = \omega + \alpha \varepsilon^2_t + \beta \sigma^2_t,
\]
where \(0 < \beta < 1\).

Consider \(w_{2,t} = \sigma^2_{t+1}\) (which is a non-linear function of \(\underline{w_{1,t}}\)). Proposition \ref{prp:GARCH} shows that:
\begin{eqnarray*}
&& \mathbb{E}\left[\exp(u_1 w_{1,t+1} + u_2 w_{2,t+1})|\underline{w_{1,t}}\right] \\
&=& \exp\left[u_1 \mu + u_2 \omega - \frac{1}{2}   \log(1-2 u_2 \alpha) \right. \\
&&\left. +  u_1 \varphi w_{1,t} + (u_2\beta +  \frac{u^2_1}{2(1-2u_2\alpha)}) w_{2,t}\right],
\end{eqnarray*}
which is exponential affine in \((w_{1,t}, w_{2,t})\).
\end{example}

\hypertarget{MHLT}{%
\section{Multi-horizon Laplace transform}\label{MHLT}}

\hypertarget{recursive-computation-and-direct-pricing-implications}{%
\subsection{Recursive computation and direct pricing implications}\label{recursive-computation-and-direct-pricing-implications}}

In this subsection, we show that multi-horizon Laplace transforms of affine processes can be calculated recursively. Various examples will show how this can be exploited to price long-dated financial instruments.

Let us consider a multivariate process \(w_{t}\), affine of order one. (As explained in Subsection \ref{SubCarp}, this includes the case of the order \(p\) case.) For the sake of generality, we consider the case where functions \(a(.)\), \(b(.)\) are possibly deterministic functions of time, denoted in this case \(a_{t+1}(.)\) and \(b_{t+1}(.)\):
\[
\mathbb{E}_t \exp[(u'w_{t+1})] = \exp[a'_{t+1}(u)w_t+b_{t+1}(u)].
\]
The multi-horizon Laplace transform of associated with date \(t\) and horizon \(h\) is defined by:
\begin{equation}
\varphi_{t,h}(\gamma_1,\dots,\gamma_h) = \mathbb{E}_t[\exp(\gamma'_1w_{t+1}+\dots+\gamma'_h w_{t+h})].\label{eq:multiLT}
\end{equation}

Lemma \ref{lem:MHLT} (in the appendix) shows that we have:
\[
\varphi_{t,h}(\gamma_1,\dots,\gamma_h) = \exp(A'_{t,h} w_t + B_{t,h}),
\]
where \(A_{t,h} = A^h_{t,h}\) and \(B_{t,h} = B^h_{t,h}\), the \(A^h_{t,i}, B^h_{t,i}\) \(i = 1,\dots,h\), being given recursively by:
\[
\left\{
\begin{array}{ccl}
A^h_{t,i} &=& a_{t+h+1-i}(\gamma_{h+1-i} + A^h_{t,i-1}), \\
B^h_{t,i} &=& b_{t+h+1-i}(\gamma_{h+1-i} + A^h_{t,i-1}) + B^h_{t,i-1}, \\
A^h_{t,0} &=& 0, B^h_{t,0} = 0.
\end{array}
\right.
\]

If the functions \(a_{t}\) and \(b_{t}\) do not depend on \(t\), these recursive formulas do not depend on \(t\), and we get \(\varphi_{t,h}(\gamma_1,\dots,\gamma_h)\), for any \(t\), with only one recursion for each \(h\).

Moreover, if the functions \(a_{t}\) and \(b_{t}\) do not depend on \(t\), and if different sequences \((\gamma^h_1,\dots,\gamma^h_h), h=1,\dots,H\) (say) satisfy \(\gamma^h_{h+1-i} = u_i\), for
\(i=1,\dots,h\), and for any \(h \leq H\), that is if we want to compute (\emph{reverse-order} case):
\begin{equation}
\varphi_{t,h}(u_h,\dots,u_1)=\mathbb{E}_t[\exp(u'_{{\color{red}h}} w_{{\color{red}t+1}}+\dots+u'_{{\color{red}1}} w_{{\color{red}t+h}})],
\quad h=1,\dots,H,\label{eq:LTreverse}
\end{equation}
then Proposition \ref{prp:reverseMLT} (in the appendix) shows that we can compute the \(\varphi_{t,h}(u_h,\dots,u_1)\) for any \(t\) and any \(h \leq H\) with only one recursion. That is \(\varphi_{t,h}(u_h,\dots,u_1)=\exp(A'_hw_t+B_h)\) with:
\begin{equation*}
\left\{
\begin{array}{ccl}
A_{h} &=& a(u_{h} + A_{h-1}), \\
B_{h} &=& b(u_{h} + A_{h-1}) + B_{h-1}, \\
A_{0} &=& 0,\quad  B_{0} = 0.
\end{array}
\right.
\end{equation*}

As mentioned above, what precedes has useful implications to price long-dated financial instruments such as nominal and real bonds (Examples \ref{exm:nominalBth} and \ref{exm:realBth}, respectively), or futures (Example \ref{exm:Futures}).

\begin{example}[Nominal interest rates]
\protect\hypertarget{exm:nominalBth}{}\label{exm:nominalBth}Let \(B(t,h)\) denote the date-\(t\) price of a nominal zero-coupon bond of maturity \(h\). We Have:
\begin{equation}
B(t,h) = \mathbb{E}^{\mathbb{Q}}_t exp (-r_{t}-\dots-r_{t+h-1}),\label{eq:stdbond}
\end{equation}
where \(r_{t}\) is the nominal short rate between \(t\) and \(t+1\) (observed at \(t\)), and the associated (continuously-compounded) yield-to-maturity is given by:
\begin{equation}
R(t,h) = -  \frac{1}{h}   \log   B(t,h), \quad   h=1,\dots,H.
\end{equation}
If \(r_t = \omega'w_t\) (say), then:
\[
B(t,h) = \exp(-r_{t}) \mathbb{E}^{\mathbb{Q}}_t \exp(-\omega' w_{t+1} - \dots - \omega' w_{t+h-1}).
\]
One can then price this bond by directly employing Eq. \eqref{eq:LTreverse}, with \(u_1 = 0\) and \(u_i = - \omega\), \(i = 2,\dots, H\).
The price \(B(t,h)\) is exponential affine in \(w_t\), the associated yield-to-maturity \(R(t,h)=-1/h\log B(t,h)\) is affine in \(w_t\).
\end{example}

\begin{example}[No-arbitrage Nelson-Siegel model]
\protect\hypertarget{exm:CDR2009}{}\label{exm:CDR2009}

In this example, we employ the results of Example \ref{exm:nominalBth} in the context described by \citet{Christensen_Diebold_Rudebusch_2009}. Specifically, we consider a three factor model following a Gaussian VAR (see Example \ref{exm:GVAR1}):
\[
w_t = \left[\begin{array}{c}X_{1,t}\\X_{2,t}\\X_{3,t}\end{array}\right] = 
\left[\begin{array}{ccc}
1 & 0 & 0\\
0&1-\lambda&\lambda\\
0&0&1-\lambda\end{array}\right]
\left[\begin{array}{c}X_{1,t-1}\\X_{2,t-1}\\X_{2,t-1}\end{array}\right] +
\left[\begin{array}{ccc}
\sigma_{11} & 0 & 0\\
\sigma_{21}&\sigma_{22}&0\\
\sigma_{31}&\sigma_{32}&\sigma_{33}\end{array}\right]
\left[\begin{array}{c}\varepsilon_{1,t}\\\varepsilon_{2,t}\\\varepsilon_{3,t}\end{array}\right],
\]
where \(\left[\begin{array}{c}\varepsilon_{1,t}\\\varepsilon_{2,t}\\\varepsilon_{3,t}\end{array}\right] \sim \,i.i.d.\, \mathcal{N}(0,Id)\).

The nominal short-term rate is given by \(r_t = X_{1,t}+X_{2,t}\). In that case, we can use the results of Example \ref{exm:nominalBth} with \(\omega = (-1,-1,0)'\). The following lines of code do that:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TSModels)}
\NormalTok{lambda }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{05}
\NormalTok{Phi }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{lambda,}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{lambda));Phi[}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ lambda}
\NormalTok{Sigma }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{0005} \SpecialCharTok{*} \FunctionTok{diag}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{psi.parameterization}\OtherTok{=}\FunctionTok{list}\NormalTok{(}\AttributeTok{mu=}\FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{),}\AttributeTok{Phi=}\NormalTok{Phi,}\AttributeTok{Sigma=}\NormalTok{Sigma)}
\NormalTok{u1 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{u2 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{),}\AttributeTok{ncol=}\DecValTok{1}\NormalTok{)}
\NormalTok{H }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{AB }\OtherTok{\textless{}{-}} \FunctionTok{reverse.MHLT}\NormalTok{(psi.GaussianVAR,}\AttributeTok{u1 =}\NormalTok{ u1,}\AttributeTok{u2 =}\NormalTok{ u2,}\AttributeTok{H =}\NormalTok{ H,}
                   \AttributeTok{psi.parameterization =}\NormalTok{ psi.parameterization)}
\NormalTok{AB}\SpecialCharTok{$}\NormalTok{A[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,,] }\OtherTok{\textless{}{-}}\NormalTok{ AB}\SpecialCharTok{$}\NormalTok{A[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,,] }\SpecialCharTok{{-}} \DecValTok{1} \CommentTok{\# add terms corresponding to exp({-}r\_t)}
\NormalTok{a.yield }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{ AB}\SpecialCharTok{$}\NormalTok{A }\SpecialCharTok{/} \FunctionTok{array}\NormalTok{((}\DecValTok{1}\SpecialCharTok{:}\NormalTok{H) }\SpecialCharTok{\%x\%} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,H))}
\NormalTok{b.yield }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{ AB}\SpecialCharTok{$}\NormalTok{B }\SpecialCharTok{/} \FunctionTok{array}\NormalTok{((}\DecValTok{1}\SpecialCharTok{:}\NormalTok{H) }\SpecialCharTok{\%x\%} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,H))}
\FunctionTok{plot}\NormalTok{(a.yield[}\DecValTok{1}\NormalTok{,,],}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{),}
     \AttributeTok{xlab=}\StringTok{"Maturity"}\NormalTok{,}\AttributeTok{ylab=}\StringTok{"Factor loadings"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(a.yield[}\DecValTok{2}\NormalTok{,,],}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lty=}\DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(a.yield[}\DecValTok{3}\NormalTok{,,],}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lty=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/CDR-1} \caption{Factor loadings in the context of a no-arbitrage nelson-Siegel model (Christensen, Diebold and Rudebusch, 2009). The first factor (black solid line) is a level factor. The second and third factors (red dashed line and blue dotted line, respectively) are slope factors.}\label{fig:CDR}
\end{figure}

\end{example}

In the previous example, note the use of function \texttt{reverse.MHLT} (in package \texttt{TSModels}), that notably takes a L.T. as an argument (\texttt{psi}). In the previous example, we consider a Gaussian VAR, and we therefore assign \texttt{psi.GaussianVAR} to \texttt{psi}. We then need to provide function \texttt{reverse.MHLT} with the arguments of the \texttt{psi} function. These arguments are provided in the form of a list (input \texttt{psi.parameterization}).

\begin{example}[Real interest rates]
\protect\hypertarget{exm:realBth}{}\label{exm:realBth}Denote by \(q_t\) the price index on date \(t\) and by \(\pi_{t+1} = \log \dfrac{q_{t+1}}{q_t}\) the inflation rate on date \(t+1\). We have:
\begin{eqnarray*}
\bar{R}(t,h) & =& -   \frac{1}{h}   \log   \bar{B}(t,h), \quad h=1,\dots,H \\    \\
\bar{B}(t,h) & =&  \mathbb{E}^{\mathbb{Q}}_t   \exp(-r_{t}-\dots-r_{t+h-1} + \pi_{t+1}+\dots+\pi_{t+h}),  \\      \\
& =& \exp(-r_{t}) \times \\
&& \mathbb{E}^{\mathbb{Q}}_t \exp(-r_{t+1}-\dots-r_{t+h-1}+\pi_{t+1}+\dots+\pi_{t+h})
\end{eqnarray*}
If \(r_t = \omega'w_t\) and \(\pi_t = \bar\omega'w_t\), then \(\bar{B}(t,h)\) is given by:
\begin{eqnarray*}
\exp(-r_{t}) \mathbb{E}^{\mathbb{Q}}_t exp[(\bar\omega-\omega)'w_{t+1}+\dots+(\bar\omega-\omega)'w_{t+h-1}+\bar\omega'
w_{t+h}]
\end{eqnarray*}
One can then price this bond by directly employing Eq. \eqref{eq:LTreverse}, with \(u_1 = \bar\omega\) and \(u_i = \bar\omega-\omega\), \(i = 2,\dots, H\).
\end{example}

\begin{example}[Futures]
\protect\hypertarget{exm:Futures}{}\label{exm:Futures}

Denote by \(F(t,h)\) the date-\(t\) price of a future of maturity \(h\) (see Section XXX). That is \(F(t,h) = \mathbb{E}^{\mathbb{Q}}_t (S_{t+h})\), \(h=1,\dots,H\), where \(S_t\) is the date-\(t\) price of the underlying asset.

\begin{itemize}
\item
  If \(w_t = (\log S_t, x'_t)'\) then \(F(t,h) = \mathbb{E}^{\mathbb{Q}}_t \exp(e'_1 w_{t+h})\). This can be calculated by using Eq. \eqref{eq:LTreverse} with \(u_1 = e_1\), and \(u_i = 0\), for \(i=2,\dots,H\).
\item
  If \(w_t = (y_t, x'_t)'\) with \(y_t = \log\frac{S_t}{S_{t-1}}\), then \(F(t,h) = S_t \mathbb{E}^{\mathbb{Q}}_t \exp(e'_1 w_{t+1}+\dots+e'_1 w_{t+h})\). This can be calculated by using Eq. \eqref{eq:LTreverse} with \(u_i = e'_1\), \(i=1,\dots,H\).
\end{itemize}

\end{example}

\hypertarget{ExponentialPayoff}{%
\subsection{Exponential payoff}\label{ExponentialPayoff}}

Consider an asset providing the payoff \(\exp(\nu' w_{t+h})\) on date \(t+h\). Its price is given by:
\[
P(t,h;\nu) = \mathbb{E}^{\mathbb{Q}}_t[\exp(-r_{t}-\dots-r_{t+h-1}) \exp(\nu' w_{t+h})].
\]
If \(r_t = \omega'w_t\), we have:
\[
P(t,h;\nu) = \exp(-r_{t})\mathbb{E}^{\mathbb{Q}}_t \left(exp[-\omega' w_{t+1}-\dots-\omega' w_{t+h-1}+ \nu' w_{t+h}]\right),
\]
which can be calculated by Eq. \eqref{eq:LTreverse}, with \(u_1 = \nu\) and \(u_i = -\omega\) for \(i = 2,\dots,H\).

What precedes can be extended to the case where the payoff (settled on date \(t+h\)) is of the form:
\[
(\nu_1'w_{t+h}) \exp(\nu_2' w_{t+h}).
\]
Indeed, we have
\[
\left[\frac{\partial \exp[(s \nu_1+ \nu_2)'w_{t+h}]}{\partial s}\right]_{s=0} = (\nu_1'w_{t+h}) \exp(\nu_2' w_{t+h}).
\]
Therefore:
\begin{eqnarray}
&&\mathbb{E}_t^{\mathbb{Q}}[\exp(-r_t - \dots - r_{t+h-1})(\nu_1'w_{t+h}) \exp(\nu_2' w_{t+h})] \nonumber\\
&=& \left[
\frac{\partial P(t,h;s \nu_1 + \nu_2)}{\partial s}
\right]_{s=0}.\label{eq:Affineexppayoff}
\end{eqnarray}
This method is easily extended to price payoffs of the form \((\nu_1'w_{t+h})^k \exp(\nu_2' w_{t+h})\), with \(k \in \mathbb{N}\).

\hypertarget{var-representation-and-conditional-moments}{%
\section{VAR representation and conditional moments}\label{var-representation-and-conditional-moments}}

An important property of affine processes is that their dynamics can be written as a vector-autoregressive process. This is useful to compute conditional moments of the process.

\begin{proposition}[VAR representation of an affine process' dynamics]
\protect\hypertarget{prp:affineVAR}{}\label{prp:affineVAR}If \(w_t\) is the affine process whose Laplace transform is defined in Def. \ref{def:Car1}, then its dynamics admits the following vectorial autoregressive representation:
\begin{equation}
w_{t+1} = \mu + \Phi w_{t} + \Sigma^{\frac{1}{2}}(w_t) \varepsilon_{t+1},\label{eq:VARw}
\end{equation}
where \(\varepsilon_{t+1}\) is a difference of martingale sequence whose conditional covariance matrix is the identity matrix and where \(\mu\), \(\Phi\) and \(\Sigma(w_t) = \Sigma^{\frac{1}{2}}(w_t){\Sigma^{\frac{1}{2}}(w_t)}'\) satisfy:
\begin{equation}
\mu =  \left[\frac{\partial }{\partial u}b(u)\right]_{u=0}, \quad \Phi= \left[\frac{\partial }{\partial u}a(u)'\right]_{u=0}\label{eq:MUPHI}
\end{equation}
\begin{equation}
\Sigma(w_t) =  \left[\frac{\partial }{\partial u\partial u'}b(u)\right]_{u=0} + \left[\frac{\partial }{\partial u\partial u'}a(u)'w_t\right]_{u=0}.\label{eq:SigmaWt}
\end{equation}
\end{proposition}

\begin{proof}
When \(w_t\) is affine, its (conditional) cumulant generating function is of the form \(\psi(u)=a(u)'w_t+b(u)\). The result directly follows from the formulas given in Section \ref{AffineLaplace}.
\end{proof}

Proposition \ref{prp:condvarAffine} (in the appendix) shows that the conditional means and variances of \(w_t\) are given by:
\begin{eqnarray}
\mathbb{E}_t(w_{t+h}) &=& (I - \Phi)^{-1}(I - \Phi^h)\mu + \Phi^h w_t \label{eq:condmean}\\
\mathbb{V}ar_t(w_{t+h}) &=& \Sigma(\mathbb{E}_t(w_{t+h-1}))+\Phi \Sigma(\mathbb{E}_t(w_{t+h-2}))\Phi' + \nonumber \\
&& \dots + \Phi^{h-1} \Sigma(w_{t}){\Phi^{h-1}}'. \label{eq:condvar}
\end{eqnarray}
Eq. \eqref{eq:condvar} notably implies that \(\mathbb{V}ar_t(w_{t+h})\) is an affine function of \(w_t\). Indeed \(\Sigma(.)\) is an affine function, and the conditional expectations \(\mathbb{E}_t(w_{t+h})\) are affine in \(w_t\), as shown by Eq. \eqref{eq:condmean}.

The unconditional means and variances are given by:
\begin{equation}
\left\{
\begin{array}{ccl}
\mathbb{E}(w_t) &=& (I - \Phi)^{-1}\mu\\
vec[\mathbb{V}ar(w_t)] &=& (I_{n^2} - \Phi \otimes \Phi)^{-1} vec\left(\Sigma[(I - \Phi)^{-1}\mu]\right).
\end{array}
\right.\label{eq:uncondmeanvar}
\end{equation}

\hypertarget{TransfAna}{%
\section{Truncated Laplace transforms of affine processes}\label{TransfAna}}

In this section, we show how one can employ Fourier transforms to compute truncated conditional moments of affine processes. For that, let us introduce the following notation:
\[
w_{t+1,T} = (w'_{t+1}, w'_{t+2},\dots, w'_T)'
\]
with \(w_t\) affine \(n\)-dimensional process.

We want to compute:
\[
\tilde{\varphi}_t(u ; v, \gamma) = \mathbb{E}_t[\exp(u'w_{t+1,T})\textbf{1}_{\{v'w_{t+1,T}<\gamma\}}].
\]

Consider the complex untruncated conditional Laplace transform:
\[
\varphi_t(z) = \mathbb{E}_t[\exp(z'w_{t+1,T})],\quad  z \in \mathbb{C}^{nT},
\]
computed using the same recursive algorithm as in the real case (see Section \ref{MHLT}).

\citet{Duffie_Pan_Singleton_2000} have shown that we have (see also Proposition \ref{prp:Fourier} in the appendix):
\begin{equation}
\tilde{\varphi}_t(u ; v, \gamma) =  \frac{\varphi_t(u)}{2} - \frac{1}{\pi}
\int^\infty_0 \frac{Im[\varphi_t(u+ivx) \exp(-i\gamma x)]}{x} dx.\label{eq:DPS}
\end{equation}
where \(Im\) means imaginary part.

Note that the integral in Eq. \eqref{eq:DPS} is one dimensional (whatever the dimension of \(w_t\)). As shown in the following example, this can be exploited to price options.

\begin{example}[Option pricing]
\protect\hypertarget{exm:OptionPricing}{}\label{exm:OptionPricing}Pricing calls and puts amounts to conditional expectations of the type (with \(k > 0\)):
\begin{eqnarray*}
&& \mathbb{E}_t\left([\exp(u'_1 w_{t+1,T})-k   \exp(u'_2 w_{t+1,T})]^+\right) \\
&= &  \mathbb{E}_t\left([\exp(u'_1 w_{t+1,T})-k   \exp(u'_2 w_{t+1,T})]\textbf{1}_{\{[\exp(u_1-u_2)'w_{t+1,T}] > k \}}\right) \\
&= & \tilde{\varphi}_t(u_1 ; u_2-u_1, - \log   k) - k \tilde{\varphi}_t(u_2 ; u_2-u_1, - \log   k).
\end{eqnarray*}
\end{example}

\begin{example}[Exogenous short rate]
\protect\hypertarget{exm:ExogSTR}{}\label{exm:ExogSTR}Consider an asset whose date-\(t\) price is \(p_t\). Denote its geometric asset return by \(y_t\), i.e., \(y_t = \log(p_t/p_{t-1})\). Consider an option written on this asset, with a strike equal \(k p_t\).

If interest rates are deterministic, the option price, for a maturity \(h\), is given by:
\[
p_t   \exp(-r_{t}-\dots-r_{t+h-1}) \mathbb{E}^{\mathbb{Q}}_t[\exp   u'_1 w_{t+1, t+h} - k]^+
\]
with \(u_1 = e \otimes e_1\), where \(e\) is the \(h\)-dimensional vector with components equal to 1, and \(e_1\) is the \(n\)-vector selecting the 1st component (\(y_t\) being the 1st component of \(w_t\), say).
\end{example}

\begin{example}[Endogenous short rate]
\protect\hypertarget{exm:EndogSTR}{}\label{exm:EndogSTR}Consider the same context as in Example \ref{exm:ExogSTR}, but with a stochastic (endogenous) short-term rate. For instance, assume that \(r_{t+1} = \omega_0 + \omega'_1 w_t\). The option price then is:
\begin{eqnarray*}
&& p_t \mathbb{E}^{\mathbb{Q}}_t  \left[ \exp(-\omega_0 - \omega'_1 w_t-\dots- \omega_0 - \omega'_1 w_{t+h-1}) [\exp(u'_1 w_{t+1,t+h})-k]^+ \right]\\
&= & p_t   \exp(-h \omega_0 - \omega'_1 w_t)\mathbb{E}^{\mathbb{Q}}_t\left(\left[\exp(\tilde{u}'_1w_{t+1,t+h})-k   \exp(u_2 w_{t+1, t+h})\right]^+\right),
\end{eqnarray*}
with \(\tilde{u}'_1 = u_1 + u_2\), {[}\(u_1 = e \otimes e_1\) as before{]}, and \(u_2 = (-\omega'_1,\dots, -\omega'_1, 0)'\).
\end{example}

\begin{example}[Numerical example: Conditional cumulated distribution function (c.d.f.)]
\protect\hypertarget{exm:truncatedR}{}\label{exm:truncatedR}

Let us use the model used in Example \ref{exm:CDR2009}. Suppose we want to compute the conditional distribution of the average interest rate over the next \(H\) periods, i.e., \(\frac{1}{H}(r_{t+1}+\dots+r_{t+H})\). Hence, we want to compute \(\mathbb{E}_t[\textbf{1}_{\{v'w_{t+1,T}<\gamma\}}]\) with \(v'w_{t+1,T}=\frac{1}{H}(r_{t+1}+\dots+r_{t+H})\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{H  }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{X  }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{,.}\DecValTok{02}\NormalTok{,}\DecValTok{0}\NormalTok{),}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{x  }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\AttributeTok{length.out=}\DecValTok{1000}\NormalTok{))}
\NormalTok{u1 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{H,}\DecValTok{1}\SpecialCharTok{/}\NormalTok{H,}\DecValTok{0}\NormalTok{),}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%*\%} \FunctionTok{matrix}\NormalTok{(1i}\SpecialCharTok{*}\NormalTok{x,}\AttributeTok{nrow=}\DecValTok{1}\NormalTok{);u2 }\OtherTok{\textless{}{-}}\NormalTok{ u1}
\NormalTok{AB }\OtherTok{\textless{}{-}} \FunctionTok{reverse.MHLT}\NormalTok{(psi.GaussianVAR,}\AttributeTok{u1 =}\NormalTok{ u1,}\AttributeTok{u2 =}\NormalTok{ u2,}\AttributeTok{H =}\NormalTok{ H,}
                   \AttributeTok{psi.parameterization =}\NormalTok{ psi.parameterization)}
\NormalTok{s1 }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{exp}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ AB}\SpecialCharTok{$}\NormalTok{A[,,H] }\SpecialCharTok{+}\NormalTok{ AB}\SpecialCharTok{$}\NormalTok{B[,,H]),}\AttributeTok{ncol=}\DecValTok{1}\NormalTok{)}
\NormalTok{dx }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(x}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,x[}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(x)}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]),}\FunctionTok{length}\NormalTok{(x),}\DecValTok{1}\NormalTok{)}
\NormalTok{gamma }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{.}\DecValTok{2}\NormalTok{,.}\DecValTok{3}\NormalTok{,}\AttributeTok{length.out=}\DecValTok{1000}\NormalTok{)}
\NormalTok{fx }\OtherTok{\textless{}{-}} \FunctionTok{outer}\NormalTok{(x,gamma,}\ControlFlowTok{function}\NormalTok{(r,c)\{}\FunctionTok{Im}\NormalTok{(s1[,}\DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{1i}\SpecialCharTok{*}\NormalTok{r}\SpecialCharTok{*}\NormalTok{c))}\SpecialCharTok{/}\NormalTok{r\})}\SpecialCharTok{*}\NormalTok{dx[,}\DecValTok{1}\NormalTok{]}
\NormalTok{f  }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\DecValTok{2} \SpecialCharTok{{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{pi }\SpecialCharTok{*} \FunctionTok{apply}\NormalTok{(fx,}\DecValTok{2}\NormalTok{,sum)}
\FunctionTok{plot}\NormalTok{(gamma,f,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics{TSM_files/figure-latex/truncatedRR-1} \caption{Conditional cumulated distribution function (c.d.f.) of $\frac{1}{H}(r_{t+1}+\dots+r_{t+H})$.}\label{fig:truncatedRR}
\end{figure}

\end{example}

\hypertarget{appendices}{%
\section{Appendices}\label{appendices}}

\begin{lemma}
\protect\hypertarget{lem:integralQuadratic}{}\label{lem:integralQuadratic}If \(\mu \in \mathbb{R}^L\) and \(Q\) is a \((L \times L)\) matrix symmetric positive definite, then:
\[
\int_{\mathbb{R}^{L}} \exp(-u'Q u + \mu'u)du =
\frac{\pi^{L/2}}{(det   Q)^{1/2}} exp \left(
\begin{array}{l}  \frac{1}{4} \mu'Q^{-1}\mu \end{array} \right).
\]
\end{lemma}

\begin{proof}
The integral is:
\begin{eqnarray*}
&& \int_{\mathbb{R}^{L}} exp \left[ \begin{array}{l} - (u -
\frac{1}{2}  Q^{-1} \mu)'  Q (u -
\frac{1}{2} Q^{-1} \mu)'
\end{array}
\right] exp\left(
\begin{array}{l}  \frac{1}{4} \mu'Q^{-1}\mu \end{array}
\right)du \\
&=&  \frac{\pi^{L/2}}{(det Q)^{1/2}} exp\left(
\begin{array}{l}  \frac{1}{4} \mu'Q^{-1}\mu \end{array}
\right)
\end{eqnarray*}
{[}using the formula for the unit mass of \(\mathcal{N}( 0.5Q^{-1}\mu,(2Q)^{-1})\){]}.
\end{proof}

\begin{lemma}
\protect\hypertarget{lem:Quadr}{}\label{lem:Quadr}If \(\varepsilon_{t+1} \sim \mathcal{N}(0,Id)\), we have
\[
\mathbb{E}_t \left(\exp[\lambda'\varepsilon_{t+1}+\varepsilon'_{t+1} V \varepsilon_{t+1}]\right) =  \frac{1}{[\det(I-2V)]^{1/2}} \exp\left[
\frac{1}{2} \lambda'(I-2V)^{-1}\lambda
\right].
\]
\end{lemma}

\begin{proof}
We have
\[
\mathbb{E}_t   \exp(\lambda'\varepsilon_{t+1}+\varepsilon'_{t+1}V\varepsilon_{t+1})
=  \frac{1}{(2\pi)^{n/2}}  \int_{\mathbb{R}^{n}} \exp\left[
\begin{array}{l}
-u'\left(
\begin{array}{l}
\frac{1}{2} I-V
\end{array}
\right)u+\lambda'u
\end{array}
\right]du
\]
From Lemma \ref{lem:integralQuadratic}, if \(u\in\mathbb{R}^n\), then
\[
\int_{\mathbb{R}^{n}} \exp(-u' Q u+\mu'u) du =
\frac{\pi^{n/2}}{(\det Q)^{1/2}} \exp\left(
\begin{array}{l}
\frac{1}{4} \mu'Q^{-1}\mu
\end{array}
\right).
\]
Therefore:
\[
\begin{array}{l}
\mathbb{E}_t   \exp(\lambda'\varepsilon_{t+1}+\varepsilon'_{t+1}V\varepsilon_{t+1}) \\
=  \frac{1}{2^{n/2}
\left[
\begin{array}{l}
\det \left(
\begin{array}{l}
\frac{1}{2} I-V
\end{array}
\right)
\end{array}
\right]^{1/2}
}
\exp\left[
\begin{array}{l}
\frac{1}{4}  \lambda'\left(
\begin{array}{l}
\frac{1}{2} I-V
\end{array}
\right)^{-1}\lambda
\end{array}
\right].
\end{array}
\]
\end{proof}

\begin{proposition}[Quadratic Gaussian process]
\protect\hypertarget{prp:QGVAR1}{}\label{prp:QGVAR1}Consider vector \(w_t = (x'_t,vec(x_t x_t')')'\), where \(x_t\) is a \(n\)-dimensional vector following a Gaussian VAR(1), i.e.
\[
x_{t+1}|\underline{w_t} \sim \mathcal{N}(\mu+\Phi x_t, \Sigma).
\]
If \(u = (v,V)\) where \(v \in \mathbb{R}^n\) and \(V\) a square symmetric matrix of size \(n\), we have:
\begin{eqnarray*}
\varphi_t(u) &=& \mathbb{E}_t\big\{\exp\big[(v',vec(V)')\times w_{t+1}\big]\big\} \\
& =& \exp \left\{a_1(v,V)'x_t +vec(a_2(v,V))' vec(x_t'x_t) + b(v,V) \right\},
\end{eqnarray*}
where:
\begin{eqnarray*}
a_2(u) & = & \Phi'V (I_n - 2\Sigma V)^{-1} \Phi \nonumber \\
a_1(u) & = & \Phi'\left[(I_n-2V\Sigma)^{-1}(v+2V\mu)\right] \nonumber \\
b(u) & = & u'(I_n - 2 \Sigma V)^{-1}\left(\mu + \frac{1}{2} \Sigma v\right) +\\
&& \mu'V(I_n - 2 \Sigma V)^{-1}\mu - \frac{1}{2}\log\big|I_n - 2\Sigma V\big|.\label{eq:laplaceZ}
\end{eqnarray*}
\end{proposition}

\begin{proof}
We have:
\begin{eqnarray*}
&&\mathbb{E}_t(\exp(v' x_{t+1} + vec(V)'vec(x_{t+1} x_{t+1}'))) \\
&=& \mathbb{E}_t[\exp(v' (\mu + \Phi x_t + \Sigma^{1/2}\varepsilon_{t+1}) + \\
&& vec(V)'vec((\mu + \Phi x_t + \Sigma^{1/2}\varepsilon_{t+1}) (\mu + \Phi x_t + \Sigma^{1/2}\varepsilon_{t+1})'))] \\
&=& \exp[v' (\mu + \Phi x_t) + vec(V)'vec\{(\mu + \Phi x_t)(\mu + \Phi x_t)'\}] \times \\
&& \mathbb{E}_t[\exp(v'\Sigma^{1/2}\varepsilon_{t+1} +2\underbrace{ vec(V)' vec\{(\mu + \Phi x_t)(\varepsilon_{t+1}'{\Sigma^{1/2}}')\}}_{=(\mu + \Phi x_t)'V\Sigma^{1/2}\varepsilon_{t+1}} +\\
&& \underbrace{vec(V)'vec\{(\Sigma^{1/2}\varepsilon_{t+1})(\Sigma^{1/2}\varepsilon_{t+1})'}_{=\varepsilon_{t+1}'{\Sigma^{1/2}}'V\Sigma^{1/2}\varepsilon_{t+1}}\}]
\end{eqnarray*}
Lemma \ref{lem:Quadr} can be used to compute the previous conditional expectation, with \(\lambda = {\Sigma^{1/2}}'(v + 2 V'(\mu + \Phi x_t))\). Some algebra then leads to the result.
\end{proof}

\begin{proposition}[]
\protect\hypertarget{prp:LTARG}{}\label{prp:LTARG}Consider the following auto-regressive gamma process:
\[
\frac{w_{t+1}}{\mu} \sim \gamma(\nu+z_t) \quad \mbox{where} \quad z_t \sim \mathcal{P} \left( \frac{\rho w_t}{\mu} \right),
\]
with \(\nu\), \(\mu\), \(\rho > 0\). (Alternatively \(z_t \sim {\mathcal{P}}(\beta w_t)\), with \(\rho = \beta \mu\).)

We have:
\(\varphi_t(u) = exp \left[ \begin{array}{l} \dfrac{\rho u}{1-u \mu} w_t - \nu \log(1-u \mu)\end{array} \right], \mbox{ for } u < \dfrac{1}{\mu}\).
\end{proposition}

\begin{proof}
Given \(\underline{w_t}\), we have \(z_t \sim {\mathcal P}\left( \begin{array}{l} \frac{\rho w_t} {\mu} \end{array}\right)\). We have:
\begin{eqnarray*}
\mathbb{E}[\exp(u w_{t+1})|\underline{w_t}] &=& \mathbb{E}\left\{\mathbb{E}\left[\exp \left(u \mu  \frac{w_{t+1}}{\mu}\right)|\underline{w_t}, \underline{z}_t\right]\underline{w_t}\right\}\\
&=& \mathbb{E}[(1-u\mu)^{-(\nu+z_t)}|\underline{w_t}] \\
&=& (1-u\mu)^{-\nu}\mathbb{E}\{\exp[-z_t   \log(1-u\mu)]|\underline{w_t}\} \\
&=& (1-u\mu)^{-\nu} \exp \left\{\frac{\rho w_t}{\mu}[\exp(-\log(1-u\mu)] -  \frac{\rho w_t}{\mu}\right\}\\
&=& \exp\left[ \begin{array}{l}  \frac{\rho u w_t}{1-u\mu} - \nu   \log(1-u\mu)  \end{array}\right],
\end{eqnarray*}
using the fact that the L.T. of \(\gamma(\nu)\) is \((1-u)^{-\nu}\)
and that the L.T. of \({\mathcal P}(\lambda)\) is \(\exp[\lambda(\exp(u)-1)]\).
\end{proof}

\begin{proposition}[Dynamics of a WAR process]
\protect\hypertarget{prp:WARAR}{}\label{prp:WARAR}If \(K\) is an integer, \(W_{t+1}\) can be obtained from:
\begin{eqnarray*}
\left\{
\begin{array}{ccl}
W_{t+1} & =&  \sum^K_{k=1} x_{k,t+1} x'_{k,t+1}\\
&&\\
x_{k,t+1} & =& M x_{k,t} + \varepsilon_{k,t+1},\quad k \in \{1,\dots,K\},
\end{array}
\right.
\end{eqnarray*}
where \(\varepsilon_{k,t+1} \sim i.i.d. \mathcal{N}(0, \Omega)\) (independent across \(k\)'s).
In particular, we have:
\[
\mathbb{E}(W_{t+1}|\underline{W_t}) = MW_tM'+K \Omega,
\]
i.e.~\(W_t\) follows a matrix weak AR(1) process.
\end{proposition}

\begin{proof}
For \(K=1\), \(W_{t+1}=x_{t+1} x'_{t+1}\), \(x_{t+1} = M x_t + \Omega^{1/2} u_{t+1}\) and \(u_{t+1} \sim i.i.d. \mathcal{N}(0,Id_L)\). We have:
\[
\mathbb{E}[\exp(Tr \Gamma W_{t+1})|\underline{w_t}] = \mathbb{E}\{\mathbb{E}[\exp(Tr \Gamma x_{t+1} x'_{t+1})|\underline{x}_t]|\underline{w_t}\}
\]
and:
\begin{eqnarray*}
&& \mathbb{E}[\exp(Tr \Gamma x_{t+1}x'_{t+1})|\underline{x}_t] = \mathbb{E}[\exp(x'_{t+1}\Gamma x_{t+1}|\underline{x}_t] \\
&=& \mathbb{E}[\exp(M x_t + \Omega^{1/2} u_{t+1})'\Gamma(M x_t + \Omega^{1/2} u_{t+1})/x_t] \\
&=& \exp(x'_tM'\Gamma M x_t)\mathbb{E}[\exp(2 x'_t M'\Gamma \Omega^{1/2}
u_{t+1}+u'_{t+1}\Omega^{1/2} \Gamma \Omega^{1/2} u_{t+1})/x_t] \\
&=&  \frac{exp(x'_tM'\Gamma M x_t)}{(2\pi)^{L/2}} \times \\
&& \int_{\mathbb{R}^L} \exp\left[2x'_tM'\Gamma
\Omega^{1/2}u_{t+1}-u'_{t+1}\left(
\frac{1}{2} Id_L-\Omega^{1/2} \Gamma \Omega^{1/2}\right)u_{t+1}\right]  du_{t+1}.
\end{eqnarray*}
Using Lemma \ref{lem:integralQuadratic} with \(\mu' = 2 x'_t M'\Gamma \Omega^{1/2}, Q = \frac{1}{2} Id_L-\Omega^{1/2}\Gamma\Omega^{1/2}\) \textbackslash{}
and after some algebra, the RHS becomes:
\[
\frac{exp[x'_tM'\Gamma(Id_L-2\Omega\Gamma)^{-1}M
x_t]}{det[Id_L-2\Omega^{1/2}\Gamma\Omega^{1/2}]} =  \frac{exp Tr[M'\Gamma(Id_L-2\Omega^{-1}]M
W_t]}{det[Id_L-2\Omega \Gamma]^{1/2}},
\]
which depends on \(x_t\) through \(W_t\), and gives the result for
\(K=1\); the result for any \(K\) integer follows.
\end{proof}

\begin{lemma}
\protect\hypertarget{lem:MHLT}{}\label{lem:MHLT}We have:
\[
\varphi_{t,h}(\gamma_1,\dots,\gamma_h) = \exp(A'_{t,h} w_t + B_{t,h}),
\]
where \(A_{t,h} = A^h_{t,h}\) and \(B_{t,h} = B^h_{t,h}\), the \(A^h_{t,i}, B^h_{t,i}\) \(i = 1,\dots,h\), being given recursively by:
\[
(i) \left\{
\begin{array}{ccl}
A^h_{t,i} &=& a_{t+h+1-i}(\gamma_{h+1-i} + A^h_{t,i-1}), \\
B^h_{t,i} &=& b_{t+h+1-i}(\gamma_{h+1-i} + A^h_{t,i-1}) + B^h_{t,i-1}, \\
A^h_{t,0} &=& 0, B^h_{t,0} = 0.
\end{array}
\right.
\]
\end{lemma}

\begin{proof}
For any \(j=1,\dots,h\) we have:
\[
\varphi_{t,h}(\gamma_1,\dots,\gamma_h) = \mathbb{E}_t[\exp(\gamma'_1 w_{t+1}+\dots\gamma'_j w_{t+j}+A^{h'}_{t,h-j}w_{t+j}+B^h_{t,h-j})]
\]
where:
\[
(ii) \left\{
\begin{array}{l}
A^h_{t,h-j+1} = a_{t+j}(\gamma_{j} + A^h_{t,h-j}), \\
B^h_{t,h-j+1} = b_{t+j}(\gamma_{j} + A^h_{t,h-j}) + B^h_{t,h-j}, \\
A^h_{t,0} = 0, B^h_{t,0} = 0.
\end{array}
\right.
\]
Since this is true for \(j=h\), and if this is true for \(j\), we get:
\[
\begin{array}{ll}
\varphi_{t,h}(\gamma_1,\dots,\gamma_h) & = \mathbb{E}_t [\exp(\gamma'_1 w_{t+1}+\dots+\gamma'_{j-1}w_{t+j-1}+a'_{t+j}(\gamma_j+A^h_{t,h-j})w_{t+j-1} \\
& + b_{t+j}(\gamma_j+A^h_{t,h-j})+B^h_{t,h-j}],
\end{array}
\]
and, therefore, this is true for \(j-1\), with \(A^h_{t,h-j+1}\) and \(B^h_{t,h-j+1}\) given by formulas (ii) above.

For \(j=1\) we get:
\begin{eqnarray*}
\varphi_{t,h}(\gamma_1,\dots,\gamma_h) &=& \mathbb{E}_t \exp(\gamma'_1 w_{t+1}+A^{h'}_{t,h-1}w_{t+1}+B^h_{t,h-1}) \\
&=& \exp(A'_{t,h} w_t+B_{t,h}),
\end{eqnarray*}

Finally note that if we put \(h-j+1 = i\), formulas (ii) become (i).
\end{proof}

\begin{proposition}[Reverse-order multi-horizon Laplace transform]
\protect\hypertarget{prp:reverseMLT}{}\label{prp:reverseMLT}If the functions \(a_{t}\) and \(b_{t}\) do not depend on \(t\), and if different sequences \((\gamma^h_1,\dots,\gamma^h_h), h=1,\dots,H\) (say) satisfy \(\gamma^h_{h+1-i} = u_i\), for
\(i=1,\dots,h\), and for any \(h \leq H\), that is if we want to compute (``reverse order'' case):
\[
\varphi_{t,h}(u_h,\dots,u_1)=\mathbb{E}_t[\exp(u'_{{\color{red}h}} w_{{\color{red}t+1}}+\dots+u'_{{\color{red}1}} w_{{\color{red}t+h}})],
\quad h=1,\dots,H,
\]
then we can compute the \(\varphi_{t,h}(u_h,\dots,u_1)\) for any \(t\) and any \(h \leq H\), with only one recursion, i.e.~\(\varphi_{t,h}(u_h,\dots,u_1)=\exp(A'_hw_t+B_h)\) with:
\begin{equation}
\left\{
\begin{array}{ccl}
A_{h} &=& a(u_{h} + A_{h-1}), \\
B_{h} &=& b(u_{h} + A_{h-1}) + B_{h-1}, \\
A_{0} &=& 0,\quad  B_{0} = 0.
\end{array}
\right.\label{eq:auxLemmareverseMLT}
\end{equation}
\end{proposition}

\begin{proof}
According to Lemma \ref{lem:MHLT}, we have, in this case:
\[
\left\{
\begin{array}{ccl}
A^h_{i} &=& a(u_{i} + A^h_{i-1}), \\
B^h_{i} &=& b(u_{i} + A^h_{i-1}) + B^h_{i-1}, \\
A^h_{0} &=& 0, \quad B^h_{0} = 0.
\end{array}
\right.
\]
The previous sequences do not dependent on \(h\) and are given by Eq. \eqref{eq:auxLemmareverseMLT}.
\end{proof}

\begin{proposition}[Conditional means and variances of an affine process]
\protect\hypertarget{prp:condvarAffine}{}\label{prp:condvarAffine}Consider an affine process \(w_t\). Using the notation of Proposition \ref{prp:affineVAR}, we have:
\begin{eqnarray}
\mathbb{E}_t(w_{t+h}) &=& (I - \Phi)^{-1}(I - \Phi^h)\mu + \Phi^h w_t \label{eq:condmeanAppendix}\\
\mathbb{V}ar_t(w_{t+h}) &=& \Sigma(\mathbb{E}_t(w_{t+h-1}))+\Phi \Sigma(\mathbb{E}_t(w_{t+h-2}))\Phi' + \nonumber \\
&& \dots + \Phi^{h-1} \Sigma(w_{t}){\Phi^{h-1}}'. \label{eq:condvarAppendix}
\end{eqnarray}
Eq. \eqref{eq:condvarAppendix} notably shows that \(\mathbb{V}ar_t(w_{t+h})\) is an affine function of \(w_t\). Indeed \(\Sigma(.)\) is an affine function, and the conditional expectations \(\mathbb{E}_t(w_{t+h})\) are affine in \(w_t\), as shown by Eq. \eqref{eq:condmeanAppendix}.

The unconditional mean and variance of \(w_t\) are given by:
\begin{equation}
\left\{
\begin{array}{ccl}
\mathbb{E}(w_t) &=& (I - \Phi)^{-1}\mu\\
vec[\mathbb{V}ar(w_t)] &=& (I_{n^2} - \Phi \otimes \Phi)^{-1} vec\left(\Sigma[(I - \Phi)^{-1}\mu]\right).
\end{array}
\right.\label{eq:uncondmeanvarAppendix}
\end{equation}
\end{proposition}

\begin{proof}
Eq. \eqref{eq:condmeanAppendix} is easily deduced from Eq. \eqref{eq:VARw}, using that \(\mathbb{E}_t(\varepsilon_{t+k})=0\) for \(k>0\).

As regards Eq. \eqref{eq:condvarAppendix}:
\begin{eqnarray*}
\mathbb{V}ar_t(w_{t+h}) &=& \mathbb{V}ar_t\left(\Sigma(w_{t+h-1})^{\frac{1}{2}}\varepsilon_{t+h}+\dots + \Phi^{h-1} \Sigma(w_{t})^{\frac{1}{2}}\varepsilon_{t+1} \right).
\end{eqnarray*}
The conditional expectation at \(t\) of all the terms of the sum is equal to zero since, for \(i \ge 1\):
\[
\mathbb{E}_t\left[\Sigma(w_{t+i-1})^{\frac{1}{2}}\varepsilon_{t+i}\right] = \mathbb{E}_t[\underbrace{\mathbb{E}_{t+i-1}\{\Sigma(w_{t+i-1})^{\frac{1}{2}}\varepsilon_{t+i}\}}_{=\Sigma(w_{t+i-1})^{\frac{1}{2}}\mathbb{E}_{t+i-1}\{\varepsilon_{t+i}\}=0}\}],
\]
and \(\forall i <j\),
\[
\mathbb{C}ov_t\left[\Sigma(w_{t+i-1})^{\frac{1}{2}}\varepsilon_{t+i},\Sigma(w_{t+j-1})^{\frac{1}{2}}\varepsilon_{t+j}\right] = \mathbb{E}_t\left[\Sigma(w_{t+i-1})^{\frac{1}{2}}\varepsilon_{t+i}\varepsilon_{t+j}'\Sigma'(w_{t+j-1})^{\frac{1}{2}}\right],
\]
which can be seen to be equal to zero by conditioning on the information available on date \(t+j-1\).

Using the same conditioning, we obtain that:
\begin{eqnarray*}
\mathbb{V}ar_t\left[\Phi^{h-j}\Sigma(w_{t+j-1})^{\frac{1}{2}}\varepsilon_{t+j}\right] &=& \mathbb{E}_t\left[\Phi^{h-j}\Sigma(w_{t+j-1})^{\frac{1}{2}}\varepsilon_{t+j}\varepsilon_{t+j}'\Sigma'(w_{t+j-1})^{\frac{1}{2}}{\Phi^{h-j}}'\right] \\
&=&  \mathbb{E}_t\left[\Phi^{h-j}\Sigma(w_{t+j-1})^{\frac{1}{2}} \mathbb{E}_{t+j-1}(\varepsilon_{t+j}\varepsilon_{t+j}')\Sigma'(w_{t+j-1})^{\frac{1}{2}}{\Phi^{h-j}}'\right] \\
&=&  \Phi^{h-j}\mathbb{E}_t[\Sigma(w_{t+j-1})]{\Phi^{h-j}}' \\
&=&  \Phi^{h-j}\Sigma(\mathbb{E}_t[w_{t+j-1}]){\Phi^{h-j}}',
\end{eqnarray*}
where the last equality results from the fact that he fact that \(\Sigma(.)\) is affine (see Eq. \eqref{eq:SigmaWt}).
\end{proof}

\begin{proposition}[Affine property of the GARCH-type process]
\protect\hypertarget{prp:GARCH}{}\label{prp:GARCH}The process \(w_t = (w_{1,t}, w_{2,t})\) defined by:
\[
\left\{
\begin{array}{ccl}
w_{1, t+1} &=& \mu + \varphi w_{1,t} + \sigma_{t+1} \varepsilon_{t+1}    \mid \varphi \mid < 1 \\
\sigma^2_{t+1} &=& \omega + \alpha \varepsilon^2_t + \beta \sigma^2_t      0 < \beta < 1, \alpha > 0, \omega > 0    \\
w_{2,t} &=& \sigma^2_{t+1}, \quad \varepsilon_t \sim   i.i.d.   \mathcal{N}(0,1)
\end{array}
\right.
\]
is affine.
\end{proposition}

\begin{proof}
Note that \(w_{2,t}\) is function of \(\underline{w_{1,t}}\)
\begin{eqnarray*}
&& \mathbb{E}[\exp(u_1 w_{1, t+1} + u_2 w_{2, t+1})|\underline{w_{1,t}}] \\
&= & \exp(u_1 \mu + u_1 \varphi w_{1,t} + u_2 \omega + u_2 \beta w_{2,t})  \mathbb{E}[\exp(u_1 \sigma_{t+1} \varepsilon_{t+1} + u_2 \alpha \varepsilon^2_{t+1})|\underline{w_{1,t}}]
\end{eqnarray*}
and, using Lemma \ref{lem:Quadr}:
\begin{eqnarray*}
&&\mathbb{E}[\exp(u_1 w_{1, t+1} + u_2 w_{2, t+1})|\underline{w_{1,t}}] \\
&= & \exp(u_1 \mu + u_1 \varphi w_{1,t} + u_2 \omega + u_2 \beta w_{2t})  \exp \left[ -   \frac{1}{2}   \log(1-2 u_2 \alpha) +
\frac{u^2_1 w_{2,t}}{2(1-2 u_2 \alpha)} \right]\\
&= & \exp \left[ u_1 \mu + u_2 \omega -  \frac{1}{2}   \log(1-2u_2\alpha)+  u_1 \varphi w_{1,t} + \left(u_2 \beta +  \frac{u^2_1}{2(1-2u_2\alpha)}\right)
w_{2,t}\right],
\end{eqnarray*}
which is exponential affine in \((w_{1,t}, w_{2,t})\).
\end{proof}

\begin{proposition}[Computation of truncated conditional moments]
\protect\hypertarget{prp:Fourier}{}\label{prp:Fourier}If \(\varphi(z)=\mathbb{E}[exp(z'w)]\), we have:
\begin{equation}
\mathbb{E}[\exp(u'w)\textbf{1}_{(v'w<\gamma})] = \frac{\varphi(u)}{2} -  \frac{1}{\pi} \int^\infty_o
\frac{{\mathcal I}m[\varphi(u+ivx)\exp(-i\gamma x)]}{x}dx.\label{eq:Truncated}
\end{equation}
\end{proposition}

\begin{proof}
We want to compute \(\tilde{\varphi}_t(u;v,\gamma) = \mathbb{E}_t[\exp(u'w)\textbf{1}_{(v'w<\gamma})]\). Let us first note that, for given \(u\) and \(v\), \(\tilde{\varphi}_t(u;v,\gamma)\) is a positive increasing bounded function of \(\gamma\) and therefore can be seen as the c.d.f. of a positive finite measure on \(\mathbb{R}\), the Fourier transform of which is:
\[
\int_{\mathbb{R}} \exp(i\gamma x)d\tilde{\varphi}(u;v,\gamma) = \mathbb{E} \int_{\mathbb{R}} \exp(i\gamma x)d\tilde{\varphi}_w(u;v,\gamma),
\]
where, for given \(w, \tilde{\varphi}_w(u;v,\gamma)\) is the c.d.f. of the mass point \(\exp(u'w)\) at \(v'w\). We then get:
\begin{eqnarray*}
\int_{\mathbb{R}} \exp(i\gamma x) d\tilde{\varphi}(u;v,\gamma) &=& \mathbb{E}[\exp(ixv'w)exp(u'w)] \\
& =& \mathbb{E}[\exp(u+ivx)'w] \\
& =& \varphi(u+ivx).
\end{eqnarray*}
Let us now compute \(A(x_0,\lambda)\) for any real number \(\lambda\), with:
\begin{eqnarray*}
&&A(x_0,\lambda) \\
&=&  \frac{1}{2\pi} \int^{x_0}_{-x_0}
\frac{\exp(i\lambda x)\varphi(u-ivx)-\exp(-i\lambda)\varphi(u+ivx)}{ix}dx \\
&=&  \frac{1}{2\pi} \int^{x_0}_{-x_0}\left[ \begin{array}{l}  \int_{\mathbb{R}}
\frac{\exp[-ix(\gamma-\lambda)]-\exp[ix(\gamma-\lambda)]}{ix}d\tilde{\varphi}(u;v,\gamma)
\end{array} \right]dx \\
&=&  \frac{1}{2\pi}  \int_{\mathbb{R}}
\left[ \begin{array}{l}   \int^{x_0}_{-x_0}   \frac{\exp[-ix(\gamma-\lambda)]
-\exp[ix(\gamma-\lambda)]}{ix}dx \end{array} \right]d\tilde{\varphi}(u;v,\gamma).
\end{eqnarray*}
Now :
\begin{eqnarray*}
\frac{1}{2\pi} \int^{x_o}_{-x_o}
\frac{\exp[-ix(\gamma-\lambda)]
-\exp[ix(\gamma-\lambda)]}{ix}dx \\ =  \frac{-sign(\gamma-\lambda)}{\pi}
\int^{x_o}_{-x_o} \frac{sin(x\mid\gamma-\lambda\mid)}{x}dx
\end{eqnarray*}
which tends to \(-sign(\gamma-\lambda)\) when \(x_0\rightarrow\infty\) (where \(sign(\omega)=1\) if \(\omega>0\), \(sign(\omega)=0\) if \(\omega=0\), \(sign(\omega)=-1\) if \(\omega<0\)).
Therefore:
\[
A(\infty,\lambda) = -  \int_{\mathbb{R}} sign(\gamma-\lambda)d\tilde{\varphi}(u;v,\gamma) = -\mathbb{E}  \int_{\mathbb{R}} sign(\gamma-\lambda)d\tilde{\varphi}_w(u;\theta,\gamma),
\]
where \(\tilde{\varphi}_w(u;v,\gamma)\) is the c.d.f. of the mass point \(\exp(u'w)\) at \(v'w\) and
\[
\int_{\mathbb{R}} \mbox{sign}(\gamma-\lambda)d\tilde{\varphi}_w(u;v,\gamma)=
\left\{
\begin{array}{ccc}
\exp(u'w) & \mbox{if} & \lambda < v'w \\
0 & \mbox{if}& \lambda = v'w \\
-\exp(u'w) & \mbox{if} & \lambda > v'w.
\end{array}
\right.
\]
Therefore, we have:
\begin{eqnarray*}
A(\infty,\lambda) & =& - \mathbb{E}[\exp(u'w)(1-\textbf{1}_{(v'w<\lambda)})-\exp(u'w)\textbf{1}_{(v'w<\lambda)}] \\
& =& - \varphi(u) + 2\tilde{\varphi}(u;v,\lambda)
\end{eqnarray*}
and, further,:
\[
\tilde{\varphi}(u;,v,\gamma) =  \frac{\varphi(u)}{2} +  \frac{1}{2} A(\infty,\gamma),
\]
where
\begin{eqnarray*}
\frac{1}{2} A(\infty,\gamma) & =&  \frac{1}{4\pi} \int^{\infty}_{-\infty}  \frac{\exp(i\gamma x)\varphi(u-ivx)-\exp(-i\gamma x)\varphi(u+ivx)}{ix} dx \\
& =&  \frac{1}{2\pi} \int^{\infty}_{o}  \frac{\exp(i\gamma x)\varphi(u-ivx)-\exp(-i\gamma x)\varphi(u+ivx)}{ix} dx \\
& =& -  \frac{1}{\pi} \int^{\infty}_{o}  \frac{{\mathcal I}m[\exp(-i\gamma x)\varphi(u+ivx)]}{x}dx,
\end{eqnarray*}
which leads to Eq. \eqref{eq:Truncated}.
\end{proof}

\hypertarget{pricing-and-risk-neutral-dynamics}{%
\chapter{Pricing and risk-neutral dynamics}\label{pricing-and-risk-neutral-dynamics}}

\begin{quote}
\textbf{\emph{In brief:}} bla bla bla bla.
\end{quote}

\hypertarget{PricingEquilibrium}{%
\section{Consumption-based Capital Asset Pricing Model (CCAPM) and stochastic discount factor (SDF)}\label{PricingEquilibrium}}

Consider an economy featuring a single good, whose date-\(t\) price is \(q_t\). There is a representative agent with an external income \(R_t\) at \(t\), and a portfolio of assets, with an allocation vector \(\alpha_{t-1}\) (decided at \(t-1\)). The vector of date-\(t\) prices is \(p_t\). At any date \(t+j\), \(j=0,1,...\), the agent will face the budget constraint:
\[
q_{t+j}C_{t+j}+\alpha'_{t+j}p_{t+j} = R_{t+j} +
\alpha'_{t+j-1}p_{t+j},
\]
where \(C_{t+j}\)is her consumption on date \(t+j\). The representative agent maximizes her expected utility time-separable preferences \(\mathbb{E}_t \sum^\infty_{j=0} \delta^j U(C_{t+j})\) subject to the budget constraints at \(t+j\), \(j= 0,1,\dots\), where \(U\) is the utility function and \(\delta\)is time discount factor or subjective discount factor. Note that the latter is different from SDF.

Replacing \(C_{t+j}\) with \([R_{t+j}-(\alpha'_{t+j}-\alpha'_{t+j-1})p_{t+j}]/q_{t+j}\), the objective function becomes:
\[
\mathbb{E}_t  \sum^\infty_{j=0} \delta^j U
[R_{t+j}/q_{t+j}-(\alpha'_{t+j}-\alpha'_{t+j-1})p_{t+j}/q_{t+j}].
\]
The vector of allocation \(\alpha_t\) appears in the first two terms:
\[
U[R_t/q_t-(\alpha'_t-\alpha'_{t-1})p_t/q_t] + \delta \mathbb{E}_t
U[R_{t+1}/q_{t+1}-(\alpha'_{t+1}-\alpha'_t)p_{t+1}/q_{t+1}].
\]
As a result, the first order condition associated with vector \(\alpha_t\) reads
\[
\frac{p_t}{q_t}  \frac{d U(C_t)}{dC} = \delta \mathbb{E}_t \left[
\begin{array}{l}
\frac{p_{t+1}}{q_{t+1}}  \frac{dU(C_{t+1})}{dC}
\end{array}
\right],
\]
or
\begin{equation}
p_t = \mathbb{E}_t(p_{t+1} \mathcal{M}_{t,t+1}),\label{eq:SDF100}
\end{equation}
where \(\mathcal{M}_{t,t+1}\) is a strictly positive scalar called \textbf{stochastic discount factor (SDF)} between dates \(t\) and \(t+1\). We have:
\[
\mathcal{M}_{t,t+1} \equiv \delta  \frac{q_t}{q_{t+1}} 
\frac{  \frac{dU(C_{t+1})}{dC}} {
\frac{dU(C_t)}{dC}}.
\]

\begin{example}[Power utility function]
\protect\hypertarget{exm:CCAPM}{}\label{exm:CCAPM}A standard case is the one of the power utility \(U(C) = \frac{C^{1-\gamma}-1}{1-\gamma}\), where \(\gamma>0\) is the coefficient of relative risk aversion.

We have \(U'(C) = C^{-\gamma} > 0\) and \(U''(C) = - \gamma C^{-\gamma-1} < 0\). As a result, the stochastic discount factor is
\begin{eqnarray}
&& \mathcal{M}_{t,t+1} \nonumber \\
&=&  \frac{q_t}{q_{t+1}} \delta \left(
\frac{C_{t+1}}{C_t} \right)^{-\gamma} \nonumber\\
&=& \exp(\log
\delta + \log q_t + \gamma \log  C_t - \log  q_{t+1} - \gamma
\log  C_{t+1}).\label{eq:powerutilSDF}
\end{eqnarray}
The vector of prices \(p_t\) satisfies:
\[
p_t = \delta q_t C^\gamma_t \mathbb{E}_t \left(
\begin{array}{l}
\frac{C^{-\gamma}_{t+1}}{q_{t+1}} p_{t+1}
\end{array}
\right),
\]
or (Euler equation):
\[
\mathbb{E}_t\left[
\begin{array}{l}
\delta\left(
\begin{array}{l}
\frac{C_{t+1}}{C_t}
\end{array}
\right)^{-\gamma}  \frac{q_t}{q_{t+1}}
\frac{p_{t+1}}{p_t} - 1
\end{array}
\right] = 0.
\]
\end{example}

According to Eq. \eqref{eq:SDF100}, for any asset \(j\):
\begin{equation}
p_{j,t} = \mathbb{E}_t(\mathcal{M}_{t,t+1} p_{j,t+1}).\label{eq:Mbasicpricing}
\end{equation}
Using that \(p_{j,t+1} = \mathbb{E}_t(\mathcal{M}_{t+1,t+2} p_{j,t+2})\), we get:
\begin{eqnarray*}
p_{j,t} &=& \mathbb{E}_t[\mathbb{E}_{t+1}(p_{j,t+2}\mathcal{M}_{t+1,t+2})\mathcal{M}_{t,t+1}] \\
&=& \mathbb{E}_t(\mathcal{M}_{t,t+1} \mathcal{M}_{t+1,t+2}p_{j,t+2}).
\end{eqnarray*}
This can be generalized as follows:
\[
p_{j,t} = \mathbb{E}_t[\mathcal{M}_{t,t+1} \dots \mathcal{M}_{t+h-1,t+h}p_{j,t+h}], \; \forall h.
\]

\hypertarget{recursive-utilities}{%
\section{Recursive utilities}\label{recursive-utilities}}

XXXX

\hypertarget{PricingAAO}{%
\section{SDF: Absence of Arbitrage Approach}\label{PricingAAO}}

Consider a period of interest \({\mathcal T} = \{0,1,2,...,T^*\}\). As in Chapter \ref{ChapterAffine}, vector \(w_t\) constitutes the new information in the economy at \(t\). The historical, or physical, dynamics of \(w_t\), \(f(\underline{w_t})\), is defined by \(f(w_{t+1}|\underline{w_t})\). The physical probability is denoted by \(\mathbb{P}\). \(L_{2t}, t \in {\mathcal T}\), is the (Hilbert) space of square integrate functions \(g(\underline{w_t})\), and we have \(L_{2t} \subset L_{2s}, t< s\).

\hypertarget{existence-and-unicity-of-the-sdf}{%
\subsection{Existence and unicity of the SDF}\label{existence-and-unicity-of-the-sdf}}

\begin{hypothesis}[Price existence and uniqueness]
\protect\hypertarget{hyp:Apricing1}{}\label{hyp:Apricing1}For any \(\underline{w_t}\), there exists a unique \(p_t[g(\underline{w_s})]\),
function of \(\underline{w_t}\), price at \(t\) of a payoff
\(g(\underline{w_s})\) delivered at \(s, \forall t \le s\).
\end{hypothesis}

\begin{hypothesis}[Linearity and continuity]
\protect\hypertarget{hyp:Apricing2}{}\label{hyp:Apricing2}

For all \(t < s\), \(\underline{w_t}\), \(g_1\), \(g_2\), we have

\begin{itemize}
\tightlist
\item
  \(p_t[\lambda_1 g_1(\underline{w_s}) + \lambda_2g_2(\underline{w_s})] = \lambda_1p_t[g_1(\underline{w_s})]+\lambda_2 p_t[g_2(\underline{w_s})]\),
\item
  If \(g_n(\underline{w_s}) \overset{L_{2s}}{\underset{n\rightarrow\infty}{\longrightarrow}} 0\), then \(p_t[g_n(\underline{w_s})] \underset{n\rightarrow\infty}{\longrightarrow} 0\).
\end{itemize}

\end{hypothesis}

\begin{hypothesis}[Absence of Arbitrage Opportunity (AAO)]
\protect\hypertarget{hyp:Apricing3}{}\label{hyp:Apricing3}

At any \(t\), it is impossible to constitute a portfolio of future payoffs, possibly modified at subsequent dates, such that:

\begin{itemize}
\tightlist
\item
  the price of the portfolio at \(t\) is zero,
\item
  payoffs at subsequent dates are \(\ge 0\),
\item
  there is at least one subsequent date \(s\) such that the net payoff at \(s\) is strictly positive with a non zero conditional probability at \(t\).
\end{itemize}

\end{hypothesis}

\begin{theorem}[Riesz representation theorem]
\protect\hypertarget{thm:Riesz}{}\label{thm:Riesz}Under Assumptions \ref{hyp:Apricing1} and \ref{hyp:Apricing2}, for all \(\underline{w_t}\), and \(s > t\), there exists \(\mathcal{M}_{t,s}(\underline{w_s}) \in L_{2s}\), unique such that, \(\forall g(\underline{w_s}) \in L_{2s}\),
\[
p_t[g(\underline{w_s})] = \mathbb{E}[\mathcal{M}_{t,s}(\underline{w_s})g(\underline{w_s})|\underline{w_t}].
\]
In particular the price at \(t\) of a zero coupon bond maturing at \(s\) is \(\mathbb{E}(\mathcal{M}_{t,s}|\underline{w_t})\).
\end{theorem}

\begin{proposition}[Positivity of M]
\protect\hypertarget{prp:PositivityM}{}\label{prp:PositivityM}If Assumption \ref{hyp:Apricing3} is satisfied, then for all \(t\) and \(s\), \(\mathbb{P}(\mathcal{M}_{t,s}>0|\underline{w_t})=1\).
\end{proposition}

\begin{proof}
\(\Leftarrow\) is obvious. If \(\Rightarrow\) was not true, the payoff
\(\textbf{1}_{\{\mathcal{M}_{t,s} \le 0\}}\), at \(s\), would be such that:
\(\mathbb{P}[\textbf{1}_{\{\mathcal{M}_{t,s} \le 0\}}=1|\underline{w_t}] > 0\) and \(p_t[\textbf{1}_{\{\mathcal{M}_{t,s} \le 0\}}] = \mathbb{E}_t[\mathcal{M}_{t,s}\textbf{1}_{\{\mathcal{M}_{t,s} \le 0\}}] \le 0\).
\end{proof}

\begin{proposition}[Time consistency]
\protect\hypertarget{prp:timeconsist}{}\label{prp:timeconsist}

For all \(t < r < s\), we have \(\mathcal{M}_{t,s} = \mathcal{M}_{t,r} \mathcal{M}_{r,s}\), which implies:

\begin{itemize}
\tightlist
\item
  \(\mathcal{M}_{t,s} = \mathcal{M}_{t,t+1} \mathcal{M}_{t+1,t+2}\dots\mathcal{M}_{s-1,s}\)
\item
  \(\mathcal{M}_{0,t} = \Pi^{t-1}_{j=0} \mathcal{M}_{j,j+1}\) (\(\mathcal{M}_{0,t}\) is called \textbf{pricing kernel}).
\end{itemize}

\end{proposition}

\begin{proof}
Using Lemma \ref{lem:sdf} we have:
\begin{eqnarray*}
p_t(g_s) &=& \mathbb{E}(\mathcal{M}_{t,s}g_s|\underline{w_t}) = \mathbb{E}(\mathcal{M}_{t,r} p_r(g_s)|\underline{w_t}) \\
&=& \mathbb{E}[\mathcal{M}_{t,r}\mathbb{E}(\mathcal{M}_{r,s} g_s|\underline{w_r})|\underline{w_t}] = \mathbb{E}(\mathcal{M}_{t,r} \mathcal{M}_{r,s} g_s|\underline{w_t}), \forall g, \forall \underline{w}_{t}
\end{eqnarray*}
and, therefore, \(\mathcal{M}_{t,s} = \mathcal{M}_{t,r}\mathcal{M}_{r,s}\).
\end{proof}

\begin{lemma}
\protect\hypertarget{lem:sdf}{}\label{lem:sdf}For any payoff \(g_s\) at \(s, p_t(g_s) = p_t[p_r(g_s)]\).
\end{lemma}

\begin{proof}
If this was not true, we could construct a sequence of portfolios with a strictly positive payoff at \(s\) with zero payoff at any other future date and with price zero at \(t\), contradicting Assumption \ref{hyp:Apricing3}. Indeed, assuming, for instance, \(p_t(g_s) > p_t[p_r(g_s)]\), the payoff at \(s\) is defined by the following strategy: (i) at \(t\): buy \(p_r(g_s)\), (short) sell \(g_s\), buy
\(\frac{p_t(g_s)-p_t[p_r(g_s)]}{\mathbb{E}(\mathcal{M}_{t,s}|\underline{w_t})}\) zero-coupon bonds maturing at \(s\), at global price zero, (ii) at \(r\): buy \(g_s\) and sell \(p_r(g_s)\), generating a zero net payoff, (iii) at \(s\), the net payoff is: \(g_s-g_s+\frac{p_t(g_s)-p_t[p_r(g_s)]}{\mathbb{E}(\mathcal{M}_{t,s}|\underline{w_t})} > 0\).
\end{proof}

Consider an asset whose payoff, on date \(s\), is \(g(\underline{w_s})\). We have, \(\forall t < s\):
\begin{equation}
\boxed{p_t[g(\underline{w_s})] = \mathbb{E}_t[\mathcal{M}_{t,t+1}...\mathcal{M}_{s-1,s}g(\underline{w_s})].}\label{eq:basic}
\end{equation}
In particular, since \(L_{2,t+1}\) contains 1, the price at \(t\) of a zero-coupon with residual maturity one is given by:
\[
B(t,1) := \mathbb{E}_t [\mathcal{M}_{t,t+1}].
\]
Denoting by \(r_t\) the continously-compounded interest rate, defined through \(B(t,1)=\exp(-r_{t})\), we get
\[
r_{t}=-\log \mathbb{E}_t [\mathcal{M}_{t,t+1}].
\]

\begin{definition}[Bank account]
\protect\hypertarget{def:bankaccount}{}\label{def:bankaccount}The bank account process \(R_t\) is defined by \(R_{t} \equiv \exp(r_0+...+r_{t-1}) = \frac{1}{\mathbb{E}_0[ \mathcal{M}_{0,1}]\times ... \times \mathbb{E}_{t-1} [\mathcal{M}_{t-1,t}]}\).

\(R_t\) is the price of an investment initiated on date 0, when it was worth one dollar, and invested on each date at the risk-free rate (for one period).
\end{definition}

For any price process \(p_t\), we have \(p_t = \mathbb{E}_t(\mathcal{M}_{t,s} p_s)\) (with \(s>t\)), or \(\mathcal{M}_{0,t} p_t = \mathbb{E}_t(\mathcal{M}_{0,s}p_s)\). That is, \(\mathcal{M}_{0,t} p_t\) is a martingale. In particular \(\mathcal{M}_{0,t} R_t\) is a martingale.

\hypertarget{PricingAffine}{%
\subsection{Exponential Affine SDF}\label{PricingAffine}}

A specific (tractable) case is that of exponential affine SDF. Assume that
\[
\mathcal{M}_{t,t+1}(\underline{w_{t+1}}) = \exp[\alpha_t(\underline{w_t})'w_{t+1}+\beta_t(\underline{w_t})]
\]
where \(\alpha_t\) defines the \emph{prices of risk} or \emph{sensitivity} vector. Using \(\mathbb{E}_t[\mathcal{M}_{t,t+1}]=\exp(-r_{t})=\exp[\psi_t(\alpha_t)+\beta_t]\), we get:
\begin{equation}
\mathcal{M}_{t,t+1} = \exp[-r_{t}+\alpha'_tw_{t+1}-\psi_t(\alpha_t)].\label{eq:keySDF}
\end{equation}

\begin{example}[CCAPM/Power utility case]
In the CCAPM-power-utility case (see Example \ref{exm:CCAPM}), we have (Eq. \eqref{eq:powerutilSDF}):
\[
\mathcal{M}_{t,t+1} = \exp(\log \delta + \log q_t + \gamma \log   C_t - \log   q_{t+1} - \gamma  \log   C_{t+1}),
\]
where \(q_t\) is the price of the consumption good, \(C_t\) is the quantity consumed at \(t\) and \(\delta\) is the intertemporal discount rate.

Hence, in that case, \(\mathcal{M}_{t,t+1}\) is exponential affine in \(w_{t+1} = (\log q_{t+1}, \log C_{t+1})'\) (and its first lag).
\end{example}

\hypertarget{PricingRN}{%
\section{The risk-neutral (R.N.) dynamics}\label{PricingRN}}

The historical Dynamics is characterized by \(f(\underline{w_{T^*}})\), or by the
sequence of conditional p.d.f. \(f_{t+1}(w_{t+1}|\underline{w_t})\), or
\(f_{t+1}(w_{t+1})\), with respect to (w.r.t.) some measure \(\mu\).

We define the conditional risk-neutral p.d.f. w.r.t. the conditional historical probability. For that, we employ the Radon-Nikodym derivative \(d^{\mathbb{Q}}_{t+1}(w_{t+1}|\underline{w_t})\):\footnote{Of course, the conditional historical p.d.f. with respect to the conditional risk-neutral (R.N.) p.d.f. is:
  \(d_{t+1}(w_{t+1}) = \frac{1}{d^{\mathbb{Q}}_{t+1}(w_{t+1})}\) or \(d_{t+1}(w_{t+1}) = \frac{\exp(-r_{t})}{\mathcal{M}_{t,t+1}}\).}
\[
d^{\mathbb{Q}}_{t+1}(w_{t+1}|\underline{w_t}) =
\frac{\mathcal{M}_{t,t+1}(\underline{w_{t+1}})}{\mathbb{E}[\mathcal{M}_{t,t+1}(\underline{w_{t+1}})|\underline{w_t}]},
\]
or
\[
d^{\mathbb{Q}}_{t+1}(w_{t+1})=
\frac{\mathcal{M}_{t,t+1}}{\mathbb{E}_t(\mathcal{M}_{t,t+1})}=\exp(r_{t}) \mathcal{M}_{t,t+1}.
\]
In this context, the risk neutral conditional p.d.f. is:
\begin{eqnarray}
f^{\mathbb{Q}}_{t+1}(w_{t+1}) &=& f_{t+1}(w_{t+1})d^{\mathbb{Q}}_{t+1}(w_{t+1}) \nonumber \\
&=&f_{t+1} (w_{t+1}) \mathcal{M}_{t,t+1} (\underline{w_{t+1}}) \exp [r_{t} (\underline{w_t})].\label{eq:fQfP}
\end{eqnarray}

The p.d.f. of \(\mathbb{Q}\) w.r.t. the historical dynamics \(\mathbb{P}\) is:
\[
\xi_{T^*} =  \frac{d\mathbb{Q}}{d\mathbb{P}} =
\Pi^{T^{*}-1}_{t=0} d^{\mathbb{Q}}_{t+1}(w_{t+1}) =
\Pi^{T^{*}-1}_{t=0} \exp(r_{t}) \mathcal{M}_{t,t+1},
\]
and the p.d.f. of the R.N. distribution of \(\underline{w_t}\), w.r.t. the corresponding historical distribution is:
\[
\xi_t= \Pi^{t-1}_{\tau=1}
d^{\mathbb{Q}}_{\tau+1}(w_{\tau+1})=\mathbb{E}_t\left(\frac{d\mathbb{Q}}{d\mathbb{P}}\right) = \mathbb{E}_t\xi_{T^*}.
\]
Therefore, \(\xi_t\) is a \(\mathbb{P}\)-martingale.\footnote{Indeed:
  \[
  \mathbb{E}_t \left( \frac{d\mathbb{Q}}{d\mathbb{P}}\right) = \Pi^{t-1}_{\tau = 1} d^{\mathbb{Q}}_{\tau + 1} (w_{\tau+1}) \mathbb{E}_t \left( d^{\mathbb{Q}}_{t+1} (w_{t+1}) \ldots d^{\mathbb{Q}}_{T^*} (w_{T^*})\right).
  \]}

Consider the date-\(t\) price of a payoff \(g(\underline{w_s})\) at time \(s>t\). An equivalent form of the pricing formula \eqref{eq:basic} is:
\begin{eqnarray*}
p_t[g(\underline{w_s})] &=& \mathbb{E}_t[\mathcal{M}_{t,t+1}...\mathcal{M}_{s-1,s}g(\underline{w_s})] \\
&=& \mathbb{E}^{\mathbb{Q}}_t[\exp(-r_{t}-...-r_{s-1})g(\underline{w_s})],
\end{eqnarray*}
or, with simpler notations:
\[
p_t = \mathbb{E}^{\mathbb{Q}}_t[\exp(-r_{t}-...-r_{s-1})p_s] = \mathbb{E}^{\mathbb{Q}}_t\left(\frac{R_t}{R_s} p_s\right),
\]
where \(R_t\) is the \emph{bank account}.

We also have \(p_t/R_t = \mathbb{E}^{\mathbb{Q}}_t\left( p_s/R_s\right)\), that is, \(p_t/R_t\) is a \(\mathbb{Q}\)-martingale. In particular \(p_t = \exp(-r_{t})\mathbb{E}^{\mathbb{Q}}_t(p_{t+1})\), or, using the arithmetic return of any payoff \((p_{t+1}-p_t)/p_t\), and the arithmetic return of the riskless asset \(r_{A,t+1}=\exp(r_{t})-1\), we get:
\[
\mathbb{E}^{\mathbb{Q}}_t\left(\frac{p_{t+1}-p_t}{p_t}\right)=r_{A,t}.
\]
Moreover the excess arithmetic return process \((p_{t+1}-p_t)/p_t-r_{A,t}\) is a \(\mathbb{Q}\)-martingale difference and, therefore, \(\mathbb{Q}\)-serially uncorrelated.

Let us consider the case of an exponential affine SDF \(\mathcal{M}_{t,t+1}=\exp(\alpha'_t w_{t+1}+\beta_t)\):
\[
d^{\mathbb{Q}}_{t+1}(w_{t+1}) = \frac{\mathcal{M}_{t,t+1}}{\mathbb{E}_t(\mathcal{M}_{t,t+1})} = \frac{\exp(\alpha'_t
w_{t+1}+\beta_t)}{\exp[\psi_t(\alpha_t)+\beta_t]} = \exp[\alpha'_t w_{t+1}-\psi_t(\alpha_t)]
\]
We then have that \(d^{\mathbb{Q}}_{t+1}(w_{t+1})\) is also exponential affine. Moreover:
\[
f^{\mathbb{Q}}_{t+1} (w_{t+1}) = \frac{f_{t+1} (w_{t+1}) \exp (\alpha'_t w_{t+1})}{\varphi_t (\alpha_t)}.
\]
The previous equation shows that \(f^{\mathbb{Q}}_{t+1}\) is the Esscher transform of \(f_{t+1}\) evaluated at \(\alpha_t\).

Let us know consider the Laplace transform of the conditional R.N. probability, \(\varphi^{\mathbb{Q}}_t(u|\underline{w_t})\), also denoted by \(\varphi^{\mathbb{Q}}_t(u)\). We have:
\begin{eqnarray*}
\varphi^{\mathbb{Q}}_t(u) &=& \mathbb{E}^{\mathbb{Q}}_t \exp(u' w_{t+1}) \\
&=& \mathbb{E}_t \exp[(u+\alpha_t)'w_{t+1}-\psi_t(\alpha_t)] \\
&=& \exp[\psi_t(u+\alpha_t)-\psi_t(\alpha_t)] =
\frac{\varphi_t(u+\alpha_t)}{\varphi_t(\alpha_t)}.
\end{eqnarray*}
Hence:
\begin{equation}
\boxed{\psi^{\mathbb{Q}}_t(u) = \psi_t(u+\alpha_t)-\psi_t(\alpha_t).}\label{eq:transfoPQ}
\end{equation}
We check that, if \(\alpha_t=0\), \(\psi^{\mathbb{Q}}_t=\psi_t\) (since \(\psi_t(0)=0)\).

Moreover, putting \(u=-\alpha_t\) in the expression of
\(\psi^{\mathbb{Q}}_t(u)\) we get \(\psi^{\mathbb{Q}}_t(-\alpha_t)=-\psi_t(\alpha_t)\),
and, replacing \(u\) by \(u-\alpha_t\), we get:
\[
\boxed{\psi_t(u) = \psi^{\mathbb{Q}}_t(u-\alpha_t)-\psi^{\mathbb{Q}}_t(-\alpha_t).}
\]
Also:
\begin{equation*}
\left\{
\begin{array}{ccl}
d_{t+1}(w_{t+1}) &=& \exp[-\alpha'_t(w_{t+1})-\psi^{\mathbb{Q}}_t(-\alpha_t)] \\
d^{\mathbb{Q}}_{t+1}(w_{t+1}) &=& \exp[\alpha'_t(w_{t+1})+\psi^{\mathbb{Q}}_t(-\alpha_t)].
\end{array}
\right.
\end{equation*}

\hypertarget{PricingTypology}{%
\section{Typology of Econometric Asset Pricing Models}\label{PricingTypology}}

\begin{definition}[Econometric Asset Pricing Model (EAPM)]
\protect\hypertarget{def:typo}{}\label{def:typo}

An Econometric Asset Pricing Model (EAPM) is defined by the following functions:

\begin{itemize}
\tightlist
\item
  \(r_{t}(\underline{w_t})\),
\item
  \(f(w_{t+1}|\underline{w_t}))\) {[}or \(\psi_t(u)\){]},
\item
  \(\mathcal{M}_{t,t+1}(\underline{w_{t+1}})\),
\item
  \(f^{\mathbb{Q}}(w_{t+1}|\underline{w_t})\) {[}or \(\psi^{\mathbb{Q}}_t(u)\){]}.
\end{itemize}

\end{definition}

The previous functions have to to be specified and parameterized. They are linked by:
\[
f^{\mathbb{Q}}(w_{t+1}|\underline{w_t}) = f(w_{t+1}|\underline{w_t}) \mathcal{M}_{t,t+1}(\underline{w_{t+1}}) \exp[r_{t}(\underline{w_t}))].
\]

In the following, we present three ways of specifying an EAPM:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the direct modelling,
\item
  the R.N.-constrained direct modelling (or mixed modelling),
\item
  the back modelling.
\end{enumerate}

We focus on the case where \(\mathcal{M}_{t,t+1}\) is exponential affine, as in Eq. \eqref{eq:keySDF}:
\[
\mathcal{M}_{t,t+1} (\underline{w_{t+1}}) = \exp\left\{ -r_{t} (\underline{w_t}) + \alpha'_t(\underline{w_t})w_{t+1} - \psi_t [\alpha_t (w_t)]\right\}.
\]
Once the short-term rate function \(r_{t}(\underline{w_t})\) is specified, we have to specify \(\psi_t\), \(\alpha_t\), and \(\psi^{\mathbb{Q}}_t\), that are linked by Eq. \eqref{eq:transfoPQ}.

In all approaches, we have to specify the status of the short rate. The short rate \(r_{t}\) is a function of \(\underline{w_t}\), this function may be known or unknown by the econometrician. It is known in two cases: (a) \(r_{t}\) is exogenous (\(r_{t}(\underline{w_t})\) does not depend on \(\underline{w_t}\)) or (b) \(r_{t}\) is a component of \(w_t\). By contrast, if the function \(r_{t} (\underline{w_t})\) is unknown, it has to be specified parametrically:
\[
\left\{ r_{t} (\underline{w_t}, \tilde{\theta}), \tilde{\theta}\in \tilde{\Theta} \right\},
\]
where \(r_{t}(\bullet,\bullet)\) is a known function.

Let us now detail the three steps on which each of the three ways of defining an EAPM is based.

\hypertarget{the-direct-modelling}{%
\subsection{The Direct Modelling}\label{the-direct-modelling}}

\begin{itemize}
\tightlist
\item
  \textbf{Step 1 -- Specification of the historical dynamics}. We choose a parametric family for the conditional historical Log-Laplace transform \(\psi_t(u|\underline{w_t})\): \(\left\{ \psi_t (u|\underline{w_t} ; \theta_1), \theta_1 \in \Theta_1 \right\}\).
\item
  \textbf{Step 2 -- Specification of the SDF}. Considering the affine specification of as Eq. \eqref{eq:keySDF}, that is:
  \[
  \mathcal{M}_{t,t+1} (\underline{w_{t+1}}) = \exp\left\{ -r_{t}(\underline{w_t}, \tilde{\theta}) + \alpha'_t(\underline{w_t})w_{t+1} - \psi_t [\alpha_t (w_t)|\underline{w_t} ; \theta_1]\right\},
  \]
  we need to specifiy functions \(r_{t}(\underline{w_t}, \tilde{\theta})\) and \(\alpha_t(\underline{w_t})\). Assume that \(\alpha_t(\underline{w_t})\) belongs to a parametric family: \(\left\{ \alpha_t (\underline{w_t} ; \theta_2),\theta_2 \in \Theta_2 \right\}\).
  We then have:
  \begin{eqnarray*}
  \mathcal{M}_{t,t+1}(\underline{w_{t+1}}, \theta) &=& \exp \left\{ - r_{t}
  (\underline{w_t}, \tilde{\theta}) + \alpha'_t (\underline{w_t},\theta_2) w_{t+1} - \psi_{t} \left[ \alpha_t (\underline{w_t},
  \theta_2) | \underline{w_t} ; \theta_1 \right] \right\},
  \end{eqnarray*}
  where \(\theta = (\tilde{\theta}', \theta'_1,\theta'_2)' \in \tilde{\Theta}\times \Theta_1 \times \Theta_2 = \Theta\).
\item
  \textbf{Step 3 -- Internal consistency conditions (ICC)}. For any payoff \(g(\underline{w_s})\) settled at \(s>t\), with price \(p(\underline{w_t})\) at \(t\) which is a known function of
  \(\underline{w_t}\), we must have:
  \begin{equation*}
  p(\underline{w_t}) = \mathbb{E} \left\{\mathcal{M}_{t,t+1} (\theta) \dots \mathcal{M}_{s-1,s} (\theta) g(\underline{w_s})  |  \underline{w_t},
  \theta_1 \right\}    \forall \; \underline{w_t}, \theta.\label{eq:ICCgen}
  \end{equation*}
  These ICC pricing conditions may imply strong constraints on \(\theta\). For instance, when components of \(w_t\) are returns of some assets: if \(w_{1,t} = \log(p_{1,t}/p_{1,t-1})\), then we must have \(\mathbb{E}_t [\mathcal{M}_{t,t+1} \exp (e'_1 w_{t+1})]= 1\) (Euler equation). Or, in the case of interest rates with various maturities: if \(w_{1,t} = -1/h\log B(t,h)\), then we must have \(e'_1 w_{t} = - 1/h \log \mathbb{E}_t (\mathcal{M}_{t,t+1}\times \dots \times \mathcal{M}_{t+h-1,t+h})\).
\end{itemize}

The previous three steps imply the specification of the R.N. dynamics (according to Eq. \eqref{eq:transfoPQ}):
\begin{equation*}
\psi^{\mathbb{Q}} (u | \underline{w_t}, \theta_1, \theta_2) =
\psi_t \left[ u + \alpha_t (\underline{w_t}, \theta_2) |
\underline{w_t}, \theta_1 \right] - \psi_t \left[ \alpha_t
(\underline{w_t}, \theta_2) | \underline{w_t}, \theta_1
\right].
\end{equation*}

\hypertarget{the-r.n.-constrained-direct-modelling-or-mixed-modelling}{%
\subsection{The R.N.-constrained direct modelling (or mixed modelling)}\label{the-r.n.-constrained-direct-modelling-or-mixed-modelling}}

\begin{itemize}
\tightlist
\item
  \textbf{Step 1 -- Specification of the physical dynamics}. We select a family \(\{ \psi_t (u | \underline{w_t},\theta_1), \theta_1 \in \Theta_1 \}\).
\item
  \textbf{Step 2 -- Specification of the risk-neutral dynamics}. We select a family \(\{\psi^{\mathbb{Q}}_t (u | \underline{w_t}, \theta^*),\theta^* \in \Theta^* \}\) and, possibly, \(\{r_{t}(\underline{w_t},\tilde{\theta}),\tilde{\theta}\in\tilde{\Theta}\}\).
\item
  \textbf{Step 3 -- Internal Consistency Conditions (ICC)}. Once the parameterization \((\tilde{\theta}, \theta_1, \theta^*) \in \tilde{\Theta} \times \Theta^*_1\) is defined, ICCs may be imposed. For instance, if \(w_{1,t} = \log(p_{1,t}/p_{1,t-1})\), then we must have \(\exp(-r_t)\mathbb{E}^{\mathbb{Q}}_t \exp (e_{1}' w_{t+1}) = 1\). Or if \(w_{1,t} = B(t,h)\), then \(e_{1}' w_{t} = \mathbb{E}_t^{\mathbb{Q}} \exp(-r_t - \dots - r_{t+h-1})\).
\end{itemize}

The SDF is a by-product. If we want an exponential affine SDF, for any pair \((\psi^{\mathbb{Q}}_t, \psi_t)\) belonging to these families, there must exist a unique function \(\alpha_t (\underline{w_t})\) denoted by \(\alpha_t (w_t ; \theta_1, \theta^*)\), and satisfying:
\begin{equation*}
\psi^{\mathbb{Q}}_t (u | \underline{w_t}) = \psi_t \left[ u +
\alpha_t (w_t) | \underline{w_t} \right] - \psi_t \left[
\alpha_t (\underline{w_t}) | \underline{w_t} \right].
\end{equation*}

\hypertarget{the-back-modelling-based-on-three-steps}{%
\subsection{The Back Modelling (based on three steps)}\label{the-back-modelling-based-on-three-steps}}

\begin{itemize}
\tightlist
\item
  \textbf{Step 1 -- Specification of the R.N. dynamics}, and possibly of \(r_{t}(\underline{w_t})\){]}: \(\psi^{\mathbb{Q}}_t (u | \underline{w_t}; \theta^*_1)\).
\item
  \textbf{Step 2 -- Internal consistency conditions (ICC)}, if relevant, are taken into account:
  \begin{equation*}
  \begin{array}{lll}
  && p(\underline{w_t}) = \mathbb{E}^{\mathbb{Q}}_t \left[ \exp (-r_{t} (\underline{w_t},\tilde{\theta}) - \dots - r_{s-1} (\underline{w_s}, \tilde{\theta}))g(\underline{w_s}) | \underline{w_t} , \theta^*_1\right] ,\\
  && \forall    \underline{w_t} , \tilde{\theta} , \theta^*_1.
  \end{array}
  \end{equation*}
\item
  \textbf{Step 3 -- Choice of the specification of the prices of risk}. One chooses function \(\alpha_t(\underline{w_t})\) without any constraint; this amounts to defining the family \(\{ \alpha_t (\underline{w_t}, \theta^*_2), \theta^*_2\in \Theta^*_2 \}\).
\end{itemize}

The historical dynamics is obtained as a by-product. Indeed:
\begin{equation*}
\psi_t(u | \underline{w_t} ; \theta^*_1, \theta^*_2) = \psi_t^{\mathbb{Q}}\left[ u -\alpha_t (\underline{w_t}, \theta^*_2)|\underline{w_t} ; \theta^*_1 \right] -\psi^{\mathbb{Q}}_t \left[- \alpha_t (\underline{w_t}, \theta^*_2) | \underline{w_t},\theta^*_1 \right].
\end{equation*}

\hypertarget{the-term-structure-or-risk-free-yields}{%
\chapter{The term structure or risk-free yields}\label{the-term-structure-or-risk-free-yields}}

\hypertarget{RFIntroduction}{%
\section{Introduction}\label{RFIntroduction}}

Risk-free yields are the yields-to-maturity associated with bonds that carry no default and/or liquidity risks. Bonds issued by sovereign entities with top credit quality are usually considered to be risk-free.

An important share of the term-structure literature pertains to the modelling of risk-free yields. Some models involve macro factors in \(w_t\) \citep{Ang_Piazzesi_2003}; some do not \citep{Duffie_Singleton_1997}. The latter are sometimes called \emph{yield-only} models.

The basic pricing formula of a risk-free zero coupon bond is (see Eq. \eqref{eq:stdbond} in Example \ref{exm:nominalBth}):
\begin{eqnarray}
B(t,h) &=& \exp(-r_{t}) \mathbb{E}^{\mathbb{Q}}_t \exp(-r_{t+1}-\dots-r_{t+h-1})\\
R(t,h) &=& - \frac{1}{h} \log B(t,h). \label{eq:stdbondRFchapter}
\end{eqnarray}

Term structure models are often used to extract \textbf{term premiums} from observed yields-to-maturity. Term premiums are those components of yields that would not exist if investors were not risk-averse.

If agents were not risk averse, i.e., under the \textbf{Expectation Hypothesis (EH)}, we would have \(\mathcal{M}_{t,t+1} = \exp(- r_t)\). We would then have ``\(\mathbb{P} \equiv \mathbb{Q}\)'\,' and \(B(t,h)\) would become:
\begin{equation}
\exp(-r_{t}) \mathbb{E}_t \exp(-r_{t+1}-\dots-r_{t+h-1}).\label{eq:stdbondRFchapterP}.
\end{equation}
And the maturity-\(h\) yield-to-maturity would then be:
\begin{eqnarray}
R^{EH}(t,h) &=& -\frac{1}{h}\log \left( \mathbb{E}_t \exp(-r_t-\dots-r_{t+h-1})\right)\nonumber\\
&\approx& \frac{1}{h}\mathbb{E}_t(r_t + \dots + r_{t+h-1}).\label{eq:REH}
\end{eqnarray}

The term premium is given by:
\begin{eqnarray}
TP_{t,h} &=& \underbrace{- \frac{1}{h} \log  \mathbb{E}^{\mathbb{Q}}_t \exp(-r_{t+1}-\dots-r_{t+h-1})}_{=R(t,h)} - \nonumber \\
&& \underbrace{- \frac{1}{h}  \log  \mathbb{E}_t \exp(-r_{t+1}-\dots-r_{t+h-1}).}_{=R^{EH}(t,h)}\label{eq:TP}
\end{eqnarray}

What is the economic meaning of the term premium? Under EH, investors are willing to buy a maturity-\(h\) bond as long as its expected return is---up to Jensen's inequality---equal to the average of future short-term rates. (Hence the definition of \(R^{EH}(t,h)\), see Eq. \eqref{eq:REH}.) When \(TP_{t,h}>0\), investors are willing to buy the maturity-\(h\) bond only if its return is, on average, higher than expected future short-term rates; this corresponds to a situation where investors consider that long-term bonds tend to lose value in \emph{bad states of the world} (i.e., states of high marginal utility).

\begin{quote}
\textbf{\emph{Risk premium:}} According to Eq. \eqref{eq:Mbasicpricing}, the price of any asset \(j\) satisfies:
\[
p_{jt} = \mathbb{E}_t(\mathcal{M}_{t,t+1} p_{j,t+1}).
\]
The previous equation rewrites:
\[
p_{jt} =  \mathbb{C}ov_t(\mathcal{M}_{t,t+1}, p_{j,t+1}) + \mathbb{E}_t(\mathcal{M}_{t,t+1})\mathbb{E}_t( p_{j,t+1})
\]
or
\begin{equation}
p_{jt} = \underbrace{\exp(-r_t)\mathbb{E}_t( p_{j,t+1})}_{=p^{EH}_{jt}} + \underbrace{\mathbb{C}ov_t(\mathcal{M}_{t,t+1}, p_{j,t+1})}_{\mbox{Risk premium}}.\label{eq:CovRP}
\end{equation}
If investors were not risk-averse, then we would have \(p_{jt} = p^{EH}_{jt}\). The S.D.F. is high (resp. low) in bad (resp. good) states of the world (states of high marginal utility in the equilibrium approach). Hence, we have \(p_{jt}< p^{EH}_{jt}\) if asset \(j\) tends to pay less in bad states of the world (i.e., if \(\mathbb{C}ov_t(\mathcal{M}_{t,t+1}, p_{j,t+1})<0\)).
\end{quote}

\hypertarget{swap-rates-and-forward-rates}{%
\section{Swap rates and forward rates}\label{swap-rates-and-forward-rates}}

\hypertarget{swap-rates}{%
\subsection{Swap rates}\label{swap-rates}}

Bonds issued by top-rated (Aaa/AAA) countries are often considered to be risk-free. Because of call-margins mechanisms, swap rates are also used as risk-free benchmarks \citep{Duffie_Stein_2015}.

\begin{definition}[Interest Rate Swap (IRS)]
\protect\hypertarget{def:swap}{}\label{def:swap}In an Interest Rate Swap (IRS), a \emph{fixed-rate payer} agrees to provide the \emph{fixed-rate receiver} with a sequence of cash flows that are determined at the negotiation date of the swap, and at predetermined dates. These cash flows constitute the \emph{fixed leg} of the swap. Conversely, the fixed-rate receiver provides the fixed-rate payer with cash-flows that depend on future values of a reference rate; this is the \emph{floating rate} of the swap.

More precisely, the dates of payment are of the form \(t+ \tau\), \(t + 2\tau\), \dots, \(t + n\tau\), where \(\tau\) is a period expressed in years (typically 1/2 or 1/4) and \(n\) is the number of payments. The maturity, or \emph{tenor}, of the swap contract is \(h = n \tau\).

The payoffs of the fixed leg are \(\tau S\), where \(S\) is the annualized payment (or \emph{swap rate}). On date \(t+j\tau\), the payoff of the floating leg is \(\tau L(t+(j-1)\tau,\tau)\), where \(L\), the annualized linear rate is given by:
\[
L(t+(j-1)\tau,\tau) = \frac{1 - B(t+(j-1)\tau,\tau)}{\tau B(t+(j-1)\tau,\tau)},
\]
where \(B(t+(j-1)\tau,\tau)\) is the price, at date \(t+(j-1)\tau\) of a bond of maturity \(\tau\).

On the negotiation date, the values of the fixed and floating legs are identical, so that the value of the swap is zero.
\end{definition}

At \(t\), the price of the fixed leg is:
\[
\sum_{j=1}^n \tau S B(t,j\tau).
\]
Let us turn to the price of the floating leg. The payoff at date \(t+j\tau\), that is \(\frac{1 - B(t+(j-1)\tau,\tau)}{B(t+(j-1)\tau,\tau)}\) is known on date \(t+(j-1)\tau\), so its price at date \(t+(j-1)\tau\) is \(1 - B(t+(j-1)\tau,\tau)\), and its price at \(t\) therefore is \(B(t,(j-1)\tau) - B(t,j\tau)\). Summing over \(j=1,\dots,n\), the date-\(t\) price of the floating leg is \(1 - B(t,n\tau)\) (independent of the payment dates).

Since the price of the contract is zero at date \(t\) (by definition of the swap), we must have:
\[
\sum_{j=1}^n \tau S B(t,j\tau) = 1 - B(t,n\tau) \Rightarrow S = \frac{1 - B(t,n\tau)}{ \tau \sum_{j=1}^n  B(t,j\tau)},
\]
or
\[
\boxed{S(t,h) = \frac{1 - B(t,h)}{\tau \sum_{j=1}^{h/\tau}  B(t,j\tau)}.}
\]

Note that all the terms appearing in the previous formula are available in closed-form in the context of an affine model (see Example \ref{exm:nominalBth}).

\hypertarget{FWD}{%
\subsection{Forward rates}\label{FWD}}

\begin{definition}[Forward Rate Agreement (FRA)]
\protect\hypertarget{def:FWD}{}\label{def:FWD}An interest rate forward contract is a contract in which the rate to be paid or received on a specific obligation for a set period, beginning in the future, is set at contract initiation.
\end{definition}

Denote by \(f(t,h_1,h_2)\) the forward interest rate, set on date \(t\), for the period between \(t+h_1\) and \(t+h_2\). Let us relate \(f(t,h_1,h_2)\) to bond rates. For that, consider two strategies (decided on date \(t\)):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Buy a zero-coupon bond of maturity \(h_2\) (price \(B(t,h_2)\)) and sell zero-coupon bonds of maturity \(h_1\) for the same amount (yielding a payoff of \(B(t,h_2)/B(t,h_1)\) on date \(t+h_1\)).
\item
  Enter a forward rate agreement between dates \(t+h_1\) and \(t+h_2\), whereby you receive 1 on date \(t+h_2\).
\end{enumerate}

These two strategies deliver the same payoffs on date \(t\) (the payoff is zero) and on date \(t+h_2\) (the payoff is 1). By absence of arbitrage, the payoffs on date \(t+h_1\) have to be the same. Therefore
\begin{eqnarray*}
\exp(-(h_2 - h_1)f(t,h_1,h_2)) &=& B(t,h_2)/B(t,h_1) \\
\Rightarrow f(t,h_1,h_2) &=& \frac{1}{h_2 - h_1}(\log[B(t,h_1)] - \log[B(t,h_2)]),
\end{eqnarray*}
which gives:
\begin{equation}
\boxed{f(t,h_1,h_2) = \frac{h_2 R(t,h_2) - h_1 R(t,h_1)}{h_2 - h_1}.}\label{eq:forward}
\end{equation}
In an affine model (where \(R(t,h)\) is an affine function of the state vector \(w_t\)), forward rates are linear in the state vector \(w_t\).

\hypertarget{RiskFreeAffine}{%
\section{The Affine Case}\label{RiskFreeAffine}}

\hypertarget{affine-yields}{%
\subsection{Affine yields}\label{affine-yields}}

In this subsection, we consider the case where the state vector \(w_t\) is affine under both \(\mathbb{P}\) and \(\mathbb{Q}\). If the nominal short-term rate is affine in \(w_t\), i.e., if \(r_t = \omega_0 + \omega'_1 w_t\), then:
\begin{eqnarray*}
B(t,h) &=& \mathbb{E}^{\mathbb{Q}}_t \exp (-r_{t}-\dots-r_{t+h-1})\\
&=& \exp(-h\omega_0 - \omega'_1 w_t) \color{blue}{\mathbb{E}^{\mathbb{Q}}_t \exp (- \omega'_1 w_{t+1}-\dots- \omega'_1 w_{t+h-1})}.
\end{eqnarray*}
The (blue) expectation is easily computed using the recursive equations of Lemma \ref{lem:MHLT} (see Example \ref{exm:nominalBth}), leading to:
\begin{equation}
R(t,h)= -  \frac{1}{h}   \log   B(t,h) = A_h'w_t + B_h.\label{eq:RthAB}
\end{equation}
It is easily seen that we can also get:
\begin{equation}
R^{EH}(t,h) = {A^{EH}_h}'w_t + B^{EH}_h.\label{eq:RthABEH}
\end{equation}
Moreover, if inflation is also affine in \(w_t\), i.e., if \(\pi_{t} = \bar\omega_0 + \bar\omega'_1 w_t\), then real yields are given by:
\begin{eqnarray*}
\bar{B}(t,h) &=& \mathbb{E}^{\mathbb{Q}}_t \exp(-r_{t}-\dots-r_{t+h-1}+\pi_{t+1}+\dots+\pi_{t+h})
\end{eqnarray*}
(see Example \ref{exm:realBth}) which also leads to:
\begin{equation}
\bar{R}(t,h) = -  \frac{1}{h}   \log   \bar{B}(t,h) = \bar{A}_h'w_t + \bar{B}_h.\label{eq:RbarthAB}
\end{equation}
Eqs. \eqref{eq:RthAB} and \eqref{eq:RthABEH} imply that term premiums are affine in \(w_t\) (see Eq. \eqref{eq:TP}). Specifically:
\[
TP(t,h) = R(t,h) - E^{EH}(t,h) = B_h - B_h^{EH} + (A_h - A_h^{EH})'w_t.
\]
Expected excess returns resulting from holding zero-coupon bonds are also affine in \(w_t\). Indeed, holding a maturity-\(h\) zero-coupon bond for one period provides the following expected gross return:
\[
\mathbb{E}_t\left(\frac{B(t+1,h-1)}{B(t,h)}\right) = \mathbb{E}_t\left(\exp(B_{h-1} - B_h + A_{h-1}'w_{t+1} - A_h'w_{t})\right),
\]
which is clearly exponential affine in \(w_t\) if \(w_t\) is an affine process. Therefore, the expected excess return, that is:
\[
\log \mathbb{E}_t\left(\frac{B(t+1,h-1)}{B(t,h)}\right) - r_t
\]
is also affine in \(w_t\) in this context. The fact that excess returns are affine in this context is exploited in the estimation approach proposed by \citet{Adrian_Crump_Moench_2013}.

Moreover, \emph{conditional expectations} of future interest rates (real or nominal) and of term premiums are also affine in \(w_t\). In particular:
\begin{equation}
\mathbb{E}_t[R(t+k,h)] = \mathbb{E}_t[{A_h}'w_{t+k} + B_h] = {A_h}'\mathbb{E}_t(w_{t+k}) + B_h,\label{eq:condmeanRth}
\end{equation}
and \(\mathbb{E}_t(w_{t+k})\) is affine in \(w_t\) (see Eq. \eqref{eq:condmean}). This can notably be used at the estimation stage, if one wants to fit survey data (see Section XXX).

Similarly, \emph{conditional variances} of future interest rates (real or nominal) and of term premiums are affine in \(w_t\). In particular:
\begin{equation}
\mathbb{V}ar_t[R(t+k,h)] = \mathbb{V}ar_t[{A_h}'w_{t+k} + B_h] = {A_h}'\mathbb{V}ar_t(w_{t+k})A_h,\label{eq:condvarRth}
\end{equation}
where the components of \(\mathbb{V}ar_t(w_{t+k})\) (and therefore \(\mathbb{V}ar_t[R(t+k,h)]\)) is affine in \(w_t\) (see Eq. \eqref{eq:condvar}). This can also be used at the estimation stage, if one wants to fit (proxies of) conditional variances \citep{zarg_2017}.

\hypertarget{maximum-sharpe-ratio}{%
\subsection{Maximum Sharpe ratio}\label{maximum-sharpe-ratio}}

In an affine model, the maximum Sharpe ratio is easily computed. This has been noted early by \citet{Duffee_2010} for the Gaussian model; \citet{Gourieroux_Monfort_Mouabbi_Renne_2021} and \citet{Pallara_Renne_2023} use it in more sophisticated affine models.

Let us derive the maximum Sharpe ratio in the context of a genral affine framework. Eq. \eqref{eq:CovRP} implies that
\[
\mathbb{E}_t\underbrace{\left(\frac{p_{j,t+1}}{p_{j,t}} - \exp(r_t)\right)}_{=xs_{j,t+1},\mbox{ excess return}} =  - \exp(r_t) \mathbb{C}ov_t\left(\mathcal{M}_{t,t+1},\frac{p_{j,t+1}}{p_{j,t}}\right),
\]
and, using \(|\mathbb{C}ov(X,Y)| \le \sqrt{\mathbb{V}ar(X)\mathbb{V}ar(Y)}\), we get the \citet{Hansen_Jagannathan_1991} bound:
\begin{equation}
\underbrace{\frac{\mathbb{E}_t(xs_{j,t+1})}{\sqrt{\mathbb{V}ar_t(xs_{j,t+1})}}}_{\mbox{Sharpe ratio}} \le \underbrace{\frac{\sqrt{\mathbb{V}ar_t(\mathcal{M}_{t,t+1})}}{\mathbb{E}_t(\mathcal{M}_{t,t+1})}}_{\mbox{Maximum Sharpe ratio}}.
\end{equation}

If the S.D.F. is given by \(\mathcal{M}_{t,t+1} = \exp[-r_{t}+\alpha'_tw_{t+1}-\psi_t(\alpha_t)]\) (Eq. \eqref{eq:keySDF}), and using that \(\mathbb{E}_t(\mathcal{M}_{t,t+1}^2)=\exp(-2r_t+\psi_t(2\alpha_t)-2\psi_t(\alpha_t))\) we get:
\[
\mbox{Maximum Sharpe ratio} = \sqrt{\exp(\psi_t(2\alpha_t)-2\psi_t(\alpha_t)) - 1}.
\]

\hypertarget{RiskFreeGaussian}{%
\section{Gaussian Affine Term Structure Model}\label{RiskFreeGaussian}}

The Gaussian Affine Term Structure Model (GATSM) is a \emph{Workhorse} model, widely used in academic and economic-policy circles. In a GATSM, \(w_t\) follows a Gaussian vector autoregressive model, and is therefore affine under \(\mathbb{P}\). The S.D.F. is exponential affine in \(w_t\), which implies that it is also affine under \(\mathbb{Q}\) (see Subsection XXX). Since the components of \(w_t\) are valued in \(\mathbb{R}\), one can easily introduce macro-factors among the state variables.

Let us be more specific. The state vector \(w_t\) follows:
\begin{equation}
w_{t+1} = \mu + \Phi w_{t} + \Sigma^{1/2} \varepsilon_{t+1}, \mbox{ where } \varepsilon_{t} \sim  i.i.d. \mathcal{N}(0,Id).\label{eq:GaussianVAR1}
\end{equation}
(The fact that we consider a VAR(1) process is without loss of generality since a VAR(p) admits a VAR(1) companion representation.)

This implies the following Laplace transform for \(w_t\) (see Example \ref{exm:Gaussian}):
\[
\psi_t(u) = \log \mathbb{E}_t(\exp(u'w_{t+1})|\underline{w_t}) = \color{blue}{u'\mu + u'\Phi w_t + \frac{1}{2}u'\Sigma'u}.
\]
Using the notations of Eq. \eqref{eq:keySDF}, the s.d.f. is defined as:
\[
\mathcal{M}_{t,t+1} = \exp(- r_t + \alpha_t'w_{t+1} - \psi_t(\alpha_t)), \mbox{ where } \alpha_t = \alpha_0 + \alpha_1'w_t.
\]

In that case, using Eq. \eqref{eq:transfoPQ}, we get:
\begin{eqnarray*}
\psi_t^{\mathbb{Q}}(u) &=& \psi_t(u + \alpha_t) - \psi_t(\alpha_t)\\
&=& (u + \alpha_t)'\mu + (u + \alpha_t)'\Phi w_t + \frac{1}{2}(u + \alpha_t)'\Sigma(u + \alpha_t) \\
&& - \left(\alpha_t'\mu + \alpha_t'\Phi w_t + \frac{1}{2}\alpha_t'\Sigma\alpha_t\right) \\
&=& \color{blue}{u' \left(\mu + \Sigma \alpha_0 \right) + u'(\Phi + \Sigma \alpha_1')w_t  + \frac{1}{2}u'\Sigma'u}.
\end{eqnarray*}
The \(\mathbb{Q}\)-dynamics of \(w_t\) is (from Example \ref{exm:Gaussian}):
\[
w_{t+1} = \mu + \Sigma  \alpha_0 + (\Phi + \Sigma \alpha_1')  w_{t} + \Sigma^{1/2} \varepsilon^*_{t+1}, \mbox{ where } \varepsilon^*_{t} \sim  i.i.d. \mathcal{N}^{\mathbb{Q}}(0,Id).
\]
Hence, \(w_t\) also follows a VAR process under \(\mathbb{Q}\) since the previous equation rewrites:
\[
w_{t+1} = \mu^{\mathbb{Q}} + \Phi^{\mathbb{Q}} w_{t} + \Sigma^{1/2} \varepsilon^*_{t+1},
\]
where \(\mu^{\mathbb{Q}} = \mu + \Sigma \alpha_0\) and \(\Phi^{\mathbb{Q}}=\Phi + \Sigma \alpha_1'\).

With affine specifications of the nominal short term rate (\(r_{t} = \omega_0 + \omega'_1 w_t\)) and of the inflation rate (\(\pi_{t} = \bar\omega_0 + \bar\omega'_1 w_t\)), we obtain affine formulas for nominal and real yields of any maturity (Eqs. \eqref{eq:RthAB} and \eqref{eq:RbarthAB}).

\begin{example}[Kim and Wright (2005)]
\protect\hypertarget{exm:KimWright}{}\label{exm:KimWright}

This model is a three-factor \emph{yield-only model} (no macro variables, except inflation in one variant of the model), where the short-term rate reads \(r_t = \omega_0 + \omega_{1,1} w_{1,t} +\omega_{1,2} w_{2,t} +\omega_{1,3} w_{3,t}\).

The model estimated by Kalman filter (see Subsection,\ref{Estimation:KF}; the state-space model (Def. \ref{def:LSSM}) includes survey-based variables (see Subsection \ref{EstimationPersistency}).

Outputs are \href{https://www.federalreserve.gov/pubs/feds/2005/200533/200533abs.html}{regularly updated by the Federal Reserve Board}.

Monthly data on the 6-month and 12-month-ahead forecasts of the three-month T-Bill yield from Blue Chip Financial Forecasts and semiannual data on the average expected three-month T-Bill yield from 6 to 11 years.

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/fredKW-1} \caption{Kim and Wright (2005) outputs.}\label{fig:fredKW}
\end{figure}

\end{example}

\begin{example}[Ang and Piazzesi (2003)]
\protect\hypertarget{exm:AngPiazzesi}{}\label{exm:AngPiazzesi}

\citet{Ang_Piazzesi_2003} propose one of the first paper mixing latent and macrovariables. The set up is also of the form Eq. \eqref{eq:GaussianVAR1}, except that the VAR features several lags.\footnote{Note that a VAR with \(p\) lags (i.e., a VAR(\(p\))) admits a VAR(1) companion form.} In their model, \(w_t = [f^{o}_{1,t},f^{o}_{2,t},f^{u}_{1,t},f^{u}_{2,t},f^{u}_{3,t}]'\) where:

\begin{itemize}
\tightlist
\item
  \(f^{o}_{1,t}\) is the first Principal Component of a set of 3 price indexes (growth rates)
\item
  \(f^{o}_{2,t}\) is the first Principal Component of a set of 4 real activity proxies (HELP, EMPLOY, IP, UE).
\item
  \(f^{u}_{i,t}\) are unobserved, or latent, factors.
\end{itemize}

The nominal short-term rate follows a Taylor rule. And latent factors are estimated via \emph{inversion techniques} (Subsection \ref{EstimationInversion}).

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/AngPiazzesi1} 

}

\caption{Source: Ang and Piazzesi (1998). Impulse response functions.}\label{fig:figAngPiazzesi}
\end{figure}

\end{example}

\begin{example}[Joslin, Priebsch and Singleton (2014)]
\protect\hypertarget{exm:JPS}{}\label{exm:JPS}

\citet{Joslin_Priebsch_Singleton_2014} first note that affine models stating that the short term rate is affine in macro factors imply that macro-factors are \emph{spanned} by the yield curve: macro-factors should be perfectly explained by yields of different maturities. Further, they show that this is not the case in the data. (That is, regressing macro factors on yields provides \(R^2\) that are far from one.)

They propose a model where macro factors are unspanned by the yield curve, but can still help predict yields. In their model, \(w_t = [\mathcal{P}_t',M_t']'\), where \(\mathcal{P}_t\) are yield factors (\(\approx\) principal components) and \(M_t\) are macro factors. The model is as follows:
\begin{eqnarray*}
r_t &=& \omega_{0} + \omega_{\mathcal{P}}'\mathcal{P}_t \\
\left[\begin{array}{c}\mathcal{P}_t \\ M_t \end{array}\right]
&=&
\left[\begin{array}{cc}\Phi_{\mathcal{P}\mathcal{P}}&\Phi_{\mathcal{P}M} \\
\Phi_{M\mathcal{P}}&\Phi_{MM} \end{array}\right]
\left[\begin{array}{c}\mathcal{P}_{t-1} \\ M_{t-1} \end{array}\right] + \Sigma \varepsilon_t \\
\left[\begin{array}{c}\mathcal{P}_t \\ M_t \end{array}\right] &=& \mu +
\left[\begin{array}{cc}\Phi^{\mathbb{Q}}_{\mathcal{P}\mathcal{P}}&{\color{red}0} \\
\Phi^{\mathbb{Q}}_{M\mathcal{P}}&\Phi^{\mathbb{Q}}_{MM} \end{array}\right]
\left[\begin{array}{c}\mathcal{P}_{t-1} \\ M_{t-1} \end{array}\right] + \Sigma \varepsilon^{\mathbb{Q}}_t,
\end{eqnarray*}
where \(\varepsilon_t\) and \(\varepsilon^{\mathbb{Q}}_t\) are \(\mathcal{N}(0,Id)\) under \(\mathbb{P}\) and \(\mathbb{Q}\), respectively.

\(M_t\) does Granger-cause \(\mathcal{P}_t\) under \(\mathbb{Q}\) and \(r_t\) is affine in \(\mathcal{P}_t\) (only).

In this context, yields \(R(t,h)\) are affine in \(\mathcal{P}_t\) (only). However \(M_t\) does Granger-cause \(\mathcal{P}_t\) under \(\mathbb{P}\), that is, macro-shocks affect the yield curve.

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/JPS_IRF} 

}

\caption{Source: Joslin, Priebsch, and Singleton (2014). Impulse response functions.}\label{fig:JPSIRF}
\end{figure}

\end{example}

\begin{example}[Ang, Boivin, Dong and Loo-Kung (2011)]
\protect\hypertarget{exm:Angetal2011}{}\label{exm:Angetal2011}

\citet{Ang_Boivin_Dong_LooKung_2011} propose a macro-finance model based on a quadratic framework. The short-term rate follows a Taylor rule with time-varying parameters:
\[
r_t = \omega_0 + a_t g_t + b_t \pi_t,
\]
where \(x_t=(g_t,\pi_t,a_t,b_t)'\) follows a Gaussian VAR. This is the context described in Example \ref{exm:QGVAR1}. The previous equation shows that \(r_t\) is linear in \(w_t = (x_t,vec(x_t x_t')')'\). Specifically:
\[
r_t = \omega_0 + \omega_1'w_t,
\]
with \(\omega_1 = [v,vec(V)]'\), where
\[
v = \left[
\begin{array}{c}
0\\
0\\
0\\
0
\end{array}
\right] \quad \mbox{and} \quad V = \left[
\begin{array}{cccc}
0 & 0& 1/2&0\\
0& 0& 0&1/2\\
1/2& 0& 0&0\\
0&1/2 &0 &0
\end{array}
\right].
\]

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figures/Ang_Boivin_loadings} 

}

\caption{Source: Ang, Boivin, Dong, Loo-Kung (2011). Estimated factor loadings ($a_t$ and $b_t$).}\label{fig:AngBoivin}
\end{figure}

\end{example}

\hypertarget{RiskFreeNonNegative}{%
\section{Non-Negative Affine Term Structure Model}\label{RiskFreeNonNegative}}

In the presence of physical currency, absence of arbitrage opportunity and of storing cost of cash, nominal interest rates should be nonnegative. Many standard models (e.g.~Gaussian ATSM) are non consistent with non-negative nominal yields. The period of extremely low interest rates challenged these models. Against this backdrop, approaches have been developed to accommodate zero (or effective) lower bounds. We provide two examples; only the second is an affine model.

\hypertarget{the-shadow-rate-approach}{%
\subsection{The shadow-rate approach}\label{the-shadow-rate-approach}}

The shadow-rate model is originally due to \citet{Black_1995}. In this model, the short term rate is given by:
\begin{equation}
r_t = \max(s_t,\underline{r}),\label{eq:SRSTR}
\end{equation}
where \(s_t\) is the shadow short-term interest rate and \(\underline{r}\) is the effective lower bound (\(\le 0\)). While \(s_t\) can be real-valued, the short term rate is nonnegative under \eqref{eq:SRSTR}. In shadow-rate models, the shadow rate \(s_t\) is usually a linear combination of a vector \(w_t\) that follows a Gaussian auto-regressive model. While \(s_t\) is a linear combination of components of an affine process, this is not the case for \(r_t\). As a result, pricing formula are not available in closed-form. Approximation formula have been proposed by, e.g., \citet{Krippner_2013}, \citet{Priebsch_2013}, \citet{Wu_Xia_2016}.

Let us describe the latter approach \citep{Wu_Xia_2016}. As in Subsection \ref{RiskFreeGaussian}, the S.D.F. is defined as:
\[
\mathcal{M}_{t,t+1} = \exp(- r_t + \alpha_t'w_{t+1} - \psi_t(\alpha_t)), \mbox{ where } \alpha_t = \alpha_0 + \alpha_1'w_t,
\]
(this is Eq. \eqref{eq:keySDF}), but the short-term rate \(r_t\) is given by \(r_t = \max(s_t,0)\), with
\[
s_t = \delta_0 + \delta_1' w_t.
\]

The approximation approach proposed by \citet{Wu_Xia_2016} is based on an approximation to the conditional expectations of forward rates. Using the results of Subsection \ref{FWD}, we have (Eq. \eqref{eq:forward}):
\[
f_{n-1,n,t} = n R_{t,n} - (n-1) R_{t,n-1}.,
\]
for \(n>0\) (and using \(R_{t,0}=0\)). This implies that:
\[
R_{t,h} =  \frac{1}{h}(f_{t,0,1}+f_{t,1,2}+\dots+f_{t,h-1,h}).
\]

The approximation of \citet{Wu_Xia_2016} consists in finding approximations of the forward rates \(f_{t,n-1,n}\) (denoted by \(\tilde{f}_{t,n-1,n}\), say) and to use them in the previous equation to get:
\begin{equation}
\boxed{R_{t,h} \approx  \frac{1}{h}\left(\tilde{f}_{t,0,1}+\tilde{f}_{t,1,2}+\dots+\tilde{f}_{t,h-1,h}\right).}\label{eq:RapproxSR}
\end{equation}

Using that, for any random variable \(Z\), we have \(\log(\mathbb{E}[e^Z]) \approx \mathbb{E}[Z] + \frac{1}{2} \mathbb{V}ar[Z]\) (based on a second order Taylor expansion), \citet{Wu_Xia_2016} further show that:
\begin{eqnarray}
f_{t,n,n+1} &=& -\log\left(\mathbb{E}_t^{\mathbb{Q}}\left(e^{-\sum_{j=0}^n r_{t+j}}\right)\right) + \log\left(\mathbb{E}_t^{\mathbb{Q}}\left(e^{-\sum_{j=0}^{n-1} r_{t+j}}\right)\right)\\
&\approx& \mathbb{E}_t^{\mathbb{Q}}[r_{t+n}] - \frac{1}{2}\left(\mathbb{V}ar_t^{\mathbb{Q}}\left(\sum_{j=0}^n r_{t+j}\right)-\mathbb{V}ar_t^{\mathbb{Q}}\left(\sum_{j=0}^{n-1} r_{t+j}\right)\right).
\end{eqnarray}

The expectation can be computed analytically:
\[
\mathbb{E}_t^{\mathbb{Q}}[r_{t+n}] = \underline{r} + \sigma_n^{\mathbb{Q}}g\left(\frac{\bar{a}_n + b_n'X_t - \underline{r}}{\sigma_n^{\mathbb{Q}}}\right),
\]
where \(g(x)= x\Phi(x)-\phi(x)\), \(\Phi\) and \(\phi\) being the c.d.f. and p.d.f. of the standard normal distribution, respectively, and where
\begin{eqnarray*}
\bar{a}_n &=& \delta_0 + \delta_1'\left(\sum_{j=0}^{n-1} \left[\Phi^{\mathbb{Q}}\right]^j\right)\mu^{\mathbb{Q}}\\
b_n' &=& \delta_1'\left(\Phi^{\mathbb{Q}}\right)^n.
\end{eqnarray*}
They also show that
\[
\frac{1}{2}\left(\mathbb{V}ar_t^{\mathbb{Q}}\left(\sum_{j=0}^n r_{t+j}\right)-\mathbb{V}ar_t^{\mathbb{Q}}\left(\sum_{j=0}^{n-1} r_{t+j}\right)\right) \approx \Phi\left(\frac{\bar{a}_n + b_n'X_t - \underline{r}}{\sigma_n^{\mathbb{Q}}}\right)\times(\bar{a}_n - a_n),
\]
where
\[
a_n = \bar{a}_n - \frac{1}{2}\sigma_n^{\mathbb{Q}},
\]
with
\[
\sigma_n^{\mathbb{Q}} := \mathbb{V}ar^{\mathbb{Q}}_t\left(s_{t+n}\right)= \delta_1'\left(\sum_{j=0}^{n-1} \left[\Phi^{\mathbb{Q}}\right]^j\right)\Sigma \Sigma' \left(\sum_{j=0}^{n-1} \left[\Phi^{\mathbb{Q}}\right]^j\right)'\delta_1.
\]
They finally obtain:
\[
\boxed{f_{t,n,n+1} \approx \tilde{f}_{t,n,n+1} = \underline{r} + \sigma_n^{\mathbb{Q}}g\left(\frac{a_n + b_n'X_t - \underline{r}}{\sigma_n^{\mathbb{Q}}}\right),}
\]
which is used in \eqref{eq:RapproxSR} to obtain an approximation to \(R_{t,h}\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TSModels)}
\CommentTok{\# Specify model:}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{2} \CommentTok{\# number of factors}
\NormalTok{rho }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,n,n)}
\FunctionTok{diag}\NormalTok{(rho) }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{97}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,n,}\DecValTok{1}\NormalTok{)}
\NormalTok{Sigma }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(n)}
\NormalTok{delta}\FloatTok{.0} \OtherTok{\textless{}{-}} \DecValTok{0}\NormalTok{;delta}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(.}\DecValTok{01}\NormalTok{,n)}
\NormalTok{r.bar }\OtherTok{\textless{}{-}} \DecValTok{0} \CommentTok{\# r = max(s,r.bar) [i.e., r.bar=0 in standard model]}
\NormalTok{Model }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{rho =}\NormalTok{ rho,}\AttributeTok{mu =}\NormalTok{ mu,}\AttributeTok{Sigma =}\NormalTok{ Sigma,}
  \AttributeTok{delta.0 =}\NormalTok{ delta}\FloatTok{.0}\NormalTok{,}\AttributeTok{delta.1 =}\NormalTok{ delta}\FloatTok{.1}\NormalTok{,}\AttributeTok{r.bar =}\NormalTok{ r.bar)}
\CommentTok{\# Simulate model and compute shadow rate:}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{simul.var}\NormalTok{(Model,}\AttributeTok{nb.sim =} \DecValTok{200}\NormalTok{) }\CommentTok{\# simulated path}
\NormalTok{s }\OtherTok{\textless{}{-}}\NormalTok{ delta}\FloatTok{.0} \SpecialCharTok{+}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ delta}\FloatTok{.1}
\CommentTok{\# Compute yields:}
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{compute.price.WX}\NormalTok{(Model,X,}\AttributeTok{max.H=}\DecValTok{100}\NormalTok{)}
\CommentTok{\# Prepare plots:}
\FunctionTok{par}\NormalTok{(}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{2}\NormalTok{,.}\DecValTok{75}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(s,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{xlab=}\StringTok{"time"}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{main=}\StringTok{"(a) Shadow rate"}\NormalTok{)}
\NormalTok{t }\OtherTok{\textless{}{-}} \DecValTok{50} \CommentTok{\#t \textless{}{-} which(s==min(s))}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{v=}\NormalTok{t,}\AttributeTok{col=}\StringTok{"dark grey"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lty=}\DecValTok{3}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{vec.f[t,],}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{xlab=}\StringTok{"maturity"}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}
     \AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{main=}\StringTok{"(b) yields and forward rates"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(res}\SpecialCharTok{$}\NormalTok{vec.y[t,],}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }
       \FunctionTok{c}\NormalTok{(}\StringTok{"forward rates"}\NormalTok{,}\StringTok{"yields to maturity"}\NormalTok{),}\AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{),}\AttributeTok{lty=}\DecValTok{1}\NormalTok{,}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"red"}\NormalTok{),}\AttributeTok{bg =} \StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/WuXia-1} 

}

\caption{bla bla bla.}\label{fig:WuXia}
\end{figure}

\hypertarget{the-auto-regressive-gamma-approach}{%
\subsection{The auto-regressive gamma approach}\label{the-auto-regressive-gamma-approach}}

\citet{zarg_2017} introduce an affine framework where the short-term rate can stay at zero for a prolonged period of time and with a stochastic lift-off probability.

Under \(\mathbb{P}\) and \(\mathbb{Q}\), the state vector \(w_t\) follows a multi-variate auto-regressive gamma (VARG) process---a multivariate extension of Example \ref{exm:ARG1}. Conditionally on \(\underline{w_t}\), the \(n\) components of \(w_{t+1}\) are independent and distributed as follows:
\begin{equation}
\frac{w_{i,t+1}}{\mu_i} \sim \gamma(\nu_i+z_{i,t}) \quad \mbox{where} \quad z_{i,t} \sim {\mathcal P} \left( \alpha_i + \beta_i' w_t \right).\label{eq:VARG}
\end{equation}
If \(\mu = (\mu_1,\dots,\mu_n)'\), \(\alpha = (\alpha_1,\dots,\alpha_n)'\), \(\nu = (\nu_1,\dots,\nu_n)'\) and \(\beta = (\beta_1,\dots,\beta_n)\), then
\begin{eqnarray*}
\varphi_t(u) &=& \exp\left[\left(\frac{u \odot \mu}{1 - u \odot \mu}\right)'\beta' w_t \right.\\
&& \left. + \alpha'\left(\frac{u \odot \mu}{1 - u \odot \mu}\right) - \nu'\log(1 - u \odot \mu)\right],
\end{eqnarray*}
where \(\odot\) denotes the element-by-element multiplication and, where, with abuse of notation, the division and log operators work element-by-element when applied to vectors.

In their baseline model, \citet{zarg_2017} use four factors. They set \(\nu_1 = \nu_2 = 0\), implying that \(w_{1,t}\) and \(w_{2,t}\) can stay at zero (see Example \ref{exm:ARG1}). The short-term rate \(r_t\) is posited to be an affine combination of \(w_{1,t}\) and \(w_{2,t}\), that is:
\[
r_t = \omega'w_t = \omega_{1} w_{1,t} + \omega_{2} w_{2,t},
\]
hence, it can stay at zero.

Factors \(w_{3,t}\) and \(w_{4,t}\) Granger-cause \(w_{1,t}\) and \(w_{2,t}\), thereby causing \(r_t\). As a result, for \(h \ge 2\), \(R(t,h)\) is a non-zero combination of the four components of \(w_t\).

For the same reason, when \(r_t=0\), the lift-off probability depends on \(w_{3,t}\) and \(w_{4,t}\). The framework offers closed-form solutions for lift-off probabilities. Indeed, using Lemma \ref{lemma:mass}:
\[
\mathbb{P}_t(\alpha'w_{t+h}=0) = \lim_{u \rightarrow -\infty} \varphi_{t,h}(0,\dots,0,u\alpha),
\]
where \(\varphi_{t,h}\) is the multi-horizon Laplace transform defined in Eq. \eqref{eq:multiLT}, which can be computed using Proposition \ref{prp:reverseMLT}. We have:
\begin{equation}
\left\{
\begin{array}{l}
\mathbb{P}_t(r_{t+h}>0) = 1 - \lim_{u \rightarrow -\infty} \varphi_{t,h}(0,\dots,0,u\omega) \\ \\
\mathbb{P}_t(r_{t+1}=0,\dots,r_{t+h}=0) = \lim_{u \rightarrow -\infty} \varphi_{t,h}(u\omega,\dots,u\omega,u\omega) \equiv p_{h}\\ \\
\mathbb{P}_t(r_{t+1}=0,\dots,r_{t+h-1}=0,r_{t+h}>0) = p_{h-1} - p_h.
\end{array}
\right.
\end{equation}
Other lift-off probabilities, of the type \(\mathbb{P}_t[R(t+h,k)>threshold]\), can be derived from Eq. \eqref{eq:DPS}.

\citet{zarg_2017} esitmate this model by means of Kalman filtering techniques (see Subsection \ref{EstimationKF}). Observed variables include (levels of) yields, as well as survey-based forecasts of yields (see Subsection \ref{EstimationPersistency} and (e-GARCH-based) proxies of conditional variances (see Eq. \eqref{eq:condvar}).

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/Figure_fit_ZARG} 

}

\caption{Source: Monfort et al. (2017). Model fit of conditional variances and surveys of professional forecasters.}\label{fig:fitZarg}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/Figure_LiftOff} 

}

\caption{Source: Monfort et al. (2017). Lift-off probabilities.}\label{fig:liftOff}
\end{figure}

\hypertarget{estimation-of-affine-asset-pricing-models}{%
\chapter{Estimation of affine asset-pricing models}\label{estimation-of-affine-asset-pricing-models}}

\hypertarget{EstimationSSModel}{%
\section{State-Space Model}\label{EstimationSSModel}}

By nature, dynamic asset-pricing models are \emph{state-space models}: The dynamics of all variables, gathered in vector \(y_t\) (yields, equity returns, macroeconomic variables, survey-based variables) are accounted for by state variables (\(w_t\)). The equations defining the relationship between the other variables and the state variables are called \emph{measurement equations} (Eq. \eqref{eq:measeq}). The equations defining the dynamics of the state variables are called \emph{transition equations} (Eq. \eqref{eq:transeq}).

In the case where \(w_t\) is an affine process (see Definition \ref{def:Car1}), the transition equations admit a VAR(1) representation (Proposition \ref{prp:affineVAR}). In that case, the state-space model is said to be linear, as formalized by the following definition. This defintion introduces, in particular, the notion of \emph{measurement errors}.

\begin{definition}[Linear State-Space Model]
\protect\hypertarget{def:LSSM}{}\label{def:LSSM}A linear state-space model writes as follows:
\begin{eqnarray}
\underset{(m \times 1)}{y_t}  &=& A + Bw_t + \eta_t  \quad \mbox{with }  \eta_t \sim i.i.d. \mathcal{N}(0,\Omega) \label{eq:measeq} \\
\underset{(n \times 1)}{w_t} & =& \mu + \Phi w_{t-1} + \Sigma^{\frac{1}{2}}(w_{t-1}) \varepsilon_t,\label{eq:transeq}
\end{eqnarray}
where \(\varepsilon_t\) is a martingale difference sequence satisfying \(\mathbb{V}ar_t(\varepsilon_{t+1}) = Id\). The components of \(\eta_t\) are measurement errors.
\end{definition}

\begin{quote}
\textbf{Note:} Eq. \eqref{eq:transeq} derives from Proposition \ref{prp:affineVAR} (Eq. \eqref{eq:VARw}).
\end{quote}

In practice, one can distinguish two situations: (a) all state variables (components of \(w_t\)) are observed and (b) some of these variables are latent. What do we mean by \emph{model estimation} in case (b)? There are different situations:

\begin{itemize}
\tightlist
\item
  (b.i) We know the model parameters but we want to recover the latent factors---for instance to compute model-implied prices.
\item
  (b.ii) We know neither the model parameters nor the latent variables, we want to estimate both of them.
\item
  (b.iii) We know neither the model parameters nor the latent variables, we are just interested in the model parameters.
\end{itemize}

In case (a): One can resort to standard estimation techniques (GMM, Maximum Likelihood) to estimate model parameters. Take for instance the maximum-likelihood case, we have:
\begin{eqnarray*}
f(y_t,w_t|\underline{y_{t-1}},\underline{w_{t-1}}) &=& f(y_t|\underline{y_{t-1}},\underline{w_{t}}) \times \underbrace{f(w_t|\underline{y_{t-1}},\underline{w_{t-1}})}_{= f(w_t|\underline{w_{t-1}})}\\
&=& \mathbf{n}(y_t;A + Bw_t,\Omega) f(w_t|\underline{w_{t-1}}),
\end{eqnarray*}
where \(\mathbf{n}(x;\mu,\Omega)\) denotes the evaluation, at vector \(x\), of the p.d.f. of the multivariate normal distribution \(\mathcal{N}(\mu,\Omega)\). That is, if \(x\) is a \(m\)-dimensional vector:
\begin{equation}
\mathbf{n}(x;\mu,\Omega) = \frac{1}{\sqrt{(2 \pi)^{m}|\Omega|}} \exp\left(-\frac{1}{2}\{x - \mu\}'\Omega^{-1}\{x-\mu\}\right).\label{eq:varPHI}
\end{equation}
Once this conditional p.d.f. is known, the total likelihood is given by (conditional on \(y_0\) and \(w_0\)):
\[
\prod_{t=1}^T f(y_t,w_t|\underline{y_{t-1}},\underline{w_{t-1}}).
\]
Of course, \(f(w_t|\underline{w_{t-1}})\) depends on the process chosen for \(w_t\). If it is complicated to compute, one can employ Pseudo Maximum Likelihood \citep{Gourieroux_Monfort_Trognon_1984}. The p.d.f. may involve, for instance, an infinite sum, which is the case in the ARG case of Example \ref{exm:ARG1}. When \(w_t\) is affine, the Pseudo Maximum Likelihood approach consists in replacing \(f(w_t|\underline{w_{t-1}})\) by:
\[
\mathbf{n}(w_t;\mu + \Phi w_{t-1},\Sigma(w_t)),
\]
where \(\mu\), \(\Phi\) and \(\Sigma(w_t)\) are introduced in Eqs. \eqref{eq:MUPHI} and \eqref{eq:SigmaWt} in Proposition \ref{prp:affineVAR}.

In case (b.iii), one can estimate the model by Generalized Method of Moments (GMM), fitting sample moments computed using observed variables (prices, yields, returns). In the context of affine processes, conditional and unconditional moments of the state vector \(w_t\) are available in closed from, as shown by Eqs. \eqref{eq:condmean}, \eqref{eq:condvar} and \eqref{eq:uncondmeanvar}. If the model-implied moments are not available in closed-form, one may have to to resort to the \emph{Simulated Method of Moments (SMM)} (see, e.g., \citet{GourMonf96} or \citet{Duffie_Singleton_1993}).

In cases (b.i) and (b.ii), one has to implement \emph{filtering methods}, on which we focus on in the following.

\hypertarget{Estimation:KF}{%
\section{Kalman-Filter-Based Approach}\label{Estimation:KF}}

\hypertarget{the-gaussian-linear-state-space-case}{%
\subsection{The Gaussian linear state-space case}\label{the-gaussian-linear-state-space-case}}

Let us start with a particular case of state-space model (Def. \ref{def:LSSM}) where \(\varepsilon_t\) is Gaussian and where \(\Sigma^{\frac{1}{2}}\) does not depend on \(w_t\), i.e.with a homoskedastic linear Gaussian state-space model.

Let's denote by \(\theta\) the vector of parameters that defines the model. For a given \(\theta\) and a sequence of observations \(\{y_1,\dots,y_T\}\), the Kalman filter computes the distribution of \(w_t\) given \(\{y_1,\dots,y_t\}\) (see Def. \ref{def:FiltvsSmooth}). This distribution is Gaussian, and obtained by a recursive algorithm. A byproduct of this algorithm is the likelihood function associated with \(\theta\) and \(\{y_1,\dots,y_T\}\). This opens the door to the estimation of \(\theta\) by MLE, maximizing this function. In this sense, Kalman-filter techniques can address Objective (b.ii).

Let us first introduce the notion of \emph{filtered} and \emph{smoothed} estimates of a latent variable (or vector of variables) \(w_t\):

\begin{definition}[Filtered versus smoothed estimates]
\protect\hypertarget{def:FiltvsSmooth}{}\label{def:FiltvsSmooth}The filtering and smoothing problems consist in computing the following conditional moments:
\begin{equation*}
\begin{array}{lccllllll}
\mbox{Filtering:} & w_{t|t} & = & \mathbb{E}(w_t|\underline{y_t}) & \mbox{and}  & P_{t|t} &=& \mathbb{V}ar(w_t|\underline{y_t})\\
\mbox{Smoothing:} & w_{t|T} & = & \mathbb{E}(w_t|\underline{y_T}) & \mbox{and} & P_{t|T} &=& \mathbb{V}ar(w_t|\underline{y_T}).
\end{array}
\end{equation*}
\end{definition}

The following proposition outlines the Kalman algorithm (see, e.g. \citet{Kim_Nelson_1999}).

\begin{proposition}[Kalman filter and smoother]
\protect\hypertarget{prp:KF}{}\label{prp:KF}If \(\varepsilon_t \sim \mathcal{N}(0,I)\) in the state-space defined in Def. \ref{def:LSSM}, then we have (\emph{filtering}):
\[
w_t|y_1,\dots,y_t \sim  \mathcal{N}(w_{t|t}|P_{t|t}),
\]
where \(w_{t|t}\) and \(P_{t|t}\) result from the following recursive equations:
\[
\boxed{
\begin{array}{ccl}
w_{t|t} &=& w_{t|t-1} + K_t \lambda_t\\
P_{t|t} &=& (I - K_t B)P_{t|t-1} \\ \\
\mbox{where (updating step)} \\
\lambda_t &=& y_t - A - Bw_{t|t-1}  \quad \mbox{(forecast error)}\\
S_{t|t-1} &=& \mathbb{V}ar(y_t|\underline{y_{t-1}}) = B P_{t|t-1} B' + \Omega\\
K_t &=& P_{t|t-1}B'S_{t|t-1}^{-1} \quad \mbox{(Kalman gain)} \\ \\
\mbox{and where (forecasting step)} \\
w_{t|t-1} &=& \mu + \Phi w_{t-1|t-1} \\
P_{t|t-1} &=& \Sigma + \Phi P_{t-1|t-1} \Phi' \quad (\Sigma = \Sigma^{\frac{1}{2}}{\Sigma^{\frac{1}{2}}}').
\end{array}
}
\]
The log likelihood is (recursively) computed as follows:
\begin{eqnarray}
\log \mathcal{L}(\theta;\underline{y_T}) &=& \frac{mT}{2}\log\left(2\pi\right) \label{eq:logLikKF}\\
&  & -\frac{1}{2}\sum_{t=1}^{T}\left(\log\left|S_{t | t-1}(\theta)\right|+\lambda'_{t}(\theta)S_{t\mid t-1}^{-1}(\theta)\lambda{}_{t}(\theta)\right). \nonumber
\end{eqnarray}

Moreover, we have (\emph{smoothing}):
\[
w_t|y_1,\dots,y_T \sim  \mathcal{N}(w_{t|T}|P_{t|T}),
\]
where \(w_{t|T}\) and \(P_{t|T}\) result from the following recursive equations:
\[
\boxed{
\begin{array}{ccl}
w_{t|T} & = & w_{t|t}+F_{t}(w_{t+1|T}-w_{t+1|t})\\
P_{t|T} & = & P_{t|t}+F_{t}(P_{t+1|T}-P_{t+1|t})F'_{t}\\ \\
\mbox{where} \\
F_{t} &=& P_{t|t}\Phi'_{t+1}P_{t+1|t}^{-1}.
\end{array}
}
\]
\end{proposition}

The following figure illustrates the updating step of the Kalman algorithm:

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/illusKF-1} \caption{Updating in the Kalman filter.}\label{fig:illusKF}
\end{figure}

The recursive equations of the Kalman filter need to be initialized. That is, one needs to provide initial values for \(w_{0|0}\), \(P_{0|0}\). Different possibilities have been proposed. One can for instance:

\begin{itemize}
\tightlist
\item
  Include the elements of(\(w_{0|0}\), \(P_{0|0}\)) among the parameters to estimate;
\item
  Set \(w_{0|0}\) and \(P_{0|0}\) to their unconditional values (using, e.g., Eq. \eqref{eq:uncondmeanvar});
\item
  Set \(w_{0|0}\) to a prior value and take either an arbitrary large value for \(P_{0\mid0}\) if the prior value is uncertain (which depicts a situation of \emph{diffuse prior}) or a small value for \(P_{0\mid0}\) if we are confident in this prior value \(w_{0|0}\).
\end{itemize}

\hypertarget{missing-observations}{%
\subsection{Missing observations}\label{missing-observations}}

In many application, one does not observe all the entries of \(y_t\) at every date. This arises for instance in situations where (i) measurement variables feature different frequencies, (ii) we have unreliable data for some period (that we prefer not to include among observations), (iii) some of the measurement variables are observed over a shorter time span.

These situations are easily addressed by Kalman filtering/smoothing (e.g., \citet{Chow_Lin_1971} or \citet{Harvey_Pierse_1984}). To accommodate missing observations in some of the \(y_t\)'s, one simply has to change the size of this vector (and of \(\lambda_t\), \(S_{t|t-1}\), \(A\) and \(B\)) for the relevant dates. Of course, the accuracy of \(w_{t|t}\) will tend to be lower during periods where one or several (or all) the entries of \(y_t\) are unobserved. (This will be apparent in the resulting covariance matrix of \(w_{t|t}\), namely \(P_{t|t}\).) The log-likelihood computation (Eq. \eqref{eq:logLikKF}) is still valid in this case; one simply has to adjust the number of observed variables at each iteration; that is, \(m\) then depends on time.

To illustrate, consider the following model:
\begin{eqnarray}
\left[\begin{array}{c}
y_{1,t}\\
y_{2,t}
\end{array}\right] & = &
\left[\begin{array}{cc}
\alpha_{1} & 0\\
0 & \alpha_{2}
\end{array}\right]
\left[\begin{array}{c}
y_{1,t-1}\\
y_{2,t-2}
\end{array}\right]+\left[\begin{array}{c}
\gamma_{1}\\
\gamma_{2}
\end{array}\right]w_{t}+ D\eta_t\label{eq_measur}\\
w_{t} & = & \phi w_{t-1}+\varepsilon_{t},\label{eq_trans}
\end{eqnarray}
where \(\eta_t \sim \mathcal{N}(0,Id)\).

We simulate a 100-period sample, we remove observations of \(y_{1,t}\) (respectively of \(y_{2,t}\)) between periods \(t=30\) and \(t=50\) (resp. between periods \(t=40\) and \(t=70\)), and try to recover the states \(w_t\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(TSModels) }\CommentTok{\# Kalman filter procedure in there.}
\CommentTok{\# Set model specifications:}
\NormalTok{alpha1 }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}\NormalTok{;alpha2 }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{95}\NormalTok{;Alpha }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{c}\NormalTok{(alpha1,alpha2))}
\NormalTok{d\_11 }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{;d\_12 }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}\NormalTok{;d\_21 }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{5}\NormalTok{;d\_22 }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(d\_11,d\_21,d\_12,d\_22),}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{gamma1 }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{;gamma2 }\OtherTok{\textless{}{-}} \DecValTok{2}\NormalTok{;Gamma }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(gamma1,gamma2),}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{phi }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{8}
\CommentTok{\# Simulate model:}
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{Y }\OtherTok{\textless{}{-}} \ConstantTok{NULL}\NormalTok{;X }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{Alpha.Y\_1 }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{);x }\OtherTok{\textless{}{-}} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T)\{}
\NormalTok{  Alpha.Y\_1 }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(Alpha.Y\_1,}\FunctionTok{c}\NormalTok{(Alpha }\SpecialCharTok{\%*\%}\NormalTok{ y))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ Alpha }\SpecialCharTok{\%*\%}\NormalTok{ y }\SpecialCharTok{+}\NormalTok{ Gamma }\SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+}\NormalTok{ D }\SpecialCharTok{\%*\%} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\NormalTok{  x }\OtherTok{\textless{}{-}}\NormalTok{ phi }\SpecialCharTok{*}\NormalTok{ x }\SpecialCharTok{+} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{  Y }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(Y,}\FunctionTok{t}\NormalTok{(y));X }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(X,x)\}}
\CommentTok{\# Define matrices needed in the Kalman\_filter procedures:}
\NormalTok{nu\_t }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,T,}\DecValTok{1}\NormalTok{)}
\NormalTok{H }\OtherTok{\textless{}{-}}\NormalTok{ phi;G }\OtherTok{\textless{}{-}}\NormalTok{ Gamma}
\NormalTok{mu\_t }\OtherTok{\textless{}{-}}\NormalTok{ Alpha.Y\_1}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{1}\NormalTok{;M }\OtherTok{\textless{}{-}}\NormalTok{ D}
\NormalTok{Sigma\_0 }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{phi}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# unconditional variance of w}
\NormalTok{rho\_0 }\OtherTok{\textless{}{-}} \DecValTok{0} \CommentTok{\# unconditional mean of w}
\NormalTok{filter.res   }\OtherTok{\textless{}{-}} \FunctionTok{Kalman\_filter}\NormalTok{(Y,nu\_t,H,N,mu\_t,G,M,Sigma\_0,rho\_0,}\AttributeTok{indic\_pos=}\DecValTok{0}\NormalTok{)}
\NormalTok{smoother.res }\OtherTok{\textless{}{-}} \FunctionTok{Kalman\_smoother}\NormalTok{(Y,nu\_t,H,N,mu\_t,G,M,Sigma\_0,rho\_0,}\AttributeTok{indic\_pos=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/Kalman10-1} \caption{XXXX.}\label{fig:Kalman10}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{15}\NormalTok{,.}\DecValTok{8}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(X,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(X[t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{r,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{r,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lty=}\DecValTok{1}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{,}
       \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(X[t]),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Filtered values of "}\NormalTok{,X[t],}\AttributeTok{sep=}\StringTok{""}\NormalTok{)),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Smoothed values of "}\NormalTok{,X[t],}\AttributeTok{sep=}\StringTok{""}\NormalTok{))),}
       \AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\CommentTok{\# line width}
       \AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"blue"}\NormalTok{),}
       \AttributeTok{seg.len =} \DecValTok{4}\NormalTok{,}
       \AttributeTok{bg =} \StringTok{"white"}
\NormalTok{)}

\FunctionTok{plot}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{Sigma\_tt),}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(X[t]),}
     \AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{S\_smooth)),}
                                            \FunctionTok{max}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{Sigma\_tt))))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{S\_smooth),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{,}
       \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Filtering standard error "}\NormalTok{,}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{Var}\NormalTok{(X[t}\SpecialCharTok{*}\StringTok{"|"}\SpecialCharTok{*}\NormalTok{t])),}\AttributeTok{sep=}\StringTok{""}\NormalTok{)),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Smoothing standard error "}\NormalTok{,}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{Var}\NormalTok{(X[t}\SpecialCharTok{*}\StringTok{"|"}\SpecialCharTok{*}\NormalTok{T])),}\AttributeTok{sep=}\StringTok{""}\NormalTok{))),}
       \AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\CommentTok{\# line width}
       \AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"red"}\NormalTok{),}
       \AttributeTok{seg.len =} \DecValTok{4}\NormalTok{,}
       \AttributeTok{bg =} \StringTok{"white"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/Kalman2-1} \caption{XXXX.}\label{fig:Kalman2}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Missing data issue: remove observations.}

\NormalTok{Y.modif }\OtherTok{\textless{}{-}}\NormalTok{ Y}
\NormalTok{Y.modif[}\DecValTok{30}\SpecialCharTok{:}\DecValTok{50}\NormalTok{,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NaN}
\NormalTok{Y.modif[}\DecValTok{40}\SpecialCharTok{:}\DecValTok{70}\NormalTok{,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NaN}

\NormalTok{filter.res }\OtherTok{\textless{}{-}}     \FunctionTok{Kalman\_filter}\NormalTok{(Y.modif,nu\_t,H,N,mu\_t,G,M,Sigma\_0,rho\_0,}\AttributeTok{indic\_pos=}\DecValTok{0}\NormalTok{)}
\NormalTok{smoother.res }\OtherTok{\textless{}{-}} \FunctionTok{Kalman\_smoother}\NormalTok{(Y.modif,nu\_t,H,N,mu\_t,G,M,Sigma\_0,rho\_0,}\AttributeTok{indic\_pos=}\DecValTok{0}\NormalTok{)}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{15}\NormalTok{,.}\DecValTok{85}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(Y.modif[,}\DecValTok{1}\NormalTok{],}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(Y[}\DecValTok{1}\SpecialCharTok{*}\StringTok{","}\SpecialCharTok{*}\NormalTok{t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(Y.modif[,}\DecValTok{2}\NormalTok{],}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(Y[}\DecValTok{2}\SpecialCharTok{*}\StringTok{","}\SpecialCharTok{*}\NormalTok{t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(X,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(X[t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/Kalman4-1} \caption{XXXX.}\label{fig:Kalman4}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{15}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{3}\NormalTok{,.}\DecValTok{95}\NormalTok{))}

\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(Y.modif[,}\DecValTok{1}\NormalTok{],}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(y[}\DecValTok{1}\SpecialCharTok{*}\StringTok{","}\SpecialCharTok{*}\NormalTok{t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\FunctionTok{expression}\NormalTok{(y[}\DecValTok{1}\SpecialCharTok{*}\StringTok{","}\SpecialCharTok{*}\NormalTok{t]))}
\FunctionTok{plot}\NormalTok{(Y.modif[,}\DecValTok{2}\NormalTok{],}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(y[}\DecValTok{2}\SpecialCharTok{*}\StringTok{","}\SpecialCharTok{*}\NormalTok{t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\FunctionTok{expression}\NormalTok{(y[}\DecValTok{2}\SpecialCharTok{*}\StringTok{","}\SpecialCharTok{*}\NormalTok{t]))}
\FunctionTok{plot}\NormalTok{(X,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(w[t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\FunctionTok{expression}\NormalTok{(w[t]))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/Kalman5-1} \caption{XXXX.}\label{fig:Kalman5}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{15}\NormalTok{,.}\DecValTok{8}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(X,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(X[t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{r,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{r,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lty=}\DecValTok{1}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }
       \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(X[t]),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Filtered values of "}\NormalTok{,X[t],}\AttributeTok{sep=}\StringTok{""}\NormalTok{)),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Smoothed values of "}\NormalTok{,X[t],}\AttributeTok{sep=}\StringTok{""}\NormalTok{))),}
       \AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\CommentTok{\# line width}
       \AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"blue"}\NormalTok{),}
       \AttributeTok{seg.len =} \DecValTok{4}\NormalTok{,}
       \AttributeTok{bg =} \StringTok{"white"}
\NormalTok{)}

\FunctionTok{plot}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{Sigma\_tt),}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(X[t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}
     \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{S\_smooth)),}\FunctionTok{max}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{Sigma\_tt))))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{S\_smooth),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }
       \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Filtering standard error "}\NormalTok{,}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{Var}\NormalTok{(X[t}\SpecialCharTok{*}\StringTok{"|"}\SpecialCharTok{*}\NormalTok{t])),}\AttributeTok{sep=}\StringTok{""}\NormalTok{)),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Smoothing standard error "}\NormalTok{,}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{Var}\NormalTok{(X[t}\SpecialCharTok{*}\StringTok{"|"}\SpecialCharTok{*}\NormalTok{T])),}\AttributeTok{sep=}\StringTok{""}\NormalTok{))),}
       \AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\CommentTok{\# line width}
       \AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"red"}\NormalTok{),}
       \AttributeTok{seg.len =} \DecValTok{4}\NormalTok{,}
       \AttributeTok{bg =} \StringTok{"white"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/Kalman6-1} \caption{XXXX.}\label{fig:Kalman6}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\FunctionTok{par}\NormalTok{(}\AttributeTok{plt=}\FunctionTok{c}\NormalTok{(.}\DecValTok{1}\NormalTok{,.}\DecValTok{95}\NormalTok{,.}\DecValTok{15}\NormalTok{,.}\DecValTok{8}\NormalTok{))}

\FunctionTok{plot}\NormalTok{(X,}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}\AttributeTok{main=}\FunctionTok{expression}\NormalTok{(w[t]),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{r,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{r,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{lty=}\DecValTok{1}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }
       \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(w[t]),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Filtered values of "}\NormalTok{,w[t],}\AttributeTok{sep=}\StringTok{""}\NormalTok{)),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Smoothed values of "}\NormalTok{,w[t],}\AttributeTok{sep=}\StringTok{""}\NormalTok{))),}
       \AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\CommentTok{\# line width}
       \AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{,}\StringTok{"red"}\NormalTok{,}\StringTok{"blue"}\NormalTok{), }\CommentTok{\# gives the legend lines the correct color and width}
       \AttributeTok{seg.len =} \DecValTok{4}\NormalTok{,}
       \AttributeTok{bg =} \StringTok{"white"}
\NormalTok{)}

\FunctionTok{plot}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{Sigma\_tt),}\AttributeTok{type=}\StringTok{"l"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Conditional standard deviation of filtered/smoothed estimates"}\NormalTok{,}
     \AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{xlab=}\StringTok{""}\NormalTok{,}\AttributeTok{ylab=}\StringTok{""}\NormalTok{,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}
     \AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{S\_smooth)),}\FloatTok{1.4}\SpecialCharTok{*}\FunctionTok{max}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(filter.res}\SpecialCharTok{$}\NormalTok{Sigma\_tt))))}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(smoother.res}\SpecialCharTok{$}\NormalTok{S\_smooth),}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}

\FunctionTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }
       \FunctionTok{c}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Filtering standard error "}\NormalTok{,}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{Var}\NormalTok{(w[t}\SpecialCharTok{*}\StringTok{"|"}\SpecialCharTok{*}\NormalTok{t])),}\AttributeTok{sep=}\StringTok{""}\NormalTok{)),}
         \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Smoothing standard error "}\NormalTok{,}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{Var}\NormalTok{(w[t}\SpecialCharTok{*}\StringTok{"|"}\SpecialCharTok{*}\NormalTok{T])),}\AttributeTok{sep=}\StringTok{""}\NormalTok{))),}
       \AttributeTok{lwd=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{), }\CommentTok{\# line width}
       \AttributeTok{lty=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}
       \AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{,}\StringTok{"blue"}\NormalTok{),}
       \AttributeTok{seg.len =} \DecValTok{4}\NormalTok{,}
       \AttributeTok{bg =} \StringTok{"white"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.95\linewidth]{TSM_files/figure-latex/Kalman8-1} \caption{XXXX.}\label{fig:Kalman8}
\end{figure}

\hypertarget{about-non-constant-conditional-matrix-sigma}{%
\section{\texorpdfstring{About non-constant conditional matrix \(\Sigma\)}{About non-constant conditional matrix \textbackslash Sigma}}\label{about-non-constant-conditional-matrix-sigma}}

\begin{itemize}
\tightlist
\item
  Proposition \ref{prp:KF} is valid when \(\varepsilon_t\) is Gaussian and when \(\Sigma^{\frac{1}{2}}\) does not depend on \(w_t\).
\item
  How to proceed in the general case?
\item
  In the general case (but when \(w_t\) is an affine process), we have that \(\Sigma(w_{t-1}) \equiv \mathbb{V}ar(w_{t+1}|\underline{w_t})\) is affine in \(w_t\) {[}Prop. \ref{prp:affineVAR}{]}.
\item
  In order to deal with this, the Kalman filter algorithm can be modified.
\item
  Specifically, in the prediction step (see Prop. \ref{prp:KF}), \(P_{t|t-1}\) can be computed as:
  \[
  P_{t|t-1} = \Sigma\color{red}{(w_{t-1|t-1})} + \Phi P_{t-1|t-1} \Phi',
  \]
  i.e.~we replace \(\Sigma(w_{t-1})\) by \(\Sigma(w_{t-1|t-1})\).
\item
  Though the approach is then not necessarily optimal, it shows good empirical properties \href{/href\%7Bhttp://link.springer.com/article/10.1023\%2FA\%3A1008304625054}{de Jong (2000)} or \href{https://www.jstor.org/stable/1392263?seq=1\#page_scan_tab_contents}{Duan and Simonato (1999)}.
\item
  In order to test for the validity of the approach in a specific context, one can resort to Monte-Carlo simulations {[}see e.g.~\href{https://www.sciencedirect.com/science/article/pii/S0304407617301653}{Monfort, Pegoraro, Renne and Roussellet (2017)}.
\end{itemize}

\hypertarget{nonlinear}{%
\subsection{Non-linear models}\label{nonlinear}}

\begin{itemize}
\tightlist
\item
  If \(w_t\) follows an affine process, it admits the VAR dynamics presented in Prop. \ref{prp:affineVAR} \(\Rightarrow\) linear transition equation.
\item
  However, measurement equations may be non-linear (affine) functions of \(w_t\).
\item
  This is in particular the case if observed variables include Swaps rates (see Remark SWAPS), CDS rates (see Subsection \ref{subsec:Credit:CDS}, in particular Eq. \eqref{eq:MCCDSformula1}) or prices of tranche products (see Example \ref{exm:DD}).
\item
  In this case, one can for instance resort to the Extended Kalman Filter (linearizing the measurement equations, see supplementary material) or the Quadratic Kalman Filter \href{https://www.sciencedirect.com/science/article/pii/S0304407615000123}{Monfort, Renne and Roussellet, 2015}, second-order expansion of the measurement equations).
\end{itemize}

\hypertarget{EstimationInversion}{%
\section{Inversion Technique}\label{EstimationInversion}}

\begin{itemize}
\tightlist
\item
  The \textbf{inversion technique} has been introduced by \href{http://www.iijournals.com/doi/abs/10.3905/jfi.1993.408090?journalCode=jfi}{Chen and Scott (1993)}.
\item
  It is used e.g.~by \href{http://web.stanford.edu/~piazzesi/AP.pdf}{Ang and Piazzesi (2003)} and \href{http://rady.ucsd.edu/faculty/directory/liu/pub/docs/rate-swaps.pdf}{Liu, Longstaff and Mandell (2006)}.
\item
  Contrary to Kalman-type approaches, this approach is not recursive. Hence can be faster (especially for long sample -- in time dimension).
\item
  Recall that \(y_t\) and \(w_t\) are respectively of dimension \(m\) and \(n\) (see Eqs. \eqref{eq:measeq} and \eqref{eq:transeq} in Def. \ref{def:LSSM}).
\end{itemize}

\begin{hypothesis}[Perfectly-modelled variables]
\protect\hypertarget{hyp:perfectlymodelled}{}\label{hyp:perfectlymodelled}\leavevmode

\begin{itemize}
\tightlist
\item
  Assumption: \(n\) components of the \(m\)-dimensional vector \(y_t\) (with \(n \le m\)) are perfectly modelled (no measurement errors in associated measurement equations).
\item
  Without loss of generality, these perfectly-modelled variables are the first \(n\) components of \(y_t\), that is:
  \[
  y_t =
  \left(\begin{array}{c}
  \underbrace{y_{1,t}}_{(n \times 1)} \\
  \underbrace{y_{2,t}}_{(m-n)\times1}
  \end{array}\right).
  \]
\end{itemize}

\end{hypothesis}

\begin{itemize}
\tightlist
\item
  Under Assumption \ref{hyp:perfectlymodelled}, the measurement equation (Eq. \eqref{eq:measeq}) becomes:
  \[
  \left[
  \begin{array}{c}
  y_{1,t}\\
  y_{2,t}
  \end{array}
  \right]
  =
  \left[
  \begin{array}{c}
  A_{1}\\
  A_{2}
  \end{array}
  \right]+
  \left[
  \begin{array}{c}
  B_{1}\\
  B_{2}
  \end{array}
  \right]w_t +
  \left[
  \begin{array}{c}
  0\\
  \eta_{2,t}
  \end{array}
  \right],
  \]
  where \(\eta_{2,t} \sim \mathcal{N}(0,\Omega_2)\) (say). This notably implies
  \begin{equation}
  w_t = B_{1}^{-1}(y_{1,t} - A_1).\label{eq:wY1}
  \end{equation}
\item
  Under this assumption and if the conditional distribution of \(w_t\) is available in closed form, then the (exact) likelihood of the model can then be computed.
\item
  Proposition \ref{prp:logLikinversion} (next slide) shows that the computation of \(f_{Y_t|\underline{Y_{t-1}}}(y_t;\underline{y_{t-1}})\) involves three terms:
\item
  The first term (in blue in \eqref{eq:inversionLogL}) stems from the conditional distribution \(w_t|\underline{w_{t-1}}\).
\item
  The second term (in red in \eqref{eq:inversionLogL}) is associated with the measurement errors pertaining to \(y_{2,t}\), that are the components of \(\eta_{2,t}\).
\item
  The third term (in brown in \eqref{eq:inversionLogL}) is the determinant of the Jacobian matrix associated with the linear transformation between \(w_t\) and \(y_{1,t}\) (Eq. \eqref{eq:wY1}), that is \(|B_1|\).
\item
  Once one knows how to compute \(f_{Y_t|\underline{Y_{t-1}}}(y_t;\underline{y_{t-1}})\), the total likelihood is easily obtained since:
  \[
  f_{Y_1,\dots,Y_T}(y_1,y_2,\dots,y_T) = f_{Y_1}(y_1) \prod_{t=2}^T f_{Y_t|\underline{Y_{t-1}}}(y_t;\underline{y_{t-1}}).
  \]
\end{itemize}

\begin{proposition}[Log-likelihood in the inversion context]
\protect\hypertarget{prp:logLikinversion}{}\label{prp:logLikinversion}In the context of a linear state-space model as defined in Def. \ref{def:LSSM}, under Assumption \ref{hyp:perfectlymodelled}, and if \(w_t\) is a Markovian process, we have:
\begin{eqnarray}
f_{Y_t|\underline{Y_{t-1}}}(y_t;\underline{y_{t-1}}) &=& \color{blue}{f_{w_t|w_{t-1}}(w(y_{1,t});w(y_{t-1}))} \times \nonumber\\
&& \color{red}{\mathbf{n}(y_{2,t}; A_2 + B_2w(y_{1,t}),\Omega_2)} \times \color{brown}{|B_1|^{-1}}.\label{eq:inversionLogL}
\end{eqnarray}
where \(w(y_{1,t}) = B_{1}^{-1}(y_{1,t} - A_1)\) and where \(\mathbf{n}\) denotes the multivariate normal p.d.f. (Eq. \eqref{eq:varPHI}).
\end{proposition}

\begin{proof}
Since \(w_t\) is Markov, so is \(y_{1,t}\) and since \(y_{2,t} = A_2 + B_2 w(y_{1,t}) + \eta_{2,t}\), with \(w(y_{1,t}) = B_{1}^{-1}(y_{1,t} - A_1)\), we have:
\begin{eqnarray*}
f(y_t|y_{t-1}) &=& f_1(y_{1,t}|y_{1,t-1}) f_2(y_{2,t}|y_{1,t}) \\
&=& |B_1|^{-1} f_w(w(y_{1,t})|w(y_{1,t-1})) \mathbf{n}(y_{2,t}; A_2 + B_2w(y_{1,t}),\Omega_2),
\end{eqnarray*}
where
* \(f_1(y_{1,t}|y_{1,t-1})= |B_1|^{-1} f_w(w(y_{1,t})|w(y_{1,t-1}))\) comes from the fact that, if \(U\) and \(V\) are two random variables such that \(V = g(U)\), where \(g\) is a bijective and differentiable function, then \(f_V(v)=\left|\frac{\partial g^{-1}(v)}{\partial v'}\right| f_U(g^{-1}(v))\),
* and \(f_2(y_{2,t}|y_{1,t}) = \mathbf{n}(y_{2,t}; A_2 + B_2w(y_{1,t}),\Omega_2)\) comes from the fact that \(y_{2,t}|y_{1,t} \sim \mathbf{n}(A_2 + B_2 w(y_{1,t}),\Omega_2)\).
\end{proof}

\hypertarget{EstimationRS}{%
\subsection{Dealing with Unobserved Regimes}\label{EstimationRS}}

\begin{itemize}
\tightlist
\item
  The (adjusted) Kalman and inversion techniques are not suited to the case where some of the components of \(w_t\) are valued in a discrete set. This is typically the case if \(w_t\) is of the form:
  \[
  w_t = \left(\begin{array}{c}
  z_t \\
  x_t
  \end{array}\right),
  \]
  where \(z_t\) is valued in \(\{e_1,\dots,e_J\}\), \(e_j\) being the \(j^{th}\) column of \(Id_J\).
\item
  Let's assume that \(z_t\) is an exogenous and homogenous Markov chain whose dynamics is defined by the \(\pi(e_i,e_j)\)'s that are such that:
  \begin{equation}
  \pi(e_i, e_j) = \mathbb{P}(z_{t+1}=e_j | z_t=e_i).\label{eq:transitproba}
  \end{equation}
\item
  We denote by \(\Pi\) the matrix of transition probabilities, i.e.~the \((i,j)\) component of \(\Pi\) is \(\pi(e_i, e_j)\).
\item
  Assume further that we have:
  \begin{equation}
  x_t = m(z_t,x_{t-1}) + \varepsilon_t,\label{eq:dynxRS}
  \end{equation}
  where \(\mathbb{E}(\varepsilon_t|\underline{z_t},\underline{x_{t-1}})=0\).
\item
  The conditional distribution of \(\varepsilon_t\) w.r.t. \((z_t,x_{t-1})\) is denoted by \(f_{\varepsilon}(.;z_t,x_{t-1})\).
\end{itemize}

\begin{hypothesis}[Measurement equations]
\protect\hypertarget{hyp:RSmeasurement}{}\label{hyp:RSmeasurement}The measurement equation is of the form:
\begin{equation}
y_t = A z_t + B x_t + \eta_t,  \quad \mbox{with }  \eta_t \sim i.i.d. \mathbf{n}(0,\Omega).\label{eq:RSmeasur}
\end{equation}
\end{hypothesis}

\begin{example}[Regime-Switching Gaussian VAR]
\protect\hypertarget{exm:GRSVAR}{}\label{exm:GRSVAR}\leavevmode

\begin{itemize}
\tightlist
\item
  Building on Example \ref{exm:RSVAR}, we know that if
  \begin{equation}
  x_t = \mu z_t + \Phi x_{t-1} +  \varepsilon_t,\label{eq:xRSVAR}
  \end{equation}
  where \(\varepsilon_t|\underline{x_t},z_t \sim \mathcal{N}(0,\Sigma(z_t))\) and if \(z_t\) is an exogenous independent Markov chain, then \(w_t = (x_t',z_t')'\) is affine.
\item
  This context is consistent with the situation presented XXX. In particular, using the notations of Eq. \eqref{eq:dynxRS}, we have:
  \[
  m(z_t,x_{t-1}) = \mu z_t + \Phi x_{t-1}.
  \]
\item
  If \(r_t\) and the s.d.f. are respectively affine and exponential in \(w_t\), then, in particular, yields are also affine in \(w_t\), i.e.~of the form \(R(t,h)= A_h'z_t + B_{h}'x_t\) (see Eq. \eqref{eq:RthAB}).
\item
  Therefore, if the components of \(y_t\) are yields of different maturities, the measurement equations are consistent with Assumption \ref{hyp:RSmeasurement}.
\end{itemize}

\end{example}

\begin{itemize}
\item
  How to estimate such a model when the regimes \(z_t\) are unobservable? Two distinct situations.
\item
  \textbf{Case 1.} The \(x_t\) factors are observable.
\item
  The probabilities of being in the different regimes on each date can be estimated by employing the Kitagawa-Hamilton filter.
\item
  The Kitagawa-Hamilton filter (Appendix \ref{app:KitagHamilton}) can be employed, with \(F_t = (y_t',x_t')'\) and:
  \begin{eqnarray*}
  f(F_t|z_t=e_j,\underline{F_{t-1}}) &=& f(y_t|x_t,z_t=e_j,\underline{F_{t-1}})f(x_t|z_t=e_j,\underline{F_{t-1}}) \\
  &=& \mathbf{n}(y_t;A z_t + B x_t,\Omega) \times \\
  &&f_{\varepsilon}(x_t - m(z_t,x_{t-1});z_t,x_{t-1}),
  \end{eqnarray*}
  where, as in Slide \ref{slide:inversionXX}, \(\mathbf{n}(u;\mu,\Omega)\) denotes the evaluation, at vector \(u\) of the p.d.f. of the multivariate normal distribution \(\mathcal{N}(\mu,\Omega)\).
\item
  A by-product of the Kitagawa-Hamilton filter is the likelihood function associated with the dataset \(\Rightarrow\) The model parameterization can be estimated by MLE.
\item
  \textbf{Case 2.} The \(x_t\) factors are not observable. Two sub-cases:
\item
  2.i The components of \(y_t\) are not perfectly modelled (i.e.~\(\Omega \ne 0\), where \(\Omega\) defined in Eq. \eqref{eq:RSmeasur}.
\item
  2.ii \(n_x\) components of \(y_t\) are perfectly modelled (where \(n_x\) is the dimension of \(x_t\)).
\item
  In Case (2.i), one has to resort to filters dealing with two types of uncertainty {[}with hidden discrete values (\(z_t\)) and continuously distributed latent variables (\(x_t\)){]}.
\end{itemize}

In particular \href{https://www.sciencedirect.com/science/article/pii/0304407694900361}{Kim (1994)'s filter} can be employed when the state-space model is of the form \eqref{eq:RSmeasur}-\eqref{eq:xRSVAR} \href{https://academic.oup.com/rof/article/18/6/2103/1661774}{Monfort and Renne (2014)}, Example \ref{exm:SovereignSpreads}{]}.
* In Case (2.ii), one can resort to an inversion technique, complemented with the Kitagawa-Hamilton filter, to estimate the model (see following box).

\begin{proposition}[Kitagawa-Hamilton filter]
\protect\hypertarget{prp:KitagHamilton}{}\label{prp:KitagHamilton}Consider a \(q\)-dimensional vector of variables \(F_t\) and an exogenous homogenous Markov chain \(z_t\). We make use of the following notations:

\begin{itemize}
\tightlist
\item
  \(\eta_t\) is a \(J\)-dimensional vector whose \(j^{th}\) component is the p.d.f. of \(F_t\) conditional on \((z_t = e_j,\underline{F_{t-1}})\), i.e.~\(f(F_t|z_t=e_j,\underline{F_{t-1}})\)
\item
  \(\xi_{t}\) is a \(J\)-dimensional vector whose \(j^{th}\) component is \(\mathbb{P}(z_t = e_j|\underline{F_t})\).
\end{itemize}

The sequence \(\xi_{t}\) can then be computed recursively as follows:
\begin{equation}
\xi_t = \frac{(\Pi' \xi_{t-1}) \odot \eta_t}{\mathbf{1}'(\Pi' \xi_{t-1} \odot \eta_t)},\label{eq:KHfilter}
\end{equation}
where \(\odot\) denotes the element-by-element (Hadamard) product and where \(\mathbf{1}\) denotes a \(J\)-dimensional vector of ones.

Moreover, the previous formulas also show how to compute the likelihood of the model since:
\begin{equation}
f(F_t|\underline{F_{t-1}})=\mathbf{1}'(\Pi' \xi_{t-1} \odot \eta_t).\label{eq:KHlikelihood}
\end{equation}
\end{proposition}

\begin{proposition}[Kitagawa-Hamilton and inversion techniques]
\protect\hypertarget{prp:mixedKFinversion}{}\label{prp:mixedKFinversion}The matrix of transition probabilities of \(\mathcal{Z}_t\) is of the form \(\mathbf{1}_{n \times 1} \otimes \widetilde{\Pi}\), with
\[
\widetilde{\Pi} =
\left[
\begin{array}{ccccc}
\pi_{1,\bullet} & 0_{1 \times n} \dots & & & 0_{1 \times n} \\
0_{1 \times n} & \pi_{2,\bullet} & 0_{1 \times n} & \dots & 0_{1 \times n} \\
&& \ddots \\
& &  0_{1 \times n} & \pi_{n-1,\bullet} & 0_{1 \times n} \\
0_{1 \times n} &\dots && 0_{1 \times n} & \pi_{n,\bullet}
\end{array}
\right],
\]
where \(\pi_{i,\bullet}\) denotes the \(i^{th}\) row of \(\Pi\) (\(\Pi\) is defined on Slide XXX).

The last term appearing in Eq. \eqref{eq:conddistri4KHfilter} can be computed as follows:
\begin{eqnarray*}
&&f\left(\left[\begin{array}{c}x(y_t,z(\mathcal{Z}_t))\\y_{2,t}\end{array}\right]|\mathcal{Z}_t,\underline{y_{t-1}}\right) \\
&=& f\left(y_{2,t}|x_t=x(y_t,z(\mathcal{Z}_t)),\mathcal{Z}_t,\underline{y_{t-1}}\right) \times\\
&& f\left(x(y_t,z(\mathcal{Z}_t))|\mathcal{Z}_t,\underline{y_{t-1}}\right) \\
&=& \mathbf{n}(y_{2,t};A_2z_t + B_2x_t,\Omega_2) \times\\
&& f_\varepsilon\left(\varepsilon_t|z_t = z(\mathcal{Z}_t),x_{t-1}=x(y_{t-1},z_{-1}(y_{t-1},\mathcal{Z}_t))\right),
\end{eqnarray*}
where \(\mathbf{n}\) is the p.d.f. of a multivariate normal distri, (Prop. \ref{prp:logLikinversion}, where \(\varepsilon_t = x_t - m[z(\mathcal{Z}_t),x(y_{t-1},z_{-1}(y_{t-1},\mathcal{Z}_t))]\) (\(m\) defined in Eq. \eqref{eq:dynxRS}).
\end{proposition}

\hypertarget{mixed-use-of-kitagawa-hamilton-and-inversion-techniques}{%
\subsection{Mixed use of Kitagawa-Hamilton and inversion techniques}\label{mixed-use-of-kitagawa-hamilton-and-inversion-techniques}}

\begin{itemize}
\tightlist
\item
  Without loss of generality, assume that the \(n_x\) first components of \(y_t\) are observed without error, i.e.~Assumption \ref{hyp:RSmeasurement} becomes
  \[
  \left[
  \begin{array}{c}
  y_{1,t}\\
  y_{2,t}
  \end{array}
  \right]
  =
  \left[
  \begin{array}{c}
  A_{1}z_t\\
  A_{2}z_t
  \end{array}
  \right]+
  \left[
  \begin{array}{c}
  B_{1}\\
  B_{2}
  \end{array}
  \right]x_t +
  \left[
  \begin{array}{c}
  0\\
  \eta_{2,t}
  \end{array}
  \right],
  \]
  where \(\varepsilon_2 \sim \mathcal{N}(0,\Omega_2)\).
\item
  Since \(y_{1,t} = A_1 z_t + B_1 x_t\), we then have:
  \begin{equation}
  x_t \equiv x(y_{t},z_t) = B_1^{-1}(y_{1,t} - A_1 z_t).\label{eq:xRS}
  \end{equation}
\item
  In order to employ the Kitagawa-Hamilton filter (Appendix \ref{app:KitagHamilton}), one need to define the extended Markov chain:
  \[
  \mathcal{Z}_t = z_{t-1} \otimes z_t,
  \]
  whose matrix of transition probabilities is detailed in Appendix \ref{app:mixedKFinversion}.
\item
  Note that we have:
  \[
  \left\{
  \begin{array}{cclll}
  z_t &\equiv& z(\mathcal{Z}_t) &=& (\mathbf{1}' \otimes Id_{n}) \mathcal{Z}_t \\
  z_{t-1} &\equiv& z_{-1}(\mathcal{Z}_t) &=& (Id_{n} \otimes \mathbf{1}') \mathcal{Z}_t.
  \end{array}
  \right.
  \]
\item
  The Kitagawa-Hamilton filter (Appendix \ref{app:KitagHamilton}) can then be employed, with \(F_t = y_t\) and:
  \begin{eqnarray}
  f(y_t|\mathcal{Z}_t,\underline{y_{t-1}}) &=&|B_1^{-1}| \times \nonumber \\
  && f\left(\left[\begin{array}{c}x(y_t,z(\mathcal{Z}_t))\\ y_{2,t}\end{array}\right]|\mathcal{Z}_t,\underline{y_{t-1}}\right),\label{eq:conddistri4KHfilter}
  \end{eqnarray}
  where the computation of the last term is detailed in Appendix \ref{app:mixedKFinversion}.
\end{itemize}

\begin{example}[Interest-rate model with monetary policy-related regimes]
\protect\hypertarget{exm:RSMP}{}\label{exm:RSMP}\leavevmode

\begin{itemize}
\tightlist
\item
  \citet{Renne_2017}: model where regimes have monetary-policy interpretations.
\item
  Short-term rate = (daily) EONIA, euro-area overnight interbank rate:
\end{itemize}

\begin{center}
\fbox{$r_{t}=\underset{\mbox{Target}}{\underbrace{\bar{r}_{t}}}+\underset{\mbox{EONIA spread}}{\underbrace{x_{t}}}$}
\par\end{center}

\begin{itemize}
\tightlist
\item
  Target rate \(\bar{r}_{t}\) has a step-like path \(\bar{r}_{t}=\Delta'z_{r,t}\),
  where
\item
  \(\Delta=[\begin{array}{ccccc} 0 & 0.25 & 0.50 & \ldots & \bar{r}_{max}\end{array}]'\) and
\item
  \(z_{r,t}=[\begin{array}{ccccccc} 0 & \ldots & 0 & 1 & 0 & \ldots & 0\end{array}]'\)
\item
  EONIA spread (\(x_t\)) persistent and mean-reverting fluctuations (AR process).
\item
  \(z_t = z_{r,t}\otimes z_{m,t}\) where \(z_{m,t}\) is the monetary-policy regime:
\item
  Easing (\(z_{m,t}=[\begin{array}{ccc} 1 & 0 & 0\end{array}]\)),
\item
  Status Quo (\(z_{m,t}=[\begin{array}{ccc} 0 & 1 & 0\end{array}]\)),
\item
  Tightening (\(z_{m,t}=[\begin{array}{ccc} 0 & 0 & 1\end{array}]\)).
\end{itemize}

\href{https://fixed-income.shinyapps.io/NLIR/}{Web-interface illustrating \(\bar{r}_t\)'s dynamic}

\begin{itemize}
\tightlist
\item
  \(z_{r,t}\) is observed, but not \(z_{m,t}\).
\item
  In the model, according to Example \ref{exm:GRSVAR}, we have:
  \[
  R(t,h) = A_h' z_t + B_h x_t.
  \]
\item
  Denote by \(\mathcal{A}_h\) the \((3 \times n_r)\) matrix such that \(A_h = vec(\mathcal{A}_h)\). We then have \(A_h' z_t = (\mathcal{A}_h z_{r,t})' z_{m,t}\) and, therefore:
  \[
  R(t,h) = A_{t,h}' z_t + B_h x_t, \quad \mbox{where $A_{t,h} = \mathcal{A}_h z_{r,t}$.}
  \]
\item
  The model is estimated by a mixe use of Kitagawa-Hamilton and inversion techniques, assuming that a linear combination of yields is modelled without errors (giving \(x_t = x(y_t,z_{m,t},z_{r,t})\)).
\end{itemize}

\end{example}

\hypertarget{EstimationPersistency}{%
\section{A Typical Small-Sample Issue}\label{EstimationPersistency}}

Interest rates are particularly persistent variables.

Since affine models eventually lead to linear relationships between state variables and interest rates {[}Eq. \eqref{eq:RthAB}{]}, some state variables are also necessarily highly persistent.

In small sample, maximum-likelihood estimates of the model parameters are likely to suffer from a downward bias, \citet{Bauer_Rudebusch_Wu_2012} or \citet{Jardet_Monfort_Pegoraro_2013}.

This relates to a well-known econometric problem:

\begin{itemize}
\tightlist
\item
  This small-sample downward bias has dramatic consequences in terms of term premium estimates.
\item
  For the sake of illustration, let's consider the following process for the short-term interest rate under the physical measure (monthly frequency):
  \[
  i_{t+1} = \bar{i} + \phi (i_{t}-\bar{i}) + \sigma \varepsilon_{t+1}, \quad \varepsilon_t \sim \mathcal{N}(0,1).
  \]
  and the following under the risk-neutral measure:
  \[
  i_{t+1} = \bar{i}^* + \phi^* (i_{t}-\bar{i}^*) + \sigma \varepsilon_{t+1}, \quad \varepsilon_t \sim \mathcal{N}(0,1).
  \]
  with \(\bar{i} = 3\%/12\), \(\bar{i}^* = 6\%/12\), \(\phi = 0.97\), \(\phi^*=0.99\), \(\sigma = 0.2\%\).
\item
  Assume the estimate of \(\phi\) is downard biased (\(\hat\phi=0.9\)). Influence on the 10-year term premium? {[}Figure \ref{fig:biasedTP}, next slide{]}
\end{itemize}

\begin{itemize}
\tightlist
\item
  \citet{Kim_Orphanides_2005} and \citet{Kim_Orphanides_2005} have proposed a simple approach to deal with this problem.
\item
  They add measurement equations to impose that the model-implied forecasts are --up to some measurement errors-- close to survey-based ones.
\item
  Kim and Orphanides use the \href{https://lrus.wolterskluwer.com/store/products/blue-chip-financial-forecasts-prod-ss07418345/paperback-item-1-ss07418345}{Blue Chip Financial Forecasts}.
\item
  Alternative (publicly available) surveys: \href{https://www.philadelphiafed.org/research-and-data/real-time-center/survey-of-professional-forecasters}{Philly Fed Survey of Professional Forecasters} and \href{https://www.ecb.europa.eu/stats/ecb_surveys/survey_of_professional_forecasters/html/index.en.html}{ECB SPF}.
\item
  Importantly, this approach is tractable because model-implied forecasts of yields are affine in the state vector. {[}This is the case for any affine model: see Eq. \eqref{eq:condmeanRth}.{]}
\item
  Their model is able to fit both survey-based forecasts and market yields {[}Figure \ref{fig:fitSurveys}{]}.
\end{itemize}

\hypertarget{forward-futures-dividends-commodity-pricing-and-convenience-yields}{%
\chapter{Forward, futures, dividends, commodity pricing, and convenience yields}\label{forward-futures-dividends-commodity-pricing-and-convenience-yields}}

\hypertarget{FCFPForwards}{%
\section{Forward Contracts}\label{FCFPForwards}}

\begin{itemize}
\tightlist
\item
  \(\underline{w_{t}}\) : information at \(t\)
\item
  Forward contract : Agreement signed at \(t\) (to-day) to buy/sell an asset (a commodity) at a given delivery date \(T>t\) at a price \(\Phi_{t,T}\) (\emph{delivery price} or \emph{forward price}) decided at \(t\).
\item
  \(S_T :\) value of the asset (commodity) at \(T\), (function of \(\underline{w_{T}}\)).
\item
  \(S_T - \Phi_{t,T}\): payoff of the contract at \(T\).
\item
  \(r_t :\) interest rate between \(t\) and \(t+1\) (known at \(t\)), (function of \(\underline{w_{t}}\)).
\item
  \(B(t_1,t_2-t_1)\): date-\(t_1\) price of a zero-coupon bond whose value is 1 on \(t_2\).
\end{itemize}

\begin{proposition}[Forward price]
\protect\hypertarget{prp:fwd}{}\label{prp:fwd}We have:
\begin{eqnarray*}
\Phi_{t,T} & = & \frac{\mathbb{E}_t (M_{t,t+1}, \ldots, M_{T-1,T} S_T)}{B(t,T-t)}\\
& = & \frac{\mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t - \ldots - r_{T-1}) S_T]}{B(t,T-t)}.
\end{eqnarray*}
\end{proposition}

:::\{.proof\} The price at \(t\) of \(S_T - \Phi_{t,T}\) is
zero. Therefore:
\(\mathbb{E}_t (M_{t,t+1}, \ldots, M_{T-1,T} S_T) - \Phi_{t,T} \mathbb{E}_t (M_{t,t+1} \ldots M_{T-1,T}) = 0\). The result follows.
:::

\begin{itemize}
\item
  If the processes \((r_t)\) and \((S_t)\) are \(\mathbb{Q}\)-independent, then
  \[
  \Phi_{t,T} = \mathbb{E}^{\mathbb{Q}}_t (S_T)
  \]
  and \(\Phi_{t,T}\) is a \(\mathbb{Q}\)-martingale.
\item
  If the asset does not generate any payoff before \(T\) (no dividends), then
  \[
  \Phi_{t,T} = \frac{S_t}{B(t,T-t)}.
  \]
\item
  The price at \(s\), with \(t<s<T\), of a forward contract signed at \(t\) is:
  \[
  (\Phi_{s,T} - \Phi_{t,T}) B (s,T-s),
  \]
  since the payoff \(S_T - \Phi_{t,T}\) at \(T\) has this price at \(s\).
\item
  Notations associated with \textbf{dividends}:
\item
  \(\tilde{S}_t\): ex-dividend price at \(t\),
\item
  \(S_t\): cum-dividend price at \(t\),
\item
  \(S_t = \tilde{S}_t \exp (\delta_t)\), \(\delta_t :\) dividend yield (or rate) known at \(t\).
\item
  We get:
  \begin{eqnarray*}
  \tilde{S}_{T-1} & = & \mathbb{E}_{T-1} (M_{T-1,T} S_T) \\
  \mbox{or } \\
  S_{T-1} & = & \mathbb{E}_{T-1} [M_{T-1,T} \exp (\delta_{T-1})
  S_T],
  \end{eqnarray*}
  and, recursively:
  \begin{eqnarray*}
  S_t & = & \mathbb{E}_t [M_{t,t+1} \ldots M_{T-1,T} \exp (\delta_t + \ldots + \delta_{T-1}) S_T] \\
  &=& \mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t \ldots - r_{T-1} + \delta_t + \ldots + \delta_{T-1}) S_T].
  \end{eqnarray*}
\end{itemize}

\(\Rightarrow\) \(r_t\) replaced by \(r_t - \delta_t\).

\begin{itemize}
\tightlist
\item
  Replacing \(S_t\) by \(\tilde{S} \exp(\delta_t)\) and \(S_T\) by \(\tilde{S}_T \exp (\delta_T)\), we get
  \[
  \tilde{S}_t = \mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t -\ldots-r_{T-1} + \delta_{t+1} + \ldots + \delta_T) \tilde{S}_T.
  \]
\item
  If deterministic \(\delta_t\):
  \[
  \Phi_{t,T} = \frac{S_t \exp (-\delta_t - \ldots - \delta_{T-1})}{B(t,T-t)}.
  \]
  If \(r_t\) deterministic too:
  \[
  \Phi_{t,T} = S_t \exp   (r_t + \ldots + r_{T-1} - \delta_t - \ldots - \delta_{T-1}).
  \]
\end{itemize}

\hypertarget{FCFPFutures}{%
\section{Futures Contracts, Futures Prices}\label{FCFPFutures}}

\begin{itemize}
\tightlist
\item
  Futures contract: agreement signed at \(t\) to buy/sell an asset (a commodity) at given delivery date \(T>t\) at a price \(F_{t,T}\) (futures price) decided at \(t\).
\item
  Difference with forward contract: both counterparties are required to deposit into a \textbf{margin account} at every trading day \(s>t\) the resettlement payment (\textbf{margin call}). The latter is equal to:
  \[
  \Delta_{s,T} = F_{s,T} - F_{s-1,T} \quad \mbox{(for the buyer)}.
  \]
\end{itemize}

\(\Rightarrow\) A Futures contract is actually closed out after every
day, starts afresh the next day and therefore is valued zero.

\begin{proposition}[Pricing futures]
\protect\hypertarget{prp:future}{}\label{prp:future}We have:
\[
F_{t,T} = \mathbb{E}^{\mathbb{Q}}_t (S_T),
\]
that is \(F_{t,T}\) is a \(\mathbb{Q}\)-martingale, or \(\Delta_{t,T}\) is a \(\mathbb{Q}\)-martingale difference.
\end{proposition}

\begin{proof}
At each date \(s\ge t\), after the deposit of the resettlement payment, there is a new contract valued zero and paying \(F_{s+1,T} - F_{s,T}\) at \(s+1\) (and providing another zero valued contract at \(s+1\)). Therefore \(0 = \mathbb{E}^{\mathbb{Q}}_s [\exp (-r_s) (F_{s+1,T} - F_{s,T})]\), and \(0 = \mathbb{E}^{\mathbb{Q}}_s (F_{s+1,T} - F_{s,T})\) since \(\exp (-r_s)\) is known at \(s\). Hence \(F_{s,T} = \mathbb{E}^{\mathbb{Q}}_s (F_{s+1,T})\), and the results follows from \(F_{T,T} = S_T\).
\end{proof}

\begin{proposition}[XXXX]
\protect\hypertarget{prp:XXX}{}\label{prp:XXX}\[
\Phi_{t,T} - F_{t,T} = \frac{cov^{\mathbb{Q}}_t \left[\prod^{T-1}_{s=t} \exp (-r_s), S_T\right]}{B(t,T-t)}.
\]
\end{proposition}

\begin{proof}
We have:
\begin{eqnarray*}
\Phi_{t,T} - F_{t,T} & = & \mathbb{E}^{\mathbb{Q}}_t \left[\frac{\prod^{T-1}_{s=t} \exp (-r_s) S_T }{B(t,T-t)}- S_T\right] \\
&=& \frac{\mathbb{E}^{\mathbb{Q}}_t \left[\prod^{T-1}_{s=t} \exp (-r_s) S_T\right] - \mathbb{E}^{\mathbb{Q}}_t \left[\prod^{T-1}_{s=t} \exp (-r_s)\right] \mathbb{E}^{\mathbb{Q}}_t (S_T)}{B(t,T-t)} \\
&=&\frac{cov^{\mathbb{Q}}_t \left[\prod^{T-1}_{s=t} \exp (-r_s), S_T)\right]}{B(t,T-t)}. \end{eqnarray*}
\end{proof}

\begin{itemize}
\tightlist
\item
  \(\Phi_{t,T} = F_{t,T}\), if, and only if, \(\prod^{T-1}_{s=t} \exp (-r_s)\) and \(S_T\) are conditionally uncorrelated under \(\mathbb{Q}\). In particular it is true in the case of deterministic short rates.
\end{itemize}

\hypertarget{FCFPConvenience}{%
\section{Convenience Yields}\label{FCFPConvenience}}

:::\{.definition \#convYield name=``Convenience yield''{]}
A convenience yield\} is a net benefit associated with holding a physical asset (rather than a forward or futures contract). It is \emph{net} in the sense that it is equal to the positive gain of holding minus the cost of storage.
:::

\begin{itemize}
\tightlist
\item
  The notion of convenience yield is valid only for storable commodities (not, e.g., for electricity).
\item
  Can be positive or negative.
\item
  Notion of convenience yield mathematically similar to a dividend yield (but can be \(<0\), and latent).
\end{itemize}

the following, we denote the convenience yield by \(c_t\).
* The price is here the \emph{cum} convenience yield price.

\textbf{Basic pricing approach}

\begin{itemize}
\tightlist
\item
  \(r_t\) and \(c_t\) deterministic. We have:
  \[
  \Phi_{t,T} = F_{t,T} = S_t \exp (r_t + \ldots + r_{T-1} - c_t - \ldots - c_{T-1}).
  \]
\item
  Moreover, if \(r_t\) and \(c_t\) time independent:
  \[
  \Phi_{t,T} = F_{t,T} = S_t \exp [(T-t)(r-c)].
  \]
\item
  If \(r>c\) forward curve function \(\uparrow\) of \(T\): situation of \textbf{contango};
\item
  If \(r<c\) forward curve function \(\downarrow\) of \(T\): \textbf{backwardated} forward curve.
\end{itemize}

\textbf{Advanced approach}: \(c_t\) is stochastic.

\begin{itemize}
\tightlist
\item
  We have:
  \begin{eqnarray}
  \Phi_{t,T} &=& \mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t - \ldots - r_{T-1}) S_T]/B(t,T-t) \label{eq:convenience}\\
  F_{t,T} &=& \mathbb{E}^{\mathbb{Q}}_t (S_T) \label{eq:convenience2}\\
  S_t &=& \mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t - \ldots - r_{T-1} + c_t + \ldots + c_{T-1}) S_T] \label{eq:convenience3}.
  \end{eqnarray}
\item
  necessitates a joint modelling (at least under \(\mathbb{Q}\)) of: \(S_t\) (or \(s_t = \log S_t\)), \(c_t\) (convenience yield), \(r_t\) (short rate),
\item
  and, in general, other factors (observable or latent).
\end{itemize}

Direct or backward approach (see XXX).

\begin{itemize}
\item
  Case of a \textbf{nonstorable commodity}. No convenience yield; if, moreover \(r_t\) deterministic, \(\Phi_{t,T} = F_{t,T} = \mathbb{E}^{\mathbb{Q}}_t (S_T)\), but since Eq. (@ref(eq:convenience3\}) is not valid we do not have \(S_t = B(t,T) \mathbb{E}^{\mathbb{Q}}_t (S_T)\) and therefore we do not have \(\Phi_{t,T} = S_t / B(t,T)\).
  \textbackslash end\{remark\}
\item
  Case of a \textbf{storable commodity}
  The price ex-convenience yield at \(t\), i.e.~\(S_t \exp (-c_t)\), is the price at \(t\) of \(S_{t+1}\):
  \begin{eqnarray}
  S_t \exp (-c_t) &=& \exp (-r_t) \mathbb{E}^{\mathbb{Q}}_t (S_{t+1}) \nonumber\\
  \mathbb{E}^{\mathbb{Q}}_t (S_{t+1}) & = & S_t \exp (r_t - c_t) \label{eq:convenience4} \\
  \mathbb{E}^{\mathbb{Q}}_t \exp (s_{t+1}) &=& \exp(s_t+r_t-c_t). \nonumber
  \end{eqnarray}
  Or if \(y_{t+1} = \log \frac{S_{t+1}}{S_t}\) denotes the (geometric) return, then:
  \[
  \mathbb{E}^{\mathbb{Q}}_t \exp (y_{t+1}) = \exp (r_t - c_t).
  \]
\item
  Eq. \eqref{eq:convenience3} is automatically satisfied (using Eq. \eqref{eq:convenience4} recursively).
\end{itemize}

\hypertarget{FCFPPricingRN}{%
\section{Pricing with Affine Models}\label{FCFPPricingRN}}

\begin{itemize}
\tightlist
\item
  If storable commodity:
  \[
  w_t = (s_t, c_t, r_t, x'_t)',
  \]
  where \(s_t = \log S_t\) and \(x_t\) is a vector of additional factors.
\item
  \(w_t\) \(\mathbb{Q}\)-affine:
  \[
  \mathbb{E}^{\mathbb{Q}}_t \exp (u' w_{t+1}) = \exp [a' (u) w_t + b(u)].
  \]
\item
  If \(S_{t+1} = \exp (e_1' w_{t+1})\), ICCs give:
  \begin{eqnarray*}
  \mathbb{E}^{\mathbb{Q}}_t \exp (s_{t+1}) &=& \exp (s_t-c_t+r_t)\\
  \Leftrightarrow \mathbb{E}^{\mathbb{Q}}_t \exp (e_1' w_{t+1}) &=& \exp [(e_1 - e_2 + e_3)' w_t]\\
  \Leftrightarrow && \left\{\begin{array}{lcl}
  a(e_1) &=& e_1 - e_2 + e_3 \\
  b(e_1) & =&0
  \end{array} \right.
  \end{eqnarray*}
  (if non storable, no \(c_t\), no ICCs).
\item
  Since (Eqs. \eqref{eq:convenience1} and \eqref{eq:convenience2}):
  \begin{eqnarray*}
  \Phi_{t,T} & = & \frac{\mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t - \ldots - r_{t-1} + s_T)]}{\mathbb{E}^{\mathbb{Q}}_t [\exp (-r_t - \ldots - r_{T-1})]} \\
  F_{t,T} & = & \mathbb{E}^{\mathbb{Q}}_t [\exp (s_T)],
  \end{eqnarray*}
  \(\Rightarrow\) quasi explicit formulas using multihorizon Laplace transforms,
  exponential affine in \(w_t = (s_t, c_t, r_t, x^{'}_t)'\).
\end{itemize}

\hypertarget{historical-dynamics}{%
\section{Historical dynamics}\label{historical-dynamics}}

\begin{itemize}
\item
  We have:
  \[
  M_{t,t+1} (\underline{w_{t+1}}) = \exp [-r_t + \alpha'_t w_{t+1} + \psi^{\mathbb{Q}}_t (-\alpha_t)],
  \]
  and
  \[
  \mathbb{E}^{\mathbb{Q}}_t (M_{t,t+1}^{-1}) = \exp (r_t).
  \]
\item
  Historical dynamics defined through:
  \[
  \psi_t (u) = \psi^{\mathbb{Q}}_t (u-\alpha_t) - \psi^{\mathbb{Q}}_t(-\alpha_t).
  \]
\item
  Note: no constraint on \(\alpha_t\), possibility to introduce seasonality.
\end{itemize}

\hypertarget{FCFPGaussian}{%
\section{A Gaussian VAR Model}\label{FCFPGaussian}}

\begin{itemize}
\item
  State vector: \(w_t = (s_t, c_t, r_t)'\).
\item
  \textbf{R.N. dynamics}:
  \[
  w_{t+1} = A_0 + A_1 w_t + \varepsilon_{t+1}, \quad \varepsilon_{t+1} \sim  i.i.d. \mathcal{N}(0,\Sigma) \mbox{ under }\mathbb{Q}.
  \]
\item
  We have (see Example \ref{exm:GAR1}):
  \begin{eqnarray*}
  \mathbb{E}_t \exp (u' w_{t+1}) &=& \exp \left[u' (A_0 + A_1 w_t) + \frac{1}{2} u' \Sigma u\right] \\
  \Rightarrow &&
  \left\{
  \begin{array}{ccl}
  a(u) &=&A^{'}_1 u \\
  b(u) & =& A'_0 u + \frac{1}{2} u' \Sigma u. \end{array} \right.
  \end{eqnarray*}
\item
  Let us decompose \(A_0\) and \(A_1\) as follows:
  \begin{eqnarray*}
  A_0 &=& \left(
  \begin{array}{c} A_{01} \\ \tilde{A}_0
  \end{array}
  \right), \quad A_1 = \left(
  \begin{array}{c} A_{11} \\
  \tilde{A}_1
  \end{array}
  \right).
  \end{eqnarray*}
\item
  ICCs (if storable, otherwise no constraint):
  \[
  \left\{
  \begin{array}{ccl}
  a (e_1) & = & e_1 - e_2 + e_3 \\
  b (e_1) &=& 0. \end{array}
  \right.
  \]
\end{itemize}

\(\Leftrightarrow\) The first row of \(A_1\) is \(A_{11} = e_1'- e_2' + e_3'\), the first element of \(A_0\) is \(A_{01} = -\frac{1}{2}\sigma^2_1\) (\(\sigma^2_1\) conditional variance of \(s_{t+1})\).

\begin{itemize}
\item
  In other words the \(\mathbb{Q}\)-VAR is:

  \centerline{$\left\{\begin{array}{cclcc} s_{t+1} & = & -\frac{1}{2}
  \sigma^2_1 + s_t - c_t + r_t &+& \varepsilon_{1,t+1} \\
  \left(\begin{array}{c} c_{t+1} \\ r_{t+1} \end{array} \right) & = &
  \tilde{A}_0 + \tilde{A}_1 w_t &+& \left(\begin{array}{c} \varepsilon_{2,t+1} \\
  \varepsilon_{3,t+1} \end{array} \right),
  \end{array} \right.$}

  (where \(\tilde{A}_0\) and \(\tilde{A}_1\) are not constrained).
\item
  Noting \(y_{t+1} = \log (S_{t+1}/S_t) = s_{t+1} - s_t\), this implies:
  \[
  \mathbb{E}^{\mathbb{Q}}_t y_{t+1} = r_t - c_t - \frac{1}{2} \sigma^2_1,
  \]

  \item[$\Rightarrow$]

  \(y_{t+1} - r_t + c_t + \frac{1}{2} \sigma^2_1\) is a \(\mathbb{Q}\)-martingale difference.
\item
  \textbf{Historical dynamics}:
  \[
  \begin{array}{lcl}
  \psi_t (u) & = & \psi^{\mathbb{Q}}_t (u-\alpha_t) - \psi^{\mathbb{Q}}_t (- \alpha_t) \\
  &=& u' (A_0 + A_1 w_t) + \frac{1}{2} (u-\alpha_t)' \Sigma (u-\alpha_t)- \frac{1}{2} \alpha'_t
  \Sigma \alpha_t \\
  &=&u' (A_0 + A_1 w_t) - u' \Sigma \alpha_t + \frac{1}{2} u' \Sigma u.
  \end{array}
  \]
\item
  If we take \(\alpha_t = \alpha_0 + \alpha_1 w_t\), we get:
  \begin{eqnarray*}
  \psi_t (u) &=& u' [A_0 - \Sigma \alpha_0 + (A_1 - \Sigma \alpha_1) w_t] + \frac{1}{2} u' \Sigma u \\
  \Rightarrow  w_{t+1} &=& A_0 - \Sigma \alpha_0 + (A_1 - \Sigma \alpha_1) w_t + \xi_t,\\
  && \xi_t \sim  i.i.d.   \mathcal{N}(0,\Sigma)\; \mbox{under}\;\mathbb{P}.
  \end{eqnarray*}
\item
  any VAR(1), with same \(\Sigma\), can be reached.
\item
  We can also take: \(\alpha_t = \alpha_{0t} + \alpha_1 w_t\). We then get the historical dynamics:
  \[
  w_{t+1} = A_{0} - \Sigma \alpha_{0t} + (A_1 - \Sigma \alpha_1) w_t + \xi_{t+1}
  \]
\item
  We can choose \(\alpha_{0t}\) such that: \(A_{0} - \Sigma \alpha_{0t} = \left( \begin{array}{c} \mu_{1t} \\ \mu_2 \\ \mu_3 \end{array}\right)\)
\end{itemize}

(\(\mu_{1t}, \mu_2, \mu_3\) given).
* In particular:
\begin{eqnarray*}
s_{t+1} & = & \mu_{1t} + (A_{11} - \Sigma_1 \alpha_1) w_t + \xi_{1,t+1} \\
& = & \mu_{1t} + \bar{A}_{11} w_t + \xi_{1,t+1}\; \mbox{(say)}, \;
\end{eqnarray*}
\(\bar{A}_{11}\) not constrained, or:
\[
s_{t+1} - \nu_{t+1} = \mu_1 + \bar{A}_{11,1} (s_t - \nu_t) + \bar{A}_{11,2} c_t + \bar{A}_{11,3} r_t + \xi_{1,t+1}
\]
with
\[
\mu_{1t} = \mu_1 + \nu_{t+1} - \bar{A}_{11,1} \nu_t.
\]
* In other words any historical seasonal function \(\nu_t\) can be reached by choosing \(\mu_{1t}\), i.e.~\(\alpha_{0t}\).

\hypertarget{FCFPApplications}{%
\section{Applications}\label{FCFPApplications}}

\begin{itemize}
\tightlist
\item
  Source: \citet{Schwartz_1997}.
\item
  Three models whose discrete-time versions are:
\item
  \textbf{Model 1}:
  \begin{eqnarray*}
  \mathbb{P}&:& s_{t+1} = a_0 + a_1 s_t + \sigma \varepsilon_{t+1}, \; \; \; \varepsilon_t \stackrel{\mathbb{P}}{\sim}  i.i.d. \mathcal{N}(0,1) \\
  \mathbb{Q} &:& s_{t+1} = a^*_0 + a_1 s_t + \sigma \xi_{t+1}, \; \; \; \xi_{t} \stackrel{\mathbb{Q}}{\sim}  i.i.d. \mathcal{N}(0,1),
  \end{eqnarray*}
  and \(\log F_{t,T}\) affine functions of \(s_t\).
\item
  \textbf{Model 2}:
  \begin{eqnarray*}
  \mathbb{P}&:& s_{t+1} = a_{10} + s_t - c_t + \sigma_1 \varepsilon_{1,t+1}\\
  && c_{t+1} = a_{20} + a_{21} c_t + \sigma_2 \varepsilon_{2,t+1}\hspace{1cm} corr (\varepsilon_{1t}, \varepsilon_{2,t}) = \rho \\
  \mathbb{Q}&:& s_{t+1} = r - \frac{\sigma^2_1}{2} + s_t - c_t + \sigma_1  \xi_{1,t+1} \\
  && c_{t+1} = a^*_{20} + a_{21} c_t + \sigma_2 \xi_{2,t+1} \hspace{1cm} corr (\xi_{1t}, \xi_{2t}) = \rho.
  \end{eqnarray*}
\item
  \textbf{Model 3}:
  \begin{eqnarray*}
  \mathbb{P}&:& s_{t+1} = a_{10} + s_t - c_t + r_t + \sigma_1 \varepsilon_{1,t+1} \\
  && c_{t+1}= a_{20} + a_{21} c_t + \sigma_2 \varepsilon_{2,t+1} \\
  && r_{r+1} = a_{30} + a_{31} r_t + \sigma_3 \varepsilon_{3,t+1} \\
  \mathbb{Q}&:& s_{t+1} = -\frac{\sigma^2_1}{2} + s_t - c_t + r_t + \sigma_1 \xi_{1,t+1}\\
  &&c_{t+1} = a^*_{20} + a_{21} c_t + \sigma_2 \xi_{2,t+1} \\
  &&r_{t+1} = a_{30} + a_{31} r_t + \sigma_3 \xi_{3,t+1},
  \end{eqnarray*}
\end{itemize}

\(corr (\varepsilon_{1t}, \varepsilon_{2t}) = \rho_1\), \(corr(\varepsilon_{2t}, \varepsilon_{3t}) = \rho_2\), \(corr(\varepsilon_{1t}, \varepsilon_{3t}) = \rho_3\), idem for the \(\xi_{it}\)'s.

\(\log F_{t,T}\) affine functions of \(s_t, c_t, r_t\).

\begin{itemize}
\tightlist
\item
  In these models \(s_t, c_t\) are latent, the parameters are estimated by the ML method. The likelihood functions are computed by the Kalman filter.
\item
  The measurement equations are of the form:
  \(\log F_{t,T} =\) affine functions of the state variables + error for various values of \(t\) and \(T\).
\item
  State variables: \(s_t\) or \((s_t, c_t)\), (the \(\mathbb{P}\) and \(\mathbb{Q}\) dynamics of \(r_t\) is estimated separately).
\end{itemize}

(Constraints between the \(\mathbb{P}\) and \(\mathbb{Q}\) parameters \(\Rightarrow\) helps identification)

Out of sample means for maturities not used at the estimation stage. F1 contract : the closest to maturity F2 : the second contract to maturity and so one. Source: \citet{Schwartz_1997}.

\hypertarget{references}{%
\chapter{References}\label{references}}

  \bibliography{book.bib,packages.bib}

\end{document}
