[["index.html", "Introduction to Term Structure Models Introduction to Term Structure Models", " Introduction to Term Structure Models Jean-Paul Renne 2023-12-18 Introduction to Term Structure Models Modeling dynamic term structures serves as a practical and indispensable tool in the realm of finance. It enables investors, institutions, and policymakers to make informed decisions, manage risk effectively, and allocate resources wisely. By understanding how interest rates and yields evolve over time, these models offer a clear lens through which to assess market trends and price financial instruments accurately. This course has been developed by Jean-Paul Renne. It is illustrated by R codes using various packages that can be obtained from CRAN. This AEC package is available on GitHub. To install it, one need to employ the devtools library: install.packages(&quot;devtools&quot;) # in case this library has not been loaded yet library(devtools) install_github(&quot;jrenne/AEC&quot;) library(AEC) Useful (R) links: Download R: R software: https://cran.r-project.org (the basic R software) RStudio: https://www.rstudio.com (a convenient R editor) Tutorials: Rstudio: https://dss.princeton.edu/training/RStudio101.pdf (by Oscar Torres-Reyna) R: https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf (by Emmanuel Paradis) My own tutorial: https://jrenne.shinyapps.io/Rtuto_publiShiny/ "],["affine-processes.html", "Chapter 1 Affine processes 1.1 Information in the Economy: The “Factors” 1.2 Dynamic Models 1.3 Some Properties of the Laplace Transform 1.4 Affine (or Car) Processes 1.5 Affine (or Car) processes 1.6 Affine (or Car) processes, Markov Chains 1.7 AFFINE (OR Car) PROCESSES, Stochastic parameters univariate affine processes 1.8 AFFINE (OR Car) PROCESSES, Building Multivariate Affine Processes 1.9 AFFINE (OR Car) PROCESSES, Wishart autoregressive (WAR) processes 1.10 AFFINE (OR Car) PROCESSES, Multivariate Stochastic Parameters Processes 1.11 AFFINE (OR Car) PROCESSES, First Key Property: Multi-Horizon Laplace Transform 1.12 AFFINE (OR Car) PROCESSES, Second Key Property: VAR representation 1.13 Multi-horizon conditional means and variances 1.14 Extended Affine Processes 1.15 Truncated Laplace Transforms of Affine Processes and Transform Analysis 1.16 APPENDICES", " Chapter 1 Affine processes 1.1 Information in the Economy: The “Factors” New information at date \\(t=1,2,\\dots,T\\): \\(K\\)-dimensional factor \\(w_t\\), or state. Information available at \\(t\\): \\(\\underline{w_t} = (w_t,w_{t-1},\\dots,w_1)\\). \\(w_t\\): random vector, observable, partially observable, or unobservable by the econometrician. Example 1.1 (Stock option pricing) Stock option pricing: \\(w_t = (y_t, z_t)\\) with \\(y_t\\): observable vector of (geometric) returns, \\(z_t\\): regime, unobservable by the econometrician. Term structure of interest rates: \\(w_t\\): unobservable factor or observable vector of yields or spreads, macroeconomic variables. 1.2 Dynamic Models Aim: modelling the dynamics of \\(w_t\\) (historical or risk-neutral, see Chapter @ref(section:PandQ}). Parametric modelling: * Choice of a family of conditional probability density functions \\(f(w_{t+1}|\\underline{w_t},\\theta)\\), \\(\\theta\\) unknown vector \\(\\in \\Theta\\). * Equivalently, choice of a conditional Laplace transforms: \\[ \\varphi(u|\\underline{w_t},\\theta) = \\mathbb{E}_{\\theta}[\\exp(u&#39;w_{t+1})|\\underline{w_t}], \\quad u \\in \\mathbb{R}^K, \\] or a conditional log Laplace transforms: \\[ \\psi(u|\\underline{w_t},\\theta) = \\log\\{\\mathbb{E}_{\\theta}[\\exp(u&#39;w_{t+1})|\\underline{w_t}]\\}, \\quad u \\in \\mathbb{R}^K. \\] Example 1.2 (Conditionally Bernoulli process) If \\(w_{t+1}|\\underline{w_t} \\sim {\\mathcal{I}} [p(\\underline{w_t},\\theta)]\\), then: \\[ \\varphi(u|w_t)= \\mathbb{E}[\\exp(u w_{t+1}) \\mid \\underline{w_t}] = p_t \\exp(u) + 1-p_t \\] with \\(p_t = p(w_t, \\theta)\\). Example 1.3 (Conditionally Bernoulli process) If \\(w_{t+1}|\\underline{w_t} \\in {\\mathcal{B}}(n, p_t)\\), then: \\[ \\varphi(u|w_t)=[p_t \\exp(u) + 1-p_t]^n. \\] Example 1.4 (Conditionally Poisson process) If \\(w_{t+1}|\\underline{w_t} \\sim {\\mathcal{P}}(\\lambda_t)\\), then: \\[\\begin{eqnarray*} \\varphi(u|w_t) &amp; =&amp; \\sum^\\infty_{j=0} \\dfrac{1}{j!} \\exp(-\\lambda_t) \\lambda^j_t \\exp(uj) = \\exp(-\\lambda_t) exp[\\lambda_t \\exp(u)] \\\\ &amp; =&amp; \\exp\\{\\lambda_t[\\exp(u)-1]\\}. \\end{eqnarray*}\\] Example 1.5 (Conditionally normal (or Gaussian) process) If \\(w_{t+1}|\\underline{w_t} \\sim \\mathcal{N}\\left(m(\\underline{w_t},\\theta), \\Sigma(\\underline{w_t},\\theta)\\right)\\), then: \\[ u&#39;w_{t+1}|\\underline{w_t} \\sim \\mathcal{N}\\left(u&#39;m(\\underline{w_t},\\theta), u&#39;\\Sigma(\\underline{w_t},\\theta)u\\right). \\] \\[ \\Rightarrow \\left\\{ \\begin{array}{ccc} \\varphi(u|\\underline{w_t},\\theta) &amp;=&amp; \\exp\\left[ \\begin{array}{l} u&#39;m(\\underline{w_t},\\theta)+ \\frac{1}{2} u&#39;\\Sigma(\\underline{w_t},\\theta)u\\end{array} \\right]\\\\ \\psi(u|\\underline{w_t},\\theta) &amp;=&amp; u&#39;m(\\underline{w_t},\\theta) + \\frac{1}{2} u&#39;\\Sigma(\\underline{w_t},\\theta)u. \\end{array} \\right. \\] 1.3 Some Properties of the Laplace Transform \\(\\varphi(0|\\underline{w_t},\\theta) = 1\\) and \\(\\psi(0|\\underline{w_t},\\theta)=0\\). Defined in a convex set \\(E\\) (containing \\(0\\)). If the interior of \\(E\\) is non empty, all the (conditional) moments exist. Scalar case: Moment of order \\(n\\): \\[ \\left[ \\begin{array}{l} \\dfrac{\\partial^n \\varphi(u|\\underline{w_t},\\theta)}{\\partial u^n} \\end{array} \\right]_{u=0} = \\mathbb{E}_{\\theta}[w^n_{t+1}|\\underline{w_t}]. \\] Cumulant of order \\(n\\): \\[ \\left[ \\begin{array}{l} \\dfrac{\\partial^n \\psi(u|\\underline{w_t},\\theta)}{\\partial u^n} \\end{array} \\right]_{u=0} = K_n(\\underline{w_t},\\theta). \\] In particular: \\[ \\left\\{ \\begin{array}{ccc} K_1(\\underline{w_t},\\theta) &amp;=&amp; \\mathbb{E}_{\\theta}[w_{t+1}|\\underline{w_t}]\\\\ K_2(\\underline{w_t}, \\theta) &amp;=&amp; \\mathbb{V}ar_{\\theta}[w_{t+1}|\\underline{w_t}]. \\end{array} \\right. \\] $ and \\(\\psi\\) are respectively called conditional moment and cumulant generating function. Multivariate case: \\[\\begin{eqnarray*} \\left[\\begin{array}{l} \\dfrac{\\partial \\psi}{\\partial u} (u|\\underline{w_t},\\theta) \\end{array} \\right]_{u=0} &amp;=&amp; \\mathbb{E}_{\\theta}[w_{t+1}|\\underline{w_t}] \\\\ \\left[\\begin{array}{l} \\dfrac{\\partial^2 \\psi}{\\partial u\\partial u&#39;} (u|\\underline{w_t},\\theta) \\end{array} \\right]_{u=0} &amp;=&amp; \\mathbb{V}ar_{\\theta}[w_{t+1}|\\underline{w_t}]. \\end{eqnarray*}\\] Example 1.5 (Conditionally normal (or Gaussian) process) See Example 1.5 Scalar case \\(\\psi(u|\\underline{w_t},\\theta)=u m(\\underline{w_t},\\theta) + \\frac{1}{2}u^2\\sigma^2(\\underline{w_t},\\theta)\\). \\(\\left[\\begin{array}{l} \\dfrac{\\partial \\psi}{\\partial u} (u|\\underline{w_t},\\theta) \\end{array} \\right]_{u=0} = m(\\underline{w_t},\\theta)\\). \\(\\left[\\begin{array}{l} \\dfrac{\\partial^2 \\psi}{\\partial u^2} (u|\\underline{w_t},\\theta) \\end{array} \\right]_{u=0} = \\sigma^2(\\underline{w_t},\\theta)\\). Multidimensional case \\(\\psi(u|\\underline{w_t},\\theta)=u&#39; m(\\underline{w_t},\\theta) + \\frac{1}{2}u&#39;\\Sigma(\\underline{w_t},\\theta)u\\). \\(\\left[\\begin{array}{l} \\dfrac{\\partial \\psi}{\\partial u} (u|\\underline{w_t},\\theta) \\end{array} \\right]_{u=0} = m(\\underline{w_t},\\theta)\\). \\(\\left[\\begin{array}{l} \\dfrac{\\partial^2 \\psi}{\\partial u\\partial u&#39;} (u|\\underline{w_t},\\theta) \\end{array} \\right]_{u=0} = \\Sigma(\\underline{w_t},\\theta)\\). In both cases, cumulants of order \\(&gt;2\\) equal to \\(0\\). If \\(w_t=(w&#39;_{1t},w&#39;_{2t})&#39;\\) \\(, u=(u&#39;_1, u&#39;_2)&#39;\\): \\[\\begin{eqnarray*} \\mathbb{E}_{\\theta}[\\exp(u&#39;_1 w_{1,t+1}|\\underline{w_t})&amp;=&amp;\\varphi(u_1,0|\\underline{w_t},\\theta)] \\\\ \\mathbb{E}_{\\theta}[\\exp(u&#39;_2 w _{2,t+1}|\\underline{w_t})&amp;=&amp;\\varphi(0,u_2|\\underline{w_t},\\theta)]. \\end{eqnarray*}\\] If \\(w_t=(w&#39;_{1t},w&#39;_{2t})&#39;\\), and if \\(w_{1t}\\) and \\(w_{2t}\\) are conditionally independent: \\[\\begin{eqnarray*} \\varphi(u|\\underline{w_t},\\theta) &amp;=&amp; \\varphi(u_1,0|\\underline{w_t},\\theta)\\times\\varphi(0,u_2|\\underline{w_t},\\theta) \\\\ \\psi(u|\\underline{w_t},\\theta) &amp;=&amp; \\psi(u_1,0|\\underline{w_t},\\theta)+\\psi(0,u_2|\\underline{w_t},\\theta). \\end{eqnarray*}\\] if \\(w_{1t}\\) and \\(w_{2t}\\) have the same size and if \\[ \\varphi(u_1, u_2|\\underline{w_t},\\theta) = \\mathbb{E}_\\theta[\\exp(u&#39;_1 w_{1, t+1} + u&#39;_2 w_{2,t+1}|\\underline{w_t}], \\] then the conditional Laplace transform of \\(w_{1, t+1} + w_{2, t+1}\\) given \\(\\underline{w_t}\\) is \\(\\varphi(u, u|\\underline{w_t},\\theta)\\). If \\(w_{1t}\\) and \\(w_{2t}\\) are conditionally independent, same size, the conditional Laplace transform and Log-Laplace transform of \\(w_{1,t+1}+w_{2,t+1}\\) are respectively: \\[ \\varphi(u,0|\\underline{w_t},\\theta)\\times \\varphi(0, u|\\underline{w_t},\\theta) \\] and \\[ \\psi(u,0|\\underline{w_t},\\theta)+ \\psi(0, u|\\underline{w_t},\\theta). \\] Lemma 1.1 (Conditional zero probability for non-negative processes) If \\(w_t\\) is univariate and nonnegative its (conditional) Laplace transform \\(\\varphi_t(u) = \\mathbb{E}_t[\\exp(u w_{t+1})]\\) is defined for \\(u \\leq 0\\) and \\[ \\mathbb{P}_t(w_{t+1} = 0) = \\lim_{u\\rightarrow - \\infty} \\varphi_t(u). \\] Proof. We have \\(\\varphi_t(u) = \\mathbb{P}_t(w_{t+1} = 0) + \\int_{w_{t+1}&gt; 0} \\exp(u w_{t+1}) d\\mathbb{P}_t(w_{t+1})\\). The Lebesgue theorem ensures that the last integral converges to zero when \\(u\\) goes to \\(-\\infty\\). Lemma 1.2 (Conditional zero probability for non-negative multivariate processes) Assume that: * \\(w_{1,t}\\) is valued in \\(\\mathbb{R}^{d}\\) (\\(d \\geq 1\\)), * \\(w_{2,t}\\) is valued in \\(\\mathbb{R}^+ = [0, + \\infty )\\), * \\(\\mathbb{E}_t \\left[ \\exp \\left( u_1 &#39; w_{1,t+1} + u_2 w_{2,t+1} \\right) \\right]\\) exists for a given \\(u_1\\) and \\(u_2 \\leq 0\\). Then, we have: \\[\\begin{equation} \\mathbb{E}_t \\left[ \\exp( u_1 &#39; w_{1,t+1}) \\textbf{1}_{\\{w_{2,t+1} = 0 \\}} \\right] = \\underset{u_2 \\rightarrow -\\infty}{\\lim} \\mathbb{E}_t \\left[ \\exp( u_1 &#39; w_{1,t+1} + u_2 w_{2,t+1} ) \\right].\\tag{1.1} \\end{equation}\\] Proof. We have that \\[\\begin{eqnarray*} &amp;&amp;\\underset{u_2 \\rightarrow -\\infty}{\\lim} \\mathbb{E}_t \\left[ \\exp( u_1 &#39; w_{1,t+1} + u_2 w_{2,t+1} ) \\right] \\\\ &amp;=&amp; \\mathbb{E}_t \\left[ \\exp( u_1 &#39; w_{1,t+1}) \\textbf{1}_{\\{w_{2,t+1} = 0 \\}} \\right] +\\\\ &amp;&amp; \\underset{u_2 \\rightarrow -\\infty}{\\lim} \\mathbb{E}_t \\left[ \\exp( u_1 &#39; w_{1,t+1} + u_2 w_{2,t+1} ) \\textbf{1}_{\\{w_{2,t+1} &gt; 0 \\}} \\right] , \\end{eqnarray*}\\] and since in the second term on the right-hand side \\(\\exp(u_2 w_{2,t+1}) \\textbf{1}_{\\{w_{2,t+1} &gt; 0 \\}} \\rightarrow 0\\) when \\(u_2 \\rightarrow -\\infty\\), relation (1.1) is a consequence of the Lebesgue theorem. 1.4 Affine (or Car) Processes Definition 1.1 (Affine process of order 1) A multivariate process \\(w_{t+1}\\) is Affine of order 1 [or \\(Car(1)\\)] if \\[ \\varphi_t(u)=\\mathbb{E}_t[\\exp(u&#39;w_{t+1})]=\\exp[a(u)&#39;w_t+b(u)] \\] for some functions \\(a(.)\\) and \\(b(.)\\). These functions are univariate if \\(w_{t+1}\\) (and therefore \\(u\\)) is scalar. Car stands for Compound auto-regressive. \\(a(.)\\) and b(.) may be deterministic functions of time. Example 1.6 (Univariate AR(1) Gaussian process) If \\(w_{t+1}|\\underline{w_t} \\sim \\mathcal{N}(\\nu+\\rho w_t, \\sigma^2)\\), then: \\[ \\varphi_t(u) = \\exp\\left( \\begin{array}{l} u \\rho w_t + u \\nu + u^2 \\frac{\\sigma^2}{2} \\end{array} \\right) = \\exp[a(u)&#39;w_t+b(u)], \\] \\[ \\mbox{with }\\left\\{ \\begin{array}{ccc} a(u) &amp;=&amp; u \\rho\\\\ b(u) &amp;=&amp; u \\nu + u^2 \\dfrac{\\sigma^2}{2}. \\end{array} \\right. \\] Example 1.7 (Gaussian VAR) If \\(w_{t+1}|\\underline{w_t} \\sim \\mathcal{N}(\\mu+\\Phi w_t, \\Sigma)\\), then: \\[ \\varphi_t(u) = \\exp\\left( \\begin{array}{l} u&#39; (\\mu + \\Phi w_t) + \\frac{1}{2} u&#39; \\Sigma u \\end{array} \\right) = \\exp[a(u)&#39;w_t+b(u)], \\] \\[ \\mbox{with }\\left\\{ \\begin{array}{ccl} a(u) &amp;=&amp; \\Phi&#39;u\\\\ b(u) &amp;=&amp; u&#39; \\mu + \\frac{1}{2} u&#39; \\Sigma u = u&#39; \\mu + \\frac{1}{2}(u \\otimes u)&#39; vec(\\Sigma). \\end{array} \\right. \\] Example 1.8 (Quadratic Gaussian process) Consider \\(w_t = (x&#39;_t,vec(x_t x_t&#39;)&#39;)&#39;\\), where \\(x_t\\) is a \\(n\\)-dimensional vector following a Gaussian VAR(1), i.e. \\[ x_{t+1}|\\underline{w_t} \\sim \\mathcal{N}(\\mu+\\Phi x_t, \\Sigma). \\] If \\(u = (v,V)\\) where \\(v \\in \\mathbb{R}^n\\) and \\(V\\) a square symmetric matrix of size \\(n\\), we have: \\[\\begin{eqnarray*} \\varphi_t(u) &amp;=&amp; \\mathbb{E}_t\\big\\{\\exp\\big[(v&#39;,vec(V)&#39;)\\times w_{t+1}\\big]\\big\\} \\\\ &amp; =&amp; \\exp \\left\\{a_1(v,V)&#39;x_t +vec(a_2(v,V))&#39; vec(x_t&#39;x_t) + b(v,V) \\right\\}, \\end{eqnarray*}\\] where: \\[\\tag{1.2}y*}(#eq:laplaceZ) a_2(u) &amp; = &amp; \\Phi&#39;V (I_n - 2\\Sigma V)^{-1} \\Phi \\nonumber \\\\ a_1(u) &amp; = &amp; \\Phi&#39;\\left[(I_n-2V\\Sigma)^{-1}(v+2V\\mu)\\right] \\nonumber \\\\ b(u) &amp; = &amp; u&#39;(I_n - 2 \\Sigma V)^{-1}\\left(\\mu + \\frac{1}{2} \\Sigma v\\right) +\\\\ &amp;&amp; \\mu&#39;V(I_n - 2 \\Sigma V)^{-1}\\mu - \\frac{1}{2}\\log\\big|I_n - 2\\Sigma V\\big|. \\end{eqnarray*}\\] Proof. We have: \\[\\begin{eqnarray*} &amp;&amp;\\mathbb{E}_t(\\exp(v&#39; x_{t+1} + vec(V)&#39;vec(x_{t+1} x_{t+1}&#39;))) \\\\ &amp;=&amp; \\mathbb{E}_t[\\exp(v&#39; (\\mu + \\Phi x_t + \\Sigma^{1/2}\\varepsilon_{t+1}) + \\\\ &amp;&amp; vec(V)&#39;vec((\\mu + \\Phi x_t + \\Sigma^{1/2}\\varepsilon_{t+1}) (\\mu + \\Phi x_t + \\Sigma^{1/2}\\varepsilon_{t+1})&#39;))] \\\\ &amp;=&amp; \\exp[v&#39; (\\mu + \\Phi x_t) + vec(V)&#39;vec\\{(\\mu + \\Phi x_t)(\\mu + \\Phi x_t)&#39;\\}] \\times \\\\ &amp;&amp; \\mathbb{E}_t[\\exp(v&#39;\\Sigma^{1/2}\\varepsilon_{t+1} +2\\underbrace{ vec(V)&#39; vec\\{(\\mu + \\Phi x_t)(\\varepsilon_{t+1}&#39;{\\Sigma^{1/2}}&#39;)\\}}_{=(\\mu + \\Phi x_t)&#39;V\\Sigma^{1/2}\\varepsilon_{t+1}} +\\\\ &amp;&amp; \\underbrace{vec(V)&#39;vec\\{(\\Sigma^{1/2}\\varepsilon_{t+1})(\\Sigma^{1/2}\\varepsilon_{t+1})&#39;}_{=\\varepsilon_{t+1}&#39;{\\Sigma^{1/2}}&#39;V\\Sigma^{1/2}\\varepsilon_{t+1}}\\}] \\end{eqnarray*}\\] Lemma @ref(lemma:Quadr} can be used to compute the previous conditional expectation, with \\(\\lambda = {\\Sigma^{1/2}}&#39;(v + 2 V&#39;(\\mu + \\Phi x_t))\\). Some algebra then leads to the result. Example 1.9 (Autoregressive gamma process, ARG(1)) An ARG process is defined as follows: \\[ \\frac{w_{t+1}}{\\mu} \\sim \\gamma(\\nu+z_t) \\quad \\mbox{where} \\quad z_t \\sim \\mathcal{P} \\left( \\frac{\\rho w_t}{\\mu} \\right), \\] with \\(\\nu\\), \\(\\mu\\), \\(\\rho &gt; 0\\). (Alternatively \\(z_t \\sim {\\mathcal{P}}(\\beta w_t)\\), with \\(\\rho = \\beta \\mu\\).) We have: \\(\\varphi_t(u) = exp \\left[ \\begin{array}{l} \\dfrac{\\rho u}{1-u \\mu} w_t - \\nu \\log(1-u \\mu)\\end{array} \\right], u &lt; \\dfrac{1}{\\mu}\\). That is: \\(\\varphi_t(u) = \\exp[a(u)&#39;w_t+b(u)]\\) with \\[ \\left\\{ \\begin{array}{ccc} a(u) &amp;=&amp; \\dfrac{\\rho u}{1-u \\mu}\\\\ b(u) &amp;=&amp; -\\nu \\log(1-u \\mu). \\end{array} \\right. \\] Proof. Given \\(\\underline{w_t}\\), we have \\(z_t \\sim {\\mathcal P}\\left( \\begin{array}{l} \\frac{\\rho w_t} {\\mu} \\end{array}\\right)\\). We have: \\[\\begin{eqnarray*} \\mathbb{E}[\\exp(u w_{t+1})|\\underline{w_t}] &amp;=&amp; \\mathbb{E}\\left\\{\\mathbb{E}\\left[\\exp \\left(u \\mu \\frac{w_{t+1}}{\\mu}\\right)|\\underline{w_t}, \\underline{z}_t\\right]\\underline{w_t}\\right\\}\\\\ &amp;=&amp; \\mathbb{E}[(1-u\\mu)^{-(\\nu+z_t)}|\\underline{w_t}] \\\\ &amp;=&amp; (1-u\\mu)^{-\\nu}\\mathbb{E}\\{\\exp[-z_t \\log(1-u\\mu)]|\\underline{w_t}\\} \\\\ &amp;=&amp; (1-u\\mu)^{-\\nu} \\exp \\left\\{\\frac{\\rho w_t}{\\mu}[\\exp(-\\log(1-u\\mu)] - \\frac{\\rho w_t}{\\mu}\\right\\}\\\\ &amp;=&amp; exp\\left[ \\begin{array}{l} \\frac{\\rho u w_t}{1-u\\mu} - \\nu \\log(1-u\\mu) \\end{array}\\right], \\end{eqnarray*}\\] using the fact that the L.T. of \\(\\gamma(\\nu)\\) is \\((1-u)^{-\\nu}\\) and that the L.T. of \\({\\mathcal P}(\\lambda)\\) is \\(\\exp[\\lambda(exp(u)-1)]\\). Web-interface illustration (“ARG” panel) This is a positive process. We have: \\[ \\left\\{ \\begin{array}{ccc} \\mathbb{E}(w_{t+1}|\\underline{w_t}) &amp;=&amp; \\nu \\mu + \\rho w_t \\\\ \\mathbb{V}ar(w_{t+1}|\\underline{w_t}) &amp;=&amp; \\nu \\mu^2 + 2 \\mu \\rho w_t. \\end{array} \\right. \\] We have: \\[ w_{t+1}=\\nu\\mu+\\rho w_t+\\varepsilon_{t+1}, \\] where \\(\\varepsilon_{t+1}\\) is a martingale difference \\(\\Rightarrow\\) \\(w_{t+1}\\) is a weak \\(AR(1)\\). \\(ARG_0(1)\\) process (Monfort et al. 2017): \\(\\nu = 0\\) and \\(\\beta w_t\\) replaced by \\(\\alpha + \\beta w_t\\), i.e.: \\[\\begin{equation} \\frac{w_{t+1}}{\\mu} \\sim \\gamma(z_t),\\quad z_t \\sim {\\mathcal{P}}(\\alpha + \\beta w_t)\\tag{1.3} \\end{equation}\\] \\[ \\Rightarrow \\varphi_t(u) = exp \\left[\\frac{\\beta \\mu u}{1-u \\mu} w_t + \\frac{\\alpha \\mu u}{1-u \\mu} \\right]. \\] Point mass at zero with conditional probability \\(exp(-\\alpha - \\beta w_t)\\), 0 is absorbing if \\(\\alpha = 0\\). library(TSModels) W &lt;- simul.ARG(300,mu=.5,nu=0,rho=.9,alpha=.1) plot(W,type=&quot;l&quot;) Figure 1.1: Simulation of an ARG0 processes. Example 1.10 (Compound Poisson process) Consider the following process: \\[\\frac{w_{t+1}}{\\gamma} = z_{t+1} + \\varepsilon_{t+1}, \\] where: * \\(z_{t+1}\\) and \\(\\varepsilon_{t+1}\\) conditionally independent, * \\(z_{t+1} \\sim {\\mathcal B} \\left( \\begin{array}{l} \\frac{w_t}{\\gamma}, \\pi \\end{array} \\right)\\), * \\(\\varepsilon_{t+1} \\sim {\\mathcal P}(\\lambda)\\), * \\(\\gamma &gt; 0\\), \\(0 &lt; \\pi&lt; 1\\), \\(\\lambda &gt; 0\\). This process is valued in \\(\\{j \\gamma, j \\in \\mathbb{N}, \\gamma \\in \\mathbb{R}^+\\}\\) and we have: \\[ \\varphi_t(u) = exp\\left\\{ \\begin{array}{l} \\dfrac{w_t}{\\gamma} \\log[\\pi exp(u\\gamma)+1-\\pi]-\\lambda[1-exp(u \\gamma)] \\end{array} \\right\\}, \\] with \\[ \\left\\{ \\begin{array}{ccl} a(u)&amp;=&amp; \\frac{1}{\\gamma} \\log[\\pi \\exp(u \\gamma)+1-\\pi],\\\\ b(u) &amp;=&amp; -\\lambda[1-exp(u \\gamma)]. \\end{array} \\right. \\] We have: \\(w_{t+1} = \\pi w_t + \\lambda \\gamma + \\eta_{t+1}\\), where \\(\\eta_{t+1}\\) is a martingale difference. Web-interface illustration (“Compound Poisson” panel) library(TSModels) W &lt;- simul.compound.poisson(100,Gamma=.5,Pi=0.5,lambda=.9) plot(W,type=&quot;l&quot;) Figure 1.2: Simulation of a Compound Poisson process. 1.5 Affine (or Car) processes Definition 1.2 (Affine process of order p) A multivariate process \\(w_{t+1}\\) is affine of order \\(p\\) [or \\(Car(p)\\)] if \\[ \\varphi_t(u)=\\mathbb{E}_t[\\exp(u&#39; w_{t+1})]=\\exp[a_1(u)&#39;w_t+\\dots+a_p(u)&#39;w_{t+1-p}+b(u)]. \\] Remarks: If \\(w_t\\) is \\(Car(p)\\), then \\(W_t = [w_t&#39;, w_{t-1}&#39;,\\dots,w_{t-p+1}&#39;]&#39;\\) is \\(Car(1)\\). Without loss of generality we can assume \\(p = 1\\). Proof. We have: \\[\\begin{eqnarray*} \\mathbb{E}_t[\\exp(u&#39;W_{t+1})] &amp;=&amp; \\mathbb{E}_t[\\exp(u&#39;_1 w_{t+1}+u&#39;_2 w_t+\\dots+u&#39;_p w_{t-p+2})] \\\\ &amp;=&amp; \\exp(u&#39;_2 w_t+\\dots+u&#39;_p w_{t-p+2})\\mathbb{E}_t[\\exp(u&#39;_1 w_{t+1})] \\\\ &amp;=&amp; \\exp(u&#39;_2 w_t+\\dots+u&#39;_p w_{t-p+2}+a&#39;_1(u_1) w_t +\\dots+a&#39;_p(u_1)w_{t+1-p}+b(u_1)) \\\\ &amp;=&amp; \\exp[A(u)&#39;W_t+B(u)], \\end{eqnarray*}\\] with \\(A(u)&#39; = [u&#39;_2+a&#39;_1(u_1),\\dots,u&#39;_p+a&#39;_{p-1}(u_1), a&#39;_p(u_1)]\\) and \\(B(u) = b(u_1)\\). 1.5.1 An important particular case Definition 1.3 (Univariate Index Affine of order p) Let \\(exp[a(u)w+b(u)]\\) be the L.T. of a univariate Affine process of order 1, the process \\(w_{t+1}\\) is an {} process of order \\(p\\) if: \\[ \\varphi_t(u)=\\mathbb{E}_t[\\exp(u w_{t+1})]=\\exp[a(u)(\\beta_1 w_t+\\dots+\\beta_p w_{t+1-p})+b(u)]. \\] Example 1.11 (Gaussian AR(p) process) Extends Example 1.6 \\[\\begin{eqnarray*} \\varphi_t(u) &amp;=&amp; \\exp \\left[ u \\rho (\\beta_1 w_t+\\dots+\\beta_p w_{t+1-p})+u\\nu + u^2 \\frac{\\sigma^2}{2}\\right]\\\\ w_{t+1} &amp;=&amp; \\nu + \\varphi_1 w_t +\\dots+ \\varphi_p w_{t+1-p}+\\sigma \\varepsilon_{t+1},\\quad \\varepsilon_{t+1} \\sim i.i.d. \\mathcal{N}(0,1), \\end{eqnarray*}\\] with \\(\\varphi_i = \\rho \\beta_i\\). Example 1.12 (ARG(p) process (positive)) Extends Example 1.9 \\[\\begin{eqnarray*} \\varphi_t(u) &amp;=&amp; \\exp\\left[\\frac{\\rho u}{1-u \\mu} (\\beta_1 w_t+\\dots+\\beta_p w_{t+1-p})-\\nu \\log(1-u\\mu)\\right],\\\\ w_{t+1} &amp;=&amp; \\nu\\mu + \\varphi_1 w_t +\\dots+ \\varphi_p w_{t+1-p}+\\varepsilon_{t+1}, \\end{eqnarray*}\\] with \\(\\varphi_i = \\rho \\beta_i\\) and where \\(\\varepsilon_{t+1}\\) is a martingale difference. 1.6 Affine (or Car) processes, Markov Chains Notations \\(e_j\\) denotes the \\(j^{th}\\) column of \\(Id_J\\), \\(j=1,\\dots,J\\). \\(\\pi(e_i, e_j) = \\mathbb{P}(z_{t+1}=e_j | z_t=e_i)\\). With these notations: \\[ \\mathbb{E}[\\exp(v&#39;z_{t+1})|z_t=e_i,\\underline{z_{t-1}}] = \\sum^J_{j=1} \\exp(v&#39;e_j)\\pi (e_i, e_j), \\] That is: \\[ \\varphi_t(v) = exp[a_z(v)&#39;z_t], \\] with \\[ a_z(v)= \\left[ \\begin{array}{l} \\log \\left( \\begin{array}{l} \\sum^J_{j=1} \\exp(v&#39;e_j) \\pi(e_1, e_j) \\end{array} \\right)\\\\ \\vdots\\\\ \\log \\left( \\begin{array}{l} \\sum^J_{j=1} \\exp(v&#39;e_j) \\pi(e_J, e_j) \\end{array} \\right) \\end{array}\\right]. \\] Web-interface illustration (“Markov-Switching” panel) 1.7 AFFINE (OR Car) PROCESSES, Stochastic parameters univariate affine processes A univariate affine dynamics based on: \\[ \\mathbb{E}_t \\exp(u y_{t+1}) = \\exp[a_0(u)y_t+b_0(u)\\delta], \\] where \\(\\delta = (\\delta_1,\\dots,\\delta_m)&#39; \\in \\mathcal{D}\\), can be generalized to the case of a stochastic \\(\\delta\\). More precisely assuming: \\[ \\mathbb{E}[\\exp(u y_{t+1})|\\underline{y_t}, \\underline{z_{t+1}}] = \\exp[a_0(u)y_t+b_0(u)&#39;\\Lambda z_{t+1}], \\] where \\(\\Lambda\\) is a \\((m\\times k)\\) matrix, with \\(\\Lambda z_{t+1} \\in \\mathcal{D}\\), then: \\[ \\mathbb{E}[\\exp(v&#39; z_{t+1})|\\underline{y_t}, \\underline{z_{t}}] = \\exp[a_1(v)&#39;z_t+b_1(v)], \\] \\(\\Rightarrow\\) \\(w_{t+1} = (y_{t+1}, z&#39;_{t+1})&#39;\\) is affine. Proof. We have: \\[\\begin{eqnarray*} &amp;&amp;\\mathbb{E}[\\exp(u y_{t+1}+v&#39;z_{t+1})|\\underline{y_t}, \\underline{z_{t}}] \\\\ &amp;=&amp; \\mathbb{E}\\{\\exp(v&#39; z_{t+1})\\mathbb{E}[\\exp(u y_{t+1})|\\underline{y_t}, \\underline{z_{t+1}}]|\\underline{y_t}, \\underline{z_{t}} \\} \\\\ &amp;=&amp; \\mathbb{E}\\{\\exp[a_0(u) y_{t}+b_0(u)&#39;\\Lambda z_{t+1}+v&#39;z_{t+1}]|\\underline{y_t}, \\underline{z_{t}} \\} \\\\ &amp;=&amp; \\exp\\{ a_0(u) y_{t}+a_1[\\Lambda&#39; b_0(u)+v]&#39;z_t+b_1 [\\Lambda&#39; b_0(u)+v]\\}. \\end{eqnarray*}\\] Example 1.13 (Gaussian AR(p)) Extends Example 1.11 Notations: \\(b_0(u) = \\left(u, \\; \\frac{u^2}{2}\\right)&#39;\\) and \\(\\delta = (\\nu,\\sigma^2)&#39; \\in \\mathcal{D}=\\mathbb{R} \\times \\mathbb{R}^+\\). \\(\\delta\\) (vector of conditional mean and variance) can be replaced by … \\(\\left( \\begin{array}{l} z_{1,t+1} \\\\ z_{2,t+1} \\end{array} \\right)\\), where \\(z_{1,t+1}\\) and \\(z_{2,t+1}\\) are independent AR(1) –see Example 1.6– and ARG(1) –see Example 1.9– processes respectively. \\(\\left( \\begin{array}{ll} \\lambda&#39;_1 &amp; 0 \\\\ 0 &amp; \\lambda&#39;_2 \\end{array} \\right)\\)\\(\\left( \\begin{array}{l} z_{1,t+1} \\\\ z_{2,t+1} \\end{array} \\right)\\), where \\(z_{1,t+1}\\) and \\(z_{2,t+1}\\) are independent Markov chains. \\(\\left( \\begin{array}{l} \\lambda&#39;_1 \\\\ \\lambda&#39;_2 \\end{array}\\right)z_{t+1}\\), where \\(z_{t+1}\\) is a Markov chai. Example 1.12 (ARG(p) model) \\(b_0(u)= - \\nu \\log(1-u\\mu)\\), \\(\\delta=\\nu\\). \\(\\nu\\) (\\(\\ge 0\\)) can be specified for instance as a Markov chain or an ARG. 1.8 AFFINE (OR Car) PROCESSES, Building Multivariate Affine Processes Recursive approach (bivariate case): \\(w_t = \\left(\\begin{array}{c} w_{1,t}\\\\ w_{2,t} \\end{array} \\right)\\). Assume that: \\[\\begin{eqnarray*} &amp;&amp;\\mathbb{E}[\\exp(u_1 w_{1,t+1}|\\underline{w_{1,t}}, \\underline{w_{2,t}})]\\\\ &amp;=&amp; \\exp[a_{11}(u_1)w_{1,{\\color{red}{t}}}+a_{12}(u_1)w_{2,{\\color{red}{t}}}+b_{1}(u_1)], \\end{eqnarray*}\\] and that: \\[\\begin{eqnarray*} &amp;&amp; \\mathbb{E}[\\exp(u_2 w_{2,t+1}|\\underline{w_{1,t+1}}, \\underline{w_{2,t}})]\\\\ &amp;= &amp; \\exp[a_0(u_2)w_{1,{\\color{red}{t+1}}}+a_{21}(u_2)w_{1,{\\color{red}{t}}}+a_{22}(u_2)w_{2,{\\color{red}{t}}}+b_2(u_2)]. \\end{eqnarray*}\\] \\(\\Rightarrow\\) Then \\(w_t\\) is an affine process. Proof. We have: \\[\\begin{eqnarray*} &amp;&amp; \\mathbb{E}[\\exp(u_1 w_{1,t+1}+u_2 w_{2,t+1}|\\underline{w_{1,t}}, \\underline{w_{2,t}})]\\\\ &amp;= &amp; \\mathbb{E}\\{\\exp(u_1 w_{1,t+1}) \\mathbb{E}[\\exp(u_{2}w_{2,t+1})|\\underline{w_{1,t+1}}, \\underline{w_{2,t}})]|\\underline{w_{1,t}}, \\underline{w_{2,t}})\\} \\\\ &amp;= &amp; \\mathbb{E}\\{\\exp[u_1+a_0(u_2)w_{1,t+1}+a_{21}(u_2)w_{1,t} + a_{22}(u_2)w_{2,t}+b_2(u_2)]|\\underline{w_{1,t}}, \\underline{w_{2,t}})\\} \\\\ &amp;= &amp; \\exp\\{a_{11}[u_1+a_0(u_2)]w_{1,t}+a_{12}[u_1+a_0(u_2)]w_{2,t}+b_1[u_1+a_0(u_2)] \\\\ &amp;&amp;+ a_{21}(u_2)w_{1,t}+a_{22}(u_2)w_{2,t}+b_2(u_2)\\}. \\end{eqnarray*}\\] The dynamics of the two components of \\(w_t\\) is of the form: \\[\\begin{eqnarray*} w_{1,t+1} &amp;=&amp; \\alpha_1 \\hspace{1.55cm} + \\alpha_{11}w_{1,t} + \\alpha_{12}w_{2,t} + \\varepsilon_{1,t+1} \\\\ w_{2,t+1} &amp;=&amp; \\alpha_2 + \\alpha_{0}w_{1,t+1} + \\alpha_{21}w_{1,t} + \\alpha _{22} w_{2,t} + \\varepsilon_{2,t+1} \\end{eqnarray*}\\] \\(\\varepsilon_{1,t+1}\\) and \\(\\varepsilon_{2,t+1}\\) are non-correlated (conditionally heteroskedastic) martingale differences. Multivariate \\(AR\\) or \\(VAR\\) models, multivariate \\(ARG\\) or \\(VARG\\) models. 1.9 AFFINE (OR Car) PROCESSES, Wishart autoregressive (WAR) processes WAR are valued in the space of \\((L \\times L)\\) symmetric positive definite matrices. Let \\(W_{t+1}\\) be a \\(WAR_L(K, M, \\Omega)\\) process. It is defined by: \\[\\begin{eqnarray} &amp;&amp;\\mathbb{E}[\\exp Tr(\\Gamma W_{t+1})|\\underline{W_t}] \\tag{1.4}\\\\ &amp;=&amp; \\exp\\left\\{Tr[M&#39;\\Gamma(Id-2\\Omega \\Gamma)^{-1}M W_t] - \\frac{K}{2} \\log [det(Id-2\\Omega \\Gamma)]\\right\\}, \\nonumber \\end{eqnarray}\\] where: \\(\\Gamma\\) is a symmetric matrix. Indeed, \\(Tr(\\Gamma W_{t+1})\\) is equal to: \\[\\begin{eqnarray*} \\sum^L_{i=1}(\\Gamma W_{t+1})_{ii} = \\sum^L_{i=1} \\sum^L_{j=1} \\gamma_{ij} W_{t+1,ij} = \\sum^L_{i=1} \\gamma_{ii} W_{t+1,ii} + \\sum^L_{i&lt;j} (\\gamma_{ij}+\\gamma_{ji}) W_{t+1,ij}. \\end{eqnarray*}\\] \\(K\\) is a positive scalar, \\(M\\) is a \\((L \\times L)\\) matrix, \\(\\Omega\\) is a \\((L \\times L)\\) symmetric positive definite matrix. If \\(K\\) integer, \\(W_{t+1}\\) obtained from: \\[\\begin{eqnarray*} \\left\\{ \\begin{array}{ccl} W_{t+1} &amp; =&amp; \\sum^K_{k=1} x_{k,t+1} x&#39;_{k,t+1}\\\\ &amp;&amp;\\\\ x_{k,t+1} &amp; =&amp; M x_{k,t} + \\varepsilon_{k,t+1},\\quad k \\in \\{1,\\dots,K\\}, \\end{array} \\right. \\end{eqnarray*}\\] where \\(\\varepsilon_{k,t+1} \\sim i.i.d. \\mathcal{N}(0, \\Omega)\\) (independent across \\(k\\)’s). We have: \\[ \\mathbb{E}(W_{t+1}|\\underline{W_t}) = MW_tM&#39;+K \\Omega, \\] i.e. \\(W_t\\) follows a matrix weak AR(1). Proof. For \\(K=1\\), \\(W_{t+1}=x_{t+1} x&#39;_{t+1}\\), \\(x_{t+1} = M x_t + \\Omega^{1/2} u_{t+1}\\) and \\(u_{t+1} \\sim i.i.d. \\mathcal{N}(0,Id_L)\\). We have: \\[ \\mathbb{E}[\\exp(Tr \\Gamma W_{t+1})|\\underline{w_t}] = \\mathbb{E}\\{\\mathbb{E}[\\exp(Tr \\Gamma x_{t+1} x&#39;_{t+1})|\\underline{x}_t]|\\underline{w_t}\\} \\] and: \\[\\begin{eqnarray*} &amp;&amp; \\mathbb{E}[\\exp(Tr \\Gamma x_{t+1}x&#39;_{t+1})|\\underline{x}_t] = \\mathbb{E}[\\exp(x&#39;_{t+1}\\Gamma x_{t+1}|\\underline{x}_t] \\\\ &amp;=&amp; \\mathbb{E}[\\exp(M x_t + \\Omega^{1/2} u_{t+1})&#39;\\Gamma(M x_t + \\Omega^{1/2} u_{t+1})/x_t] \\\\ &amp;=&amp; \\exp(x&#39;_tM&#39;\\Gamma M x_t)\\mathbb{E}[\\exp(2 x&#39;_t M&#39;\\Gamma \\Omega^{1/2} u_{t+1}+u&#39;_{t+1}\\Omega^{1/2} \\Gamma \\Omega^{1/2} u_{t+1})/x_t] \\\\ &amp;=&amp; \\frac{exp(x&#39;_tM&#39;\\Gamma M x_t)}{(2\\pi)^{L/2}} \\times \\\\ &amp;&amp; \\int_{\\mathbb{R}^L} \\exp\\left[2x&#39;_tM&#39;\\Gamma \\Omega^{1/2}u_{t+1}-u&#39;_{t+1}\\left( \\frac{1}{2} Id_L-\\Omega^{1/2} \\Gamma \\Omega^{1/2}\\right)u_{t+1}\\right] du_{t+1}. \\end{eqnarray*}\\] Using Lemma 1.4 with \\(\\mu&#39; = 2 x&#39;_t M&#39;\\Gamma \\Omega^{1/2}, Q = \\frac{1}{2} Id_L-\\Omega^{1/2}\\Gamma\\Omega^{1/2}\\) \\ and after some algebra, the RHS becomes: \\[ \\frac{exp[x&#39;_tM&#39;\\Gamma(Id_L-2\\Omega\\Gamma)^{-1}M x_t]}{det[Id_L-2\\Omega^{1/2}\\Gamma\\Omega^{1/2}]} = \\frac{exp Tr[M&#39;\\Gamma(Id_L-2\\Omega^{-1}]M W_t]}{det[Id_L-2\\Omega \\Gamma]^{1/2}}, \\] which depends on \\(x_t\\) through \\(W_t\\), and gives the result for \\(K=1\\); the result for any \\(K\\) integer follows. Particular case: \\(L=1\\) (univariate). \\[\\begin{eqnarray*} \\mathbb{E}[\\exp(u W_{t+1})|\\underline{W_t}] = \\exp\\left[ \\frac{u m^2}{1-2\\omega u}W_t - \\frac{K}{2} \\log(1-2\\omega u)\\right] \\end{eqnarray*}\\] \\(\\Leftrightarrow\\) \\(ARG(1)\\) process (Example 1.9) with \\(\\rho = m^2\\), \\(\\mu = 2\\omega\\), \\(\\nu = \\frac{K}{2}\\). 1.10 AFFINE (OR Car) PROCESSES, Multivariate Stochastic Parameters Processes Consider the same framework as in Section 1.7 when \\(y_t\\) is a \\(n\\)-dimensional vector. The same proof shows that \\(w_{t+1}=(y_{t+1}&#39;,z_{t+1}&#39;)&#39;\\) is affine. Example 1.14 (Stochastic parameters Gaussian VAR(1)) Extends Example 1.7 Using the same notations as in Example 1.7 and in Section 1.7, we have \\[ b_0(u) = \\left(u&#39;, \\frac{1}{2} (u \\otimes u)&#39;\\right)&#39; \\quad \\mbox{and} \\quad\\delta = (\\mu&#39;, vec(\\Sigma)&#39;)&#39; \\in \\mathbb{R}^n \\times vec(\\mathcal{S}), \\] where \\(\\mathcal{S}\\) is the set of symmetric positive semi-definite matrices. \\(\\delta\\) can be replaced by: \\(\\left( \\begin{array}{l} z_{1,t+1} \\\\ z_{2,t+1} \\end{array} \\right)\\), where \\(z_{1,t+1}\\) is, for instance, a Gaussian VAR process and \\(z_{2,t+1}\\) is obtained by applying the \\(vec\\) operator to a Wishart process, or is replaced by \\(\\Lambda_2 z_{2,t+1}\\), where \\(\\Lambda_2\\) is a \\((n^2 \\times J)\\) matrix whose columns are \\(vec(\\Sigma_j)\\), \\(j \\in \\{1,\\dots,J\\}\\), the \\(\\Sigma_j\\) being \\((n \\times n)\\) positive semi-definite, and \\(z_{2,t+1}\\) being, for instance, a standardized \\(J\\)-dimensional VARG process (multivariate extension of Example 1.9). Example 1.14 (Stochastic parameters Gaussian VAR(1)) Extends Example 1.7. \\(\\left( \\begin{array}{ll} \\Lambda_1 &amp; 0 \\\\ 0 &amp; \\Lambda_2 \\end{array} \\right)\\)\\(\\left( \\begin{array}{l} z_{1,t+1} \\\\ z_{2,t+1} \\end{array} \\right)\\), where \\(\\Lambda_1\\) is a \\((n \\times J_1)\\) matrix and \\(z_{1,t+1}\\) is a Markov chain valued in the set of selection vectors of size \\(J_1\\) (see Slide @ref(slide:Markov}), \\(\\Lambda_2\\) is the same matrix as in (i) and \\(z_{2,t+1}\\) is a Markov chain valued in the set of selection vectors of size \\(J_2\\). \\(\\left( \\begin{array}{l} \\Lambda_1 \\\\ \\Lambda_2 \\end{array}\\right)z_{t+1}\\), where \\(\\Lambda_1\\) and\\(\\Lambda_2\\) are the same matrices as above with \\(J_1=J_2=J\\), and \\(z_{t+1}\\) is a Markov chain valued in the set of selection vectors of size \\(J\\). 1.11 AFFINE (OR Car) PROCESSES, First Key Property: Multi-Horizon Laplace Transform \\(w_{t+1}\\): multivariate affine of order 1 (contains the order \\(p\\) case, with functions \\(a(.)\\), \\(b(.)\\), possibly deterministic functions of time, denoted in this case \\(a_{t+1}(.)\\) and \\(b_{t+1}(.)\\): \\[ \\mathbb{E}_t \\exp[(u&#39;w_{t+1})] = \\exp[a&#39;_{t+1}(u)w_t+b_{t+1}(u)]. \\] We want to compute, for some pair \\((t,h)\\): \\[\\begin{equation} \\varphi_{t,h}(\\gamma_1,\\dots,\\gamma_h) = \\mathbb{E}_t[\\exp(\\gamma&#39;_1w_{t+1}+\\dots+\\gamma&#39;_h w_{t+h})].\\tag{1.5} \\end{equation}\\] Lemma 1.3 We have: \\[ \\varphi_{t,h}(\\gamma_1,\\dots,\\gamma_h) = \\exp(A&#39;_{t,h} w_t + B_{t,h}), \\] where \\(A_{t,h} = A^h_{t,h}\\) and \\(B_{t,h} = B^h_{t,h}\\), the \\(A^h_{t,i}, B^h_{t,i}\\) \\(i = 1,\\dots,h\\), being given recursively by: \\[ (i) \\left\\{ \\begin{array}{ccl} A^h_{t,i} &amp;=&amp; a_{t+h+1-i}(\\gamma_{h+1-i} + A^h_{t,i-1}), \\\\ B^h_{t,i} &amp;=&amp; b_{t+h+1-i}(\\gamma_{h+1-i} + A^h_{t,i-1}) + B^h_{t,i-1}, \\\\ A^h_{t,0} &amp;=&amp; 0, B^h_{t,0} = 0. \\end{array} \\right. \\] Proof. For any \\(j=1,\\dots,h\\) we have: \\[ \\varphi_{t,h}(\\gamma_1,\\dots,\\gamma_h) = \\mathbb{E}_t[\\exp(\\gamma&#39;_1 w_{t+1}+\\dots\\gamma&#39;_j w_{t+j}+A^{h&#39;}_{t,h-j}w_{t+j}+B^h_{t,h-j})] \\] where: \\[ (ii) \\left\\{ \\begin{array}{l} A^h_{t,h-j+1} = a_{t+j}(\\gamma_{j} + A^h_{t,h-j}), \\\\ B^h_{t,h-j+1} = b_{t+j}(\\gamma_{j} + A^h_{t,h-j}) + B^h_{t,h-j}, \\\\ A^h_{t,0} = 0, B^h_{t,0} = 0. \\end{array} \\right. \\] Since this is true for \\(j=h\\), and if this is true for \\(j\\), we get: \\[ \\begin{array}{ll} \\varphi_{t,h}(\\gamma_1,\\dots,\\gamma_h) &amp; = \\mathbb{E}_t [\\exp(\\gamma&#39;_1 w_{t+1}+\\dots+\\gamma&#39;_{j-1}w_{t+j-1}+a&#39;_{t+j}(\\gamma_j+A^h_{t,h-j})w_{t+j-1} \\\\ &amp; + b_{t+j}(\\gamma_j+A^h_{t,h-j})+B^h_{t,h-j}], \\end{array} \\] and, therefore, this is true for \\(j-1\\), with \\(A^h_{t,h-j+1}\\) and \\(B^h_{t,h-j+1}\\) given by formulas (ii) above. For \\(j=1\\) we get: \\[\\begin{eqnarray*} \\varphi_{t,h}(\\gamma_1,\\dots,\\gamma_h) &amp;=&amp; \\mathbb{E}_t \\exp(\\gamma&#39;_1 w_{t+1}+A^{h&#39;}_{t,h-1}w_{t+1}+B^h_{t,h-1}) \\\\ &amp;=&amp; \\exp(A&#39;_{t,h} w_t+B_{t,h}), \\end{eqnarray*}\\] Finally note that if we put \\(h-j+1 = i\\), formulas (ii) become (i). Remark: If the functions \\(a_{t}\\) and \\(b_{t}\\) do not depend on \\(t\\), these recursive formulas do not depend on \\(t\\), and we get \\(\\varphi_{t,h}(\\gamma_1,\\dots,\\gamma_h)\\), for any \\(t\\), with only one recursion for each \\(h\\). Proposition 1.1 (Reverse-order multi-horizon Laplace transform) If the functions \\(a_{t}\\) and \\(b_{t}\\) do not depend on \\(t\\), and if different sequences \\((\\gamma^h_1,\\dots,\\gamma^h_h), h=1,\\dots,H\\) (say) satisfy \\(\\gamma^h_{h+1-i} = u_i\\), for \\(i=1,\\dots,h\\), and for any \\(h \\leq H\\), that is if we want to compute (“reverse order” case): \\[ \\varphi_{t,h}(u_h,\\dots,u_1)=\\mathbb{E}_t[\\exp(u&#39;_{{\\color{red}h}} w_{{\\color{red}t+1}}+\\dots+u&#39;_{{\\color{red}1}} w_{{\\color{red}t+h}})], \\quad h=1,\\dots,H, \\] then we can compute the \\(\\varphi_{t,h}(u_h,\\dots,u_1)\\) for any \\(t\\) and any \\(h \\leq H\\), with only one recursion, i.e. \\(\\varphi_{t,h}(u_h,\\dots,u_1)=\\exp(A&#39;_hw_t+B_h)\\) with: \\[\\begin{equation} \\left\\{ \\begin{array}{ccl} A_{h} &amp;=&amp; a(u_{h} + A_{h-1}), \\\\ B_{h} &amp;=&amp; b(u_{h} + A_{h-1}) + B_{h-1}, \\\\ A_{0} &amp;=&amp; 0,\\quad B_{0} = 0. \\end{array} \\right.\\tag{1.6} \\end{equation}\\] Proof. According to Lemma 1.3, we have, in this case: \\[ \\left\\{ \\begin{array}{ccl} A^h_{i} &amp;=&amp; a(u_{i} + A^h_{i-1}), \\\\ B^h_{i} &amp;=&amp; b(u_{i} + A^h_{i-1}) + B^h_{i-1}, \\\\ A^h_{0} &amp;=&amp; 0, \\quad B^h_{0} = 0. \\end{array} \\right. \\] The previous sequences do not dependent on \\(h\\) and are given by Eq. (1.6). Example 1.15 (Nominal interest rates) If \\(B(t,h)\\) denotes the date-\\(t\\) price of a nominal zero-coupon bon of maturity \\(h\\), then \\[\\begin{equation} B(t,h) = \\mathbb{E}^{\\mathbb{Q}}_t exp (-r_{t}-\\dots-r_{t+h-1}),\\tag{1.7} \\end{equation}\\] where \\(r_{t}\\) is the nominal short rate between \\(t\\) and \\(t+1\\) (observed at \\(t\\)), and the associated (continuously-compounded) yield-to-maturity is given by: \\[\\begin{equation} R(t,h) = - \\frac{1}{h} \\log B(t,h), \\quad h=1,\\dots,H. \\end{equation}\\] If \\(r_t = \\omega&#39;w_t\\) (say), then: \\[ B(t,h) = \\exp(-r_{t}) \\mathbb{E}^{\\mathbb{Q}}_t \\exp(-\\omega&#39; w_{t+1} - \\dots - \\omega&#39; w_{t+h-1}) \\] \\[ \\Rightarrow u_1 = 0,\\mbox{ and } u_i = - \\omega, i = 2,\\dots, H. \\] \\(B(t,h)\\) exponential affine in \\(w_t\\), \\(R(t,h)\\) affine in \\(w_t\\). Example 1.16 (Real interest rates) Denoting by \\(q_t\\) the price index on date \\(t\\) and by \\(\\pi_{t+1} = log \\dfrac{q_{t+1}}{q_t}\\) the inflation rate on date \\(t+1\\), we have: \\[\\begin{eqnarray*} \\bar{R}(t,h) &amp; =&amp; - \\frac{1}{h} \\log \\bar{B}(t,h), \\quad h=1,\\dots,H \\\\ \\\\ \\bar{B}(t,h) &amp; =&amp; \\mathbb{E}^{\\mathbb{Q}}_t \\exp(-r_{t}-\\dots-r_{t+h-1} + \\pi_{t+1}+\\dots+\\pi_{t+h}), \\\\ \\\\ &amp; =&amp; \\exp(-r_{t}) \\times \\\\ &amp;&amp; \\mathbb{E}^{\\mathbb{Q}}_t \\exp(-r_{t+1}-\\dots-r_{t+h-1}+\\pi_{t+1}+\\dots+\\pi_{t+h}) \\end{eqnarray*}\\] If \\(r_t = \\omega&#39;w_t\\) and \\(\\pi_t = \\bar\\omega&#39;w_t\\) then \\(\\bar{B}(t,h)\\) is given by: \\[\\begin{eqnarray*} \\exp(-r_{t}) \\mathbb{E}^{\\mathbb{Q}}_t exp[(\\bar\\omega-\\omega)&#39;w_{t+1}+\\dots+(\\bar\\omega-\\omega)&#39;w_{t+h-1}+\\bar\\omega&#39; w_{t+h}] \\end{eqnarray*}\\] \\(\\Rightarrow\\) \\(u_1 = \\bar\\omega\\) and \\(u_i = \\bar\\omega-\\omega\\), \\(i=2,\\dots,H\\). Example 1.17 (Futures) \\(F(t,h) = \\mathbb{E}^{\\mathbb{Q}}_t (S_{t+h})\\), \\(h=1,\\dots,H\\), where \\(S_t\\) date-\\(t\\) price of the asset. If \\(w_t = (\\log S_t, x&#39;_t)&#39;\\) then \\[ F(t,h) = \\mathbb{E}^{\\mathbb{Q}}_t \\exp(e&#39;_1 w_{t+h}) \\Rightarrow u_1 = e_1, \\mbox{and} u_i = 0, i=2,\\dots,H. \\] If \\(w_t = (y_t, x&#39;_t)&#39;\\) with \\(y_t = \\log \\frac{S_t}{S_{t-1}}\\), then: \\[ F(t,h) = S_t \\mathbb{E}^{\\mathbb{Q}}_t \\exp(e&#39;_1 w_{t+1}+\\dots+e&#39;_1 w_{t+h}) \\Rightarrow u_i = e&#39;_1, i=1,\\dots,H. \\] Example 1.18 (Exponential affine payoffs) Consider, for \\(h \\in \\{1,\\dots,H\\}\\), the date-\\(t\\) price of the payoff \\(\\exp(\\nu&#39; w_{t+h}\\)), settled on date \\(h\\): \\[ P(t,h;\\nu) = \\mathbb{E}^{\\mathbb{Q}}_t[\\exp(-r_{t}-\\dots-r_{t+h-1}) \\exp(\\nu&#39; w_{t+h})]. \\] If \\(r_t = \\omega&#39;w_t\\), we get: \\[ P(t,h;\\nu) = \\exp(-r_{t})\\mathbb{E}^{\\mathbb{Q}}_t \\left(exp[-\\omega&#39; w_{t+1}-\\dots-\\omega&#39; w_{t+h-1}+ \\nu&#39; w_{t+h}]\\right) \\] \\(\\Rightarrow u_1 = \\nu\\) and \\(u_i = -\\omega\\), \\(i = 2,\\dots,H\\). What precedes can be extended to the case where the payoff (settled on date \\(t+h\\)) is of the form: \\[ (\\nu_1&#39;w_{t+h}) \\exp(\\nu_2&#39; w_{t+h}). \\] Indeed, we have \\[ \\left[\\frac{\\partial \\exp[(s \\nu_1+ \\nu_2)&#39;w_{t+h}]}{\\partial s}\\right]_{s=0} = (\\nu_1&#39;w_{t+h}) \\exp(\\nu_2&#39; w_{t+h}). \\] Therefore: \\[\\begin{eqnarray} &amp;&amp;\\mathbb{E}_t^{\\mathbb{Q}}[\\exp(-r_t - \\dots - r_{t+h-1})(\\nu_1&#39;w_{t+h}) \\exp(\\nu_2&#39; w_{t+h})] \\nonumber\\\\ &amp;=&amp; \\left[ \\frac{\\partial P(t,h;s \\nu_1 + \\nu_2)}{\\partial s} \\right]_{s=0}.\\tag{1.8} \\end{eqnarray}\\] This method is easily extended to price payoffs of the form \\((\\nu_1&#39;w_{t+h})^k \\exp(\\nu_2&#39; w_{t+h})\\), \\(k \\in \\mathbb{N}\\). 1.12 AFFINE (OR Car) PROCESSES, Second Key Property: VAR representation Proposition 1.2 (VAR representation of an affine process' dynamics) If \\(w_t\\) is the affine process whose Laplace transform is defined in Def. 1.1, then its dynamics admits the following vectorial autoregressive representation: \\[\\begin{equation} w_{t+1} = \\mu + \\Phi w_{t} + \\Sigma^{\\frac{1}{2}}(w_t) \\varepsilon_{t+1},\\tag{1.9} \\end{equation}\\] where \\(\\varepsilon_{t+1}\\) is a difference of martingale sequence whose conditional covariance matrix is the identity matrix and where \\(\\mu\\), \\(\\Phi\\) and \\(\\Sigma(w_t) = \\Sigma^{\\frac{1}{2}}(w_t){\\Sigma^{\\frac{1}{2}}(w_t)}&#39;\\) satisfy: \\[\\begin{equation} \\mu = \\left[\\frac{\\partial }{\\partial u}b(u)\\right]_{u=0}, \\quad \\Phi= \\left[\\frac{\\partial }{\\partial u}a(u)&#39;\\right]_{u=0}\\tag{1.10} \\end{equation}\\] \\[\\begin{equation} \\Sigma(w_t) = \\left[\\frac{\\partial }{\\partial u\\partial u&#39;}b(u)\\right]_{u=0} + \\left[\\frac{\\partial }{\\partial u\\partial u&#39;}a(u)&#39;w_t\\right]_{u=0}.\\tag{1.11} \\end{equation}\\] Proof. When \\(w_t\\) is affine, its (conditional) cumulant generating function is of the form \\(\\psi(u)=a(u)&#39;w_t+b(u)\\). The result directly follows from the formulas given in Section 1.3. 1.13 Multi-horizon conditional means and variances Proposition 1.2 implies that: \\[\\begin{eqnarray} \\mathbb{E}_t(w_{t+h}) &amp;=&amp; (I - \\Phi)^{-1}(I - \\Phi^h)\\mu + \\Phi^h w_t \\tag{1.12}\\\\ \\mathbb{V}ar_t(w_{t+h}) &amp;=&amp; \\Sigma(\\mathbb{E}_t(w_{t+h-1}))+\\Phi \\Sigma(\\mathbb{E}_t(w_{t+h-2}))\\Phi&#39; + \\nonumber \\\\ &amp;&amp; \\dots + \\Phi^{h-1} \\Sigma(w_{t}){\\Phi^{h-1}}&#39;. \\tag{1.13} \\end{eqnarray}\\] Eq. (1.13) notably shows that \\(\\mathbb{V}ar_t(w_{t+h})\\) is an affine function of \\(w_t\\) (indeed \\(\\Sigma(.)\\) is an affine function and the conditional expectations \\(\\mathbb{E}_t(w_{t+h})\\) are affine in \\(w_t\\), as shown in Eq. (1.12). We also have: \\[\\begin{equation} \\left\\{ \\begin{array}{ccl} \\mathbb{E}(w_t) &amp;=&amp; (I - \\Phi)^{-1}\\mu\\\\ vec[\\mathbb{V}ar(w_t)] &amp;=&amp; (I_{n^2} - \\Phi \\otimes \\Phi)^{-1} vec\\left(\\Sigma[(I - \\Phi)^{-1}\\mu]\\right). \\end{array} \\right.\\tag{1.14} \\end{equation}\\] Proof. Eq. (1.12) is easily deduced from Eq. (1.9), using that \\(\\mathbb{E}_t(\\varepsilon_{t+k})=0\\) for \\(k&gt;0\\). As regards Eq. (1.13): \\[\\begin{eqnarray*} \\mathbb{V}ar_t(w_{t+h}) &amp;=&amp; \\mathbb{V}ar_t\\left(\\Sigma(w_{t+h-1})^{\\frac{1}{2}}\\varepsilon_{t+h}+\\dots + \\Phi^{h-1} \\Sigma(w_{t})^{\\frac{1}{2}}\\varepsilon_{t+1} \\right). \\end{eqnarray*}\\] The conditional expectation at \\(t\\) of all the terms of the sum is equal to zero since, for \\(i \\ge 1\\): \\[ \\mathbb{E}_t\\left[\\Sigma(w_{t+i-1})^{\\frac{1}{2}}\\varepsilon_{t+i}\\right] = \\mathbb{E}_t[\\underbrace{\\mathbb{E}_{t+i-1}\\{\\Sigma(w_{t+i-1})^{\\frac{1}{2}}\\varepsilon_{t+i}\\}}_{=\\Sigma(w_{t+i-1})^{\\frac{1}{2}}\\mathbb{E}_{t+i-1}\\{\\varepsilon_{t+i}\\}=0}\\}], \\] and \\(\\forall i &lt;j\\), \\[ \\mathbb{C}ov_t\\left[\\Sigma(w_{t+i-1})^{\\frac{1}{2}}\\varepsilon_{t+i},\\Sigma(w_{t+j-1})^{\\frac{1}{2}}\\varepsilon_{t+j}\\right] = \\mathbb{E}_t\\left[\\Sigma(w_{t+i-1})^{\\frac{1}{2}}\\varepsilon_{t+i}\\varepsilon_{t+j}&#39;\\Sigma&#39;(w_{t+j-1})^{\\frac{1}{2}}\\right], \\] which can be seen to be equal to zero by conditioning on the information available on date \\(t+j-1\\). Using the same conditioning, we obtain that: \\[\\begin{eqnarray*} \\mathbb{V}ar_t\\left[\\Phi^{h-j}\\Sigma(w_{t+j-1})^{\\frac{1}{2}}\\varepsilon_{t+j}\\right] &amp;=&amp; \\mathbb{E}_t\\left[\\Phi^{h-j}\\Sigma(w_{t+j-1})^{\\frac{1}{2}}\\varepsilon_{t+j}\\varepsilon_{t+j}&#39;\\Sigma&#39;(w_{t+j-1})^{\\frac{1}{2}}{\\Phi^{h-j}}&#39;\\right] \\\\ &amp;=&amp; \\mathbb{E}_t\\left[\\Phi^{h-j}\\Sigma(w_{t+j-1})^{\\frac{1}{2}} \\mathbb{E}_{t+j-1}(\\varepsilon_{t+j}\\varepsilon_{t+j}&#39;)\\Sigma&#39;(w_{t+j-1})^{\\frac{1}{2}}{\\Phi^{h-j}}&#39;\\right] \\\\ &amp;=&amp; \\Phi^{h-j}\\mathbb{E}_t[\\Sigma(w_{t+j-1})]{\\Phi^{h-j}}&#39; \\\\ &amp;=&amp; \\Phi^{h-j}\\Sigma(\\mathbb{E}_t[w_{t+j-1}]){\\Phi^{h-j}}&#39;, \\end{eqnarray*}\\] where the last equality results from the fact that he fact that \\(\\Sigma(.)\\) is affine (see Eq. (1.11)). 1.14 Extended Affine Processes Definition 1.4 (Extended Affine Processes) A process \\(w_{1,t}\\) is extended affine if there exists a process \\(w_{2,t} = g(\\underline{w_{1,t}})\\) such that \\((w&#39;_{1,t}, w&#39;_{2,t})&#39;\\) is affine (of order 1). For an extended affine processes, \\(\\varphi_{1,t}(u) = \\mathbb{E}[\\exp(u&#39;w_{1,t+1})|\\underline{w_{1,t}}]\\) can be obtained from: \\[\\begin{eqnarray*} \\varphi_t(u_1, u_2) &amp;=&amp; \\mathbb{E}[\\exp(u&#39;_1w_{1,t+1}+u&#39;_2 w_{2,t+1)}|\\underline{w_{1,t}}, \\underline{w_{2,t}}] \\\\ &amp;=&amp; \\exp[a&#39;_1(u_1,u_2)w_{1,t} + a&#39;_2(u_1,u_2)w_{2,t}+b(u_1,u_2)] \\end{eqnarray*}\\] by: \\[ \\varphi_{1,t}(u) = \\varphi_t(u, 0) = \\exp[a&#39;_1(u,0)w_{1,t}+a&#39;_2(u,0)g(\\underline{w_{1,t}}) + b(u, 0)]. \\] In particular \\(w_{1,t}\\) may be non-Markovian. Similarly a multi-horizon Laplace transform \\[ \\mathbb{E}[\\exp(\\gamma&#39;_{1}w_{1,t+1}+\\dots+\\gamma&#39;_{h}w_{1,t+h})|\\underline{w_{1,t}}] \\] can be obtained from: \\[\\begin{eqnarray*} \\mathbb{E}_t[\\exp(\\{\\gamma&#39;_{1,1}w_{1,t+1}+\\gamma&#39;_{2,1}w_{2,t+1}\\}+\\dots+ \\{\\gamma&#39;_{1,h}w_{1,t+h}+\\gamma&#39;_{2,h}w_{2,t+h}\\}] \\\\ = exp[A&#39;_{1,t,h}(\\gamma^h_1, \\gamma^h_2)w_{1,t}+A&#39;_{2,t,h}(\\gamma^h_1, \\gamma^h_2)w_{2,t}+B_{t,h}(\\gamma^h_1, \\gamma^h_2)], \\end{eqnarray*}\\] (with \\(\\gamma^h_1 = (\\gamma&#39;_{1,1},\\dots, \\gamma&#39;_{1,h})&#39;, \\gamma^h_2 = (\\gamma&#39;_{2,1},\\dots, \\gamma&#39;_{2,h})&#39;\\)) by: \\[ \\exp[A&#39;_{1,t,h}(\\gamma^h,0) w_{1,t} + A&#39;_{2,t,h}(\\gamma^h,0)g (\\underline{w_{1,t}}) + B_{t,h}(\\gamma^h,0)], \\] with \\(\\gamma^h = (\\gamma_1&#39;,\\dots,\\gamma_h&#39;)&#39;\\). Example 1.19 (Affine process of order p) If \\(\\{w_{1,t}\\}\\) is affine or order \\(p\\), then \\((w_{1,t},\\dots,w_{1,t-p+1})\\) is affine of order 1. Here \\(w_{2,t} = (w&#39;_{1,t-1}, \\dots.w&#39;_{1,t-p+1})&#39;\\). Extreme case since \\(w_{2,t}\\) belongs to the information at \\(t-1\\), which implies \\(a_2(u_1, u_2) = u_2\\). Example 1.20 (Gaussian ARMA process) Consider an \\(ARMA(1,1)\\) process \\[ w_{1,t} - \\varphi w_{1,t-1} = \\varepsilon_t-\\theta \\varepsilon_{t-1} \\] \\[ \\mbox{$|\\varphi | &lt; 1$, $|\\theta| &lt; 1$, $\\varepsilon_t \\sim i.i.d. \\mathcal{N}(0, \\sigma^2)$}. \\] \\(w_{1,t}\\) is not Markovian. Take \\(w_{2,t} = \\varepsilon_t = (1-\\theta L)^{-1}(1-\\varphi L)w_{1,t}\\). We have: \\[ \\left( \\begin{array}{l} w_{1,t+1} \\\\ w_{2,t+1} \\end{array} \\right) = \\left( \\begin{array}{ll} \\varphi &amp; -\\theta \\\\ 0 &amp; 0 \\end{array} \\right) \\left( \\begin{array}{l} w_{1,t} \\\\ w_{2,t} \\end{array} \\right) + \\left( \\begin{array}{l} 1 \\\\ 1 \\end{array} \\right) \\varepsilon_{t+1} \\] * Hence \\((w_{1,t}, w_{2,t})&#39;\\) is Gaussian \\(VAR(1)\\) and, therefore, affine (of order 1). * Easily extended to \\(ARMA(p,q)\\) and \\(VARMA(p,q).\\) Example 1.21 (GARCH type process) \\(w_{1,t}\\) is defined by: \\[ w_{1,t+1} = \\mu + \\varphi w_{1,t} + \\sigma_{t+1} \\varepsilon_{t+1}, \\] where \\(|\\varphi| &lt; 1\\) and \\(\\varepsilon_t \\sim i.i.d. \\mathcal{N}(0,1)\\), and \\[ \\sigma^2_{t+1} = \\omega + \\alpha \\varepsilon^2_t + \\beta \\sigma^2_t, \\] where \\(0 &lt; \\beta &lt; 1\\). Consider \\(w_{2,t} = \\sigma^2_{t+1}\\) non-linear function of \\(\\underline{w_{1,t}}\\). It can be shown (see below) that: \\[\\begin{eqnarray*} &amp;&amp; \\mathbb{E}\\left[\\exp(u_1 w_{1,t+1} + u_2 w_{2,t+1})|\\underline{w_{1,t}}\\right] \\\\ &amp;=&amp; \\exp\\left[u_1 \\mu + u_2 \\omega - \\frac{1}{2} \\log(1-2 u_2 \\alpha) \\right. \\\\ &amp;&amp;\\left. + u_1 \\varphi w_{1,t} + (u_2\\beta + \\frac{u^2_1}{2(1-2u_2\\alpha)}) w_{2,t}\\right], \\end{eqnarray*}\\] which is exponential affine in \\((w_{1,t}, w_{2,t})\\). Proposition 1.3 (Affine property of the GARCH-type process) The process \\(w_t = (w_{1,t}, w_{2,t})\\) defined by: \\[ \\left\\{ \\begin{array}{ccl} w_{1, t+1} &amp;=&amp; \\mu + \\varphi w_{1,t} + \\sigma_{t+1} \\varepsilon_{t+1} \\mid \\varphi \\mid &lt; 1 \\\\ \\sigma^2_{t+1} &amp;=&amp; \\omega + \\alpha \\varepsilon^2_t + \\beta \\sigma^2_t 0 &lt; \\beta &lt; 1, \\alpha &gt; 0, \\omega &gt; 0 \\\\ w_{2,t} &amp;=&amp; \\sigma^2_{t+1}, \\quad \\varepsilon_t \\sim i.i.d. \\mathcal{N}(0,1) \\end{array} \\right. \\] is affine. Proof. Note that \\(w_{2,t}\\) is function of \\(\\underline{w_{1,t}}\\) \\[\\begin{eqnarray*} &amp;&amp; \\mathbb{E}[\\exp(u_1 w_{1, t+1} + u_2 w_{2, t+1})|\\underline{w_{1,t}}] \\\\ &amp;= &amp; \\exp(u_1 \\mu + u_1 \\varphi w_{1,t} + u_2 \\omega + u_2 \\beta w_{2,t}) \\mathbb{E}[\\exp(u_1 \\sigma_{t+1} \\varepsilon_{t+1} + u_2 \\alpha \\varepsilon^2_{t+1})|\\underline{w_{1,t}}] \\end{eqnarray*}\\] and, using Lemma 1.5: \\[\\begin{eqnarray*} &amp;&amp;\\mathbb{E}[\\exp(u_1 w_{1, t+1} + u_2 w_{2, t+1})|\\underline{w_{1,t}}] \\\\ &amp;= &amp; \\exp(u_1 \\mu + u_1 \\varphi w_{1,t} + u_2 \\omega + u_2 \\beta w_{2t}) \\exp \\left[ - \\frac{1}{2} \\log(1-2 u_2 \\alpha) + \\frac{u^2_1 w_{2,t}}{2(1-2 u_2 \\alpha)} \\right]\\\\ &amp;= &amp; \\exp \\left[ u_1 \\mu + u_2 \\omega - \\frac{1}{2} \\log(1-2u_2\\alpha)+ u_1 \\varphi w_{1,t} + \\left(u_2 \\beta + \\frac{u^2_1}{2(1-2u_2\\alpha)}\\right) w_{2,t}\\right], \\end{eqnarray*}\\] which is exponential affine in \\((w_{1,t}, w_{2,t})\\). 1.15 Truncated Laplace Transforms of Affine Processes and Transform Analysis Let us introduce the following notation: \\[ w_{t+1,T} = (w&#39;_{t+1}, w&#39;_{t+2},\\dots, w&#39;_T)&#39; \\] with \\(w_t\\) affine \\(n\\)-dimensional process. We want to compute: \\[ \\tilde{\\varphi}_t(u ; v, \\gamma) = \\mathbb{E}_t[\\exp(u&#39;w_{t+1,T})\\textbf{1}_{\\{v&#39;w_{t+1,T&lt;\\gamma}\\}}]. \\] Consider the complex untruncated conditional Laplace transform: \\[ \\varphi_t(z) = \\mathbb{E}_t[\\exp(z&#39;w_{t+1,T})],\\quad z \\in \\mathbb{C}^{nT}, \\] computed using the same recursive algorithm as in the real case. We have (Duffie, Pan, and Singleton 2000): \\[\\begin{equation} \\tilde{\\varphi}_t(u ; v, \\gamma) = \\frac{\\varphi_t(u)}{2} - \\frac{1}{\\pi} \\int^\\infty_0 \\frac{Im[\\varphi_t(u+ivx) \\exp(-i\\gamma x)]}{x} dx.\\tag{1.15} \\end{equation}\\] where \\(Im\\) means imaginary part. Note that the integral in Eq. (1.15) is one dimensional (whatever the dimension of \\(w_t\\)). Application: Option pricing. The typical problem is to compute conditional expectation of the type (with \\(k &gt; 0\\)): \\[\\begin{eqnarray*} &amp;&amp; \\mathbb{E}_t\\left([\\exp(u&#39;_1 w_{t+1,T})-k \\exp(u&#39;_2 w_{t+1,T})]^+\\right) \\\\ &amp;= &amp; \\mathbb{E}_t\\left([\\exp(u&#39;_1 w_{t+1,T})-k \\exp(u&#39;_2 w_{t+1,T})]\\textbf{1}_{\\{[\\exp(u_1-u_2)&#39;w_{t+1,T}] &gt; k \\}}\\right) \\\\ &amp;= &amp; \\tilde{\\varphi}_t(u_1 ; u_2-u_1, - \\log k) - k \\tilde{\\varphi}_t(u_2 ; u_2-u_1, - \\log k). \\end{eqnarray*}\\] PROOFS We want to compute: \\[ \\tilde{\\varphi}_t(u;v,\\gamma) = \\mathbb{E}_t[\\exp(u&#39;w)\\textbf{1}_{(v&#39;w&lt;\\gamma})] \\] (noting \\(w=\\tilde{w}_{t+1,T}\\)) knowing the function \\(\\varphi_t(z)=\\mathbb{E}_t[exp(z&#39;w)],\\) \\(z\\): complex components.\\ We omit the index \\(t\\) for notational simplicity. Let us first note that, for given \\(u\\) and \\(v\\), \\(\\tilde{\\varphi}_t(u;v,\\gamma)\\) is a positive increasing bounded function of \\(\\gamma\\) and therefore can be seen as the c.d.f. of a positive finite measure on \\(\\mathbb{R}\\), the Fourier transform of which is: \\[ \\int_{\\mathbb{R}} \\exp(i\\gamma x)d\\tilde{\\varphi}(u;v,\\gamma) = \\mathbb{E} \\int_{\\mathbb{R}} \\exp(i\\gamma x)d\\tilde{\\varphi}_w(u;v,\\gamma), \\] where, for given \\(w, \\tilde{\\varphi}_w(u;v,\\gamma)\\) is the c.d.f. of the mass point \\(\\exp(u&#39;w)\\) at \\(v&#39;w\\), so we get the function of \\(x\\): \\[\\begin{eqnarray*} \\displaystyle \\int_{\\mathbb{R}} \\exp(i\\gamma x) d\\tilde{\\varphi}(u;v,\\gamma) &amp;=&amp; \\mathbb{E}[\\exp(ixv&#39;w)exp(u&#39;w)] \\\\ &amp; =&amp; \\mathbb{E}[\\exp(u+ivx)&#39;w] \\\\ &amp; =&amp; \\varphi(u+ivx). \\end{eqnarray*}\\] Let us now compute for any real number \\(\\lambda\\): \\[\\begin{eqnarray*} &amp;&amp;A(x_0,\\lambda) \\\\ &amp;=&amp; \\displaystyle \\frac{1}{2\\pi} \\int^{x_0}_{-x_0} \\displaystyle \\frac{\\exp(i\\lambda x)\\varphi(u-ivx)-\\exp(-i\\lambda)\\varphi(u+ivx)}{ix}dx \\\\ &amp;=&amp; \\displaystyle \\frac{1}{2\\pi} \\int^{x_0}_{-x_0}\\left[ \\begin{array}{l} \\displaystyle \\int_{\\mathbb{R}} \\displaystyle \\frac{\\exp[-ix(\\gamma-\\lambda)]-\\exp[ix(\\gamma-\\lambda)]}{ix}d\\tilde{\\varphi}(u;v,\\gamma) \\end{array} \\right]dx \\\\ &amp;=&amp; \\displaystyle \\frac{1}{2\\pi} \\displaystyle \\int_{\\mathbb{R}} \\left[ \\begin{array}{l} \\displaystyle \\int^{x_0}_{-x_0} \\displaystyle \\frac{\\exp[-ix(\\gamma-\\lambda)] -\\exp[ix(\\gamma-\\lambda)]}{ix}dx \\end{array} \\right]d\\tilde{\\varphi}(u;v,\\gamma) \\end{eqnarray*}\\] Now : \\[\\begin{eqnarray*} \\displaystyle \\frac{1}{2\\pi} \\int^{x_o}_{-x_o} \\displaystyle \\frac{\\exp[-ix(\\gamma-\\lambda)] -\\exp[ix(\\gamma-\\lambda)]}{ix}dx \\\\ = \\displaystyle \\frac{-sign(\\gamma-\\lambda)}{\\pi} \\int^{x_o}_{-x_o}\\displaystyle \\frac{sin(x\\mid\\gamma-\\lambda\\mid)}{x}dx \\end{eqnarray*}\\] which tends to -sign\\((\\gamma-\\lambda)\\) when \\(x_o\\rightarrow\\infty\\) (where sign\\((\\omega)=1\\) if \\(\\omega&gt;0\\), sign\\((\\omega)=0\\) if \\(\\omega=0\\), sign\\((\\omega)=-1\\) if \\(\\omega&lt;0\\)). Therefore: \\[ A(\\infty,\\lambda) = - \\displaystyle \\int_{\\mathbb{R}} sign(\\gamma-\\lambda)d\\tilde{\\varphi}(u;v,\\gamma) = -\\mathbb{E} \\displaystyle \\int_{\\mathbb{R}} sign(\\gamma-\\lambda)d\\tilde{\\varphi}_w(u;\\theta,\\gamma), \\] where \\(\\tilde{\\varphi}_w(u;v,\\gamma)\\) is the c.d.f. of the mass point \\(exp(u&#39;w)\\) at \\(v&#39;w\\) and \\[ \\displaystyle \\int_{\\mathbb{R}} sign(\\gamma-\\lambda)d\\tilde{\\varphi}_w(u;v,\\gamma)= \\left\\{ \\begin{array}{ccl} \\exp(u&#39;w) &amp; if&amp; \\lambda&lt;v&#39;w \\\\ 0 &amp; if&amp; \\lambda=v&#39;w \\\\ - exp(u&#39;w) &amp; if&amp; \\lambda&gt;v&#39;w \\end{array} \\right. \\] so \\[\\begin{eqnarray*} A(\\infty,\\lambda) &amp; =&amp; - \\mathbb{E}[\\exp(u&#39;w)(1-\\textbf{1}_{(v&#39;w&lt;\\lambda)})-\\exp(u&#39;w)\\textbf{1}_{(v&#39;w&lt;\\lambda)}] \\\\ &amp; =&amp; - \\varphi(u) + 2\\tilde{\\varphi}(u;v,\\lambda) \\end{eqnarray*}\\] and therefore: \\[ \\tilde{\\varphi}(u;,v,\\gamma) = \\displaystyle \\frac{\\varphi(u)}{2} + \\displaystyle \\frac{1}{2} A(\\infty,\\gamma) \\] where: \\[\\begin{eqnarray*} \\displaystyle \\frac{1}{2} A(\\infty,\\gamma) &amp; =&amp; \\displaystyle \\frac{1}{4\\pi} \\int^{\\infty}_{-\\infty} \\displaystyle \\frac{\\exp(i\\gamma x)\\varphi(u-ivx)-\\exp(-i\\gamma x)\\varphi(u+ivx)}{ix} dx \\\\ &amp; =&amp; \\displaystyle \\frac{1}{2\\pi} \\int^{\\infty}_{o} \\displaystyle \\frac{\\exp(i\\gamma x)\\varphi(u-ivx)-\\exp(-i\\gamma x)\\varphi(u+ivx)}{ix} dx \\\\ &amp; =&amp; - \\displaystyle \\frac{1}{\\pi} \\int^{\\infty}_{o} \\displaystyle \\frac{{\\mathcal I}m[\\exp(-i\\gamma x)\\varphi(u+ivx)]}{x}dx \\end{eqnarray*}\\] and finally \\[ \\tilde{\\varphi}(u;v,\\gamma) = \\displaystyle \\frac{\\varphi(u)}{2} - \\displaystyle \\frac{1}{\\pi} \\int^\\infty_o \\displaystyle \\frac{{\\mathcal I}m[\\varphi(u+ivx)\\exp(-i\\gamma x)]}{x}dx. \\] Example 1.22 (Exogenous short rate) Consider an asset whose date-\\(t\\) price is \\(p_t\\). Geometric asset return: \\(y_t = \\log(p_t/p_{t-1})\\). Consider an option written on this asset. Strike: \\(k p_t\\). Deterministic (exogenous) interest rates. Residual maturity: \\(h\\). *[\\(\\Rightarrow\\)] Option price: \\[ p_t \\exp(-r_{t}-\\dots-r_{t+h-1}) \\mathbb{E}^{\\mathbb{Q}}_t[\\exp u&#39;_1 w_{t+1, t+h} - k]^+ \\] with \\(u_1 = e \\otimes e_1\\), where \\(e\\) is the \\(h\\)-dimensional vector with components 1 and \\(e_1\\) the \\(n\\)-vector selecting the 1st component (\\(y_t\\) being the 1st component of \\(w_t\\), say). Example 1.23 (Endogenous short rate) Stochastic (endogenous) short-term rate: \\(r_{t+1} = \\omega_0 + \\omega&#39;_1 w_t\\). The price is: \\[\\begin{eqnarray*} &amp;&amp; p_t \\mathbb{E}^{\\mathbb{Q}}_t \\left[ \\exp(-\\omega_0 - \\omega&#39;_1 w_t-\\dots- \\omega_0 - \\omega&#39;_1 w_{t+h-1}) [\\exp(u&#39;_1 w_{t+1,t+h})-k]^+ \\right]\\\\ &amp;= &amp; p_t \\exp(-h \\omega_0 - \\omega&#39;_1 w_t)\\mathbb{E}^{\\mathbb{Q}}_t\\left(\\left[\\exp(\\tilde{u}&#39;_1w_{t+1,t+h})-k \\exp(u_2 w_{t+1, t+h})\\right]^+\\right), \\end{eqnarray*}\\] with \\(\\tilde{u}&#39;_1 = u_1 + u_2\\), [\\(u_1 = e \\otimes e_1\\) as before], and \\(u_2 = (-\\omega&#39;_1,\\dots, -\\omega&#39;_1, 0)&#39;\\). 1.16 APPENDICES Lemma 1.4 If \\(\\mu \\in \\mathbb{R}^L\\) and \\(Q\\) is a \\((L \\times L)\\) matrix symmetric positive definite, then: \\[ \\int_{\\mathbb{R}^{L}} \\exp(-u&#39;Q u + \\mu&#39;u)du = \\frac{\\pi^{L/2}}{(det Q)^{1/2}} exp \\left( \\begin{array}{l} \\frac{1}{4} \\mu&#39;Q^{-1}\\mu \\end{array} \\right). \\] Proof. The integral is: \\[\\begin{eqnarray*} &amp;&amp; \\int_{\\mathbb{R}^{L}} exp \\left[ \\begin{array}{l} - (u - \\frac{1}{2} Q^{-1} \\mu)&#39; Q (u - \\frac{1}{2} Q^{-1} \\mu)&#39; \\end{array} \\right] exp\\left( \\begin{array}{l} \\frac{1}{4} \\mu&#39;Q^{-1}\\mu \\end{array} \\right)du \\\\ &amp;=&amp; \\frac{\\pi^{L/2}}{(det Q)^{1/2}} exp\\left( \\begin{array}{l} \\frac{1}{4} \\mu&#39;Q^{-1}\\mu \\end{array} \\right) \\end{eqnarray*}\\] [using the formula for the unit mass of \\(\\mathcal{N}( 0.5Q^{-1}\\mu,(2Q)^{-1})\\)]. Lemma 1.5 If \\(\\varepsilon_{t+1} \\sim \\mathcal{N}(0,Id)\\), we have \\[ \\mathbb{E}_t \\left(\\exp[\\lambda&#39;\\varepsilon_{t+1}+\\varepsilon&#39;_{t+1} V \\varepsilon_{t+1}]\\right) = \\frac{1}{[\\det(I-2V)]^{1/2}} \\exp\\left[ \\frac{1}{2} \\lambda&#39;(I-2V)^{-1}\\lambda \\right]. \\] Proof. We have \\[ \\mathbb{E}_t \\exp(\\lambda&#39;\\varepsilon_{t+1}+\\varepsilon&#39;_{t+1}V\\varepsilon_{t+1}) = \\frac{1}{(2\\pi)^{n/2}} \\int_{\\mathbb{R}^{n}} \\exp\\left[ \\begin{array}{l} -u&#39;\\left( \\begin{array}{l} \\frac{1}{2} I-V \\end{array} \\right)u+\\lambda&#39;u \\end{array} \\right]du \\] From Lemma 1.4, if \\(u\\in\\mathbb{R}^n\\), then \\[ \\int_{\\mathbb{R}^{n}} \\exp(-u&#39; Q u+\\mu&#39;u) du = \\frac{\\pi^{n/2}}{(\\det Q)^{1/2}} \\exp\\left( \\begin{array}{l} \\frac{1}{4} \\mu&#39;Q^{-1}\\mu \\end{array} \\right). \\] Therefore: \\[ \\begin{array}{l} \\mathbb{E}_t \\exp(\\lambda&#39;\\varepsilon_{t+1}+\\varepsilon&#39;_{t+1}V\\varepsilon_{t+1}) \\\\ = \\frac{1}{2^{n/2} \\left[ \\begin{array}{l} \\det \\left( \\begin{array}{l} \\frac{1}{2} I-V \\end{array} \\right) \\end{array} \\right]^{1/2} } \\exp\\left[ \\begin{array}{l} \\frac{1}{4} \\lambda&#39;\\left( \\begin{array}{l} \\frac{1}{2} I-V \\end{array} \\right)^{-1}\\lambda \\end{array} \\right]. \\end{array} \\] References "],["pricing-and-risk-neutral-dynamics.html", "Chapter 2 Pricing and risk-neutral dynamics 2.1 SDF: Equilibrium Approach", " Chapter 2 Pricing and risk-neutral dynamics 2.1 SDF: Equilibrium Approach "],["technical-details.html", "Chapter 3 Technical Details", " Chapter 3 Technical Details Now I’ll teach you some crazy math, but I need to work it out first… "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
